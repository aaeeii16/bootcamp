{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost\n",
    "except ImportError as ex:\n",
    "    print(\"Error: the xgboost library is not installed.\")\n",
    "    xgboost = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zaloguj się do https://www.kaggle.com/ i przejdź do wyzwania https://www.kaggle.com/c/titanic, aby pobrać \n",
    " * train.csv i test.csv. \n",
    "\n",
    "Zapisz je w katalogu datasets/titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dane są już podzielone na zestaw treningowy i zestaw testów. \n",
    "* Jednak dane testowe nie zawierają etykiet: Twoim celem jest wyszkolenie najlepszego modelu, który możesz wykorzystać w danych treningowych, następnie dokonanie swoich przewidywań na danych testowych i przesłanie ich do Kaggle, aby zobaczyć ostateczny wynik.\n",
    "\n",
    "Rzućmy okiem na kilka pierwszych rzędów zestawu treningowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "\n",
    "* Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* Pclass: passenger class.\n",
    "* Name, Sex, Age: self-explanatory\n",
    "* SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* Parch: how many children & parents of the passenger aboard the Titanic.\n",
    "* Ticket: ticket id\n",
    "* Fare: price paid (in pounds)\n",
    "* Cabin: passenger's cabin number\n",
    "* Embarked: where the passenger embarked the Titanic\n",
    "* Let's get more info to see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atrybuty **Age**, **Cabin** oraz **Embarked** są czasami zerowe (mniej niż 891 wartości bez wartości null), szczególnie w przypadku **Cabin** (77% ma wartość zerową). Zignorujemy teraz **Cabin** i skupimy się na reszcie. Atrybut **Age** ma około 19% wartości pustych, więc będziemy musieli zdecydować, co z nimi zrobić. Zastąpienie wartości null medianą wieku wydaje się uzasadnione.\n",
    "\n",
    "Atrybuty **Name** i **Ticket** mogą mieć pewną wartość, ale będą one nieco trudne do przekształcenia w użyteczne liczby. Na razie będziemy je ignorować.\n",
    "\n",
    "Rzućmy okiem na atrybuty liczbowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tylko 38% przeżyło: to wystarczająco blisko do 40%, więc **accuracy** będzie rozsądną miarą do oceny naszego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie zapomnij o etykietach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, X_test, y_train, y_test = train_test_split(train_data, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "plt.hist(y_train, alpha=0.5)\n",
    "plt.hist(y_test, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>3</td>\n",
       "      <td>McEvoy, Mr. Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36568</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>686</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Mr. Joseph Philippe Lemercier</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>Chronopoulos, Mr. Apostolos</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2680</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                    Name     Sex  \\\n",
       "6              7       1                 McCarthy, Mr. Timothy J    male   \n",
       "718          719       3                     McEvoy, Mr. Michael    male   \n",
       "685          686       2  Laroche, Mr. Joseph Philippe Lemercier    male   \n",
       "73            74       3             Chronopoulos, Mr. Apostolos    male   \n",
       "882          883       3            Dahlberg, Miss. Gerda Ulrika  female   \n",
       "\n",
       "      Age  SibSp  Parch         Ticket     Fare Cabin Embarked  \n",
       "6    54.0      0      0          17463  51.8625   E46        S  \n",
       "718   NaN      0      0          36568  15.5000   NaN        Q  \n",
       "685  25.0      1      2  SC/Paris 2123  41.5792   NaN        C  \n",
       "73   26.0      1      0           2680  14.4542   NaN        C  \n",
       "882  22.0      0      0           7552  10.5167   NaN        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(\"Survived\",axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    336\n",
       "1    135\n",
       "2    125\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      390\n",
       "female    206\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    437\n",
       "C    105\n",
       "Q     53\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atrybut **Embarked** mówi nam, gdzie pasażer zaokrętował: C = Cherbourg, Q = Queenstown, S = Southampton.\n",
    "\n",
    "Teraz zbudujmy nasze **pipeline** preprocessingu. \n",
    "\n",
    "Wykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudujmy **pipeline** dla atrybutów numerycznych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.    ,   0.    ,   0.    ,  51.8625],\n",
       "       [ 28.    ,   0.    ,   0.    ,  15.5   ],\n",
       "       [ 25.    ,   1.    ,   2.    ,  41.5792],\n",
       "       ...,\n",
       "       [ 41.    ,   2.    ,   0.    ,  14.1083],\n",
       "       [ 14.    ,   1.    ,   2.    , 120.    ],\n",
       "       [ 21.    ,   0.    ,   1.    ,  77.2875]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy także potrzebować imputera do kategorycznych kolumn  napisowych (zwykły Imputer nie działa na tych kolumnach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy zbudować **pipeline** dla atrybutów kategorycznych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec połączmy powyższe podejścia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz mamy fajny **pipeline** przetwarzania wstępnego, który pobiera dane wejściowe i zwraca dane wyjściowe złorzone z liczb, które możemy podać do dowolnego modelu uczenia maszynowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', LinearSVC(C=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_1.fit(train_data, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100, 'classifier__gamma': 0.001}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pipe_2 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', SVC(C=1, probability=True))])\n",
    "\n",
    "param_grid_2 = {\n",
    "            'classifier__C': [0.001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe_2, param_grid_2, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(train_data, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_3 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', LogisticRegression(C=1))])\n",
    "\n",
    "param_grid_3 = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(pipe_3, param_grid_3, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_3.fit(train_data, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__metric': 'cityblock', 'classifier__n_neighbors': 11}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_4 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', KNeighborsClassifier(n_neighbors=2, metric='euclidean'))])\n",
    "\n",
    "param_grid_4 = {\n",
    "            'classifier__n_neighbors': [2, 5, 10, 11,12],\n",
    "            'classifier__metric': ['euclidean', 'cityblock', 'cosine']\n",
    "}\n",
    "\n",
    "\n",
    "grid_4 = GridSearchCV(pipe_4, param_grid_4, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_4.fit(train_data, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 9,\n",
       " 'classifier__max_leaf_nodes': 16,\n",
       " 'classifier__min_samples_split': 2}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_5 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "param_grid_5 = {\n",
    "            'classifier__max_depth': [5,9,10,11,20,30],\n",
    "            'classifier__min_samples_split': [2,3,5,10,20,30,40],\n",
    "            'classifier__max_leaf_nodes': [3,4,10,14,15,16,20,30,40]\n",
    "}\n",
    "\n",
    "\n",
    "grid_5 = GridSearchCV(pipe_5, param_grid_5, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_5.fit(train_data, y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_samples': 20, 'classifier__n_estimators': 50}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_6 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', BaggingClassifier(\n",
    "                                    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "                                    max_samples=100, bootstrap=True, random_state=42))\n",
    "                  ])\n",
    "\n",
    "param_grid_6 = {'classifier__n_estimators': [10,50,100],\n",
    "              'classifier__max_samples': [10,20]\n",
    "             }\n",
    "\n",
    "grid_6 = GridSearchCV(pipe_6, param_grid_6, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_6.fit(train_data, y_train)\n",
    "grid_6.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 20,\n",
       " 'classifier__max_leaf_nodes': 20,\n",
       " 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_7 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', RandomForestClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_7 = {'classifier__n_estimators': [10, 50, 100],\n",
    "              'classifier__max_leaf_nodes': [10, 20],\n",
    "              'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_7 = GridSearchCV(pipe_7, param_grid_7, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_7.fit(train_data, y_train)\n",
    "grid_7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 10,\n",
       " 'classifier__max_leaf_nodes': 20,\n",
       " 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pipe_8 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_8 = {'classifier__n_estimators': [10, 50, 100],\n",
    "              'classifier__max_leaf_nodes': [10, 20],\n",
    "              'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_8 = GridSearchCV(pipe_8, param_grid_8, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_8.fit(train_data, y_train)\n",
    "grid_8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.9, 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_9 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', AdaBoostClassifier(\n",
    "                        DecisionTreeClassifier(max_depth=1), \n",
    "                        n_estimators=1, learning_rate=0.5, \n",
    "                        algorithm=\"SAMME.R\", random_state=42)\n",
    "                   )\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_9 = {'classifier__n_estimators': [50, 100, 200],\n",
    "               'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1],\n",
    "#                'classifier__base_estimator__max_depth':[5,10,20,50] \n",
    "             }\n",
    "\n",
    "grid_9 = GridSearchCV(pipe_9, param_grid_9, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_9.fit(train_data, y_train)\n",
    "grid_9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 50}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_10 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', GradientBoostingClassifier(\n",
    "                       n_estimators=1, \n",
    "                      learning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_10 = {'classifier__n_estimators': [50, 100, 200],\n",
    "              'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_10 = GridSearchCV(pipe_10, param_grid_10, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_10.fit(train_data, y_train)\n",
    "grid_10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 50}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "pipe_11 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', xgboost.XGBClassifier(n_estimators=1, \n",
    "                      learning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_11 = {'classifier__n_estimators': [50, 100, 200],\n",
    "              'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_11 = GridSearchCV(pipe_11, param_grid_11, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_11.fit(train_data, y_train)\n",
    "grid_11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('grid_2', grid_2.best_estimator_), \n",
    "                ('grid_3', grid_3.best_estimator_), \n",
    "                ('grid_4', grid_4.best_estimator_), \n",
    "                ('grid_5', grid_5.best_estimator_), \n",
    "                ('grid_6', grid_6.best_estimator_), \n",
    "                ('grid_7', grid_7.best_estimator_), \n",
    "                ('grid_8', grid_8.best_estimator_), \n",
    "                ('grid_9', grid_9.best_estimator_),\n",
    "                ('grid_10', grid_10.best_estimator_), \n",
    "                ('grid_11', grid_11.best_estimator_)\n",
    "               ],\n",
    "    voting='soft')\n",
    "voting_clf.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator = xgboost.XGBClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_12 = Pipeline([('preprocessing', preprocess_pipeline), \n",
    "                   ('classifier', xgboost.XGBClassifier(n_jobs=-1))\n",
    "                  ])\n",
    "\n",
    "param_grid_12 = {\n",
    "    'classifier__max_depth': [3, 5, 8, 10],\n",
    "    'classifier__learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'classifier__n_estimators': [50, 100, 150, 200, 400],\n",
    "    'classifier__gamma': [0, 0.5, 1, 2],\n",
    "    'classifier__colsample_bytree': [1, 0.8, 0.5],\n",
    "    'classifier__subsample': [1, 0.8, 0.5],\n",
    "    'classifier__min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_12 = RandomizedSearchCV(n_iter=30,estimator=pipe_12, \n",
    "                             param_distributions=param_grid_12, \n",
    "                      cv=kfold, \n",
    "                      return_train_score=True)\n",
    "\n",
    "grid_12.fit(train_data, y_train)\n",
    "grid_12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "models.append(('LR', grid_3.best_estimator_))\n",
    "models.append(('KNN', grid_4.best_estimator_))\n",
    "models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "models.append(('voting_clf', voting_clf))\n",
    "models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "    if (name == 'SVM linear'):\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.decision_function(X_test)) ))            \n",
    "    else:\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]) ))\n",
    "    \n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n",
    "    if (name == 'SVM linear'):\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.decision_function(X_test)))        \n",
    "    else:    \n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score,\n",
    "     'roc_auc_score' : roc_auc_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM linear','SVM rbf','LR','KNN','DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','voting','XGBClassifier r'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    if (name == 'SVM linear'):\n",
    "        y_scores = model.decision_function(X_test)\n",
    "    else: \n",
    "        y_scores = model.predict_proba(X_test)[:,1]        \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "    plot_roc_curve(fpr, tpr, name)\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "n_features = len(grid_7.best_estimator_.named_steps['classifier'].feature_importances_)\n",
    "plt.barh(range(n_features), grid_7.best_estimator_.named_steps['classifier'].feature_importances_, align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
