{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.6746 - accuracy: 0.5951 - val_loss: 0.5648 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.5823 - accuracy: 0.7357 - val_loss: 0.5447 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.5513 - accuracy: 0.7490 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4870 - accuracy: 0.7818 - val_loss: 0.4240 - val_accuracy: 0.8254\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4442 - accuracy: 0.8060 - val_loss: 0.3936 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4260 - accuracy: 0.8121 - val_loss: 0.3789 - val_accuracy: 0.8374\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4109 - accuracy: 0.8183 - val_loss: 0.3698 - val_accuracy: 0.8384\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4020 - accuracy: 0.8189 - val_loss: 0.3636 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3947 - accuracy: 0.8215 - val_loss: 0.3590 - val_accuracy: 0.8373\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3911 - accuracy: 0.8213 - val_loss: 0.3571 - val_accuracy: 0.8374\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3901 - accuracy: 0.8230 - val_loss: 0.3555 - val_accuracy: 0.8376\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3871 - accuracy: 0.8215 - val_loss: 0.3539 - val_accuracy: 0.8381\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3897 - accuracy: 0.8213 - val_loss: 0.3528 - val_accuracy: 0.8390\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3836 - accuracy: 0.8229 - val_loss: 0.3515 - val_accuracy: 0.8386\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3808 - accuracy: 0.8273 - val_loss: 0.3502 - val_accuracy: 0.8383\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3794 - accuracy: 0.8273 - val_loss: 0.3490 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3793 - accuracy: 0.8258 - val_loss: 0.3481 - val_accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3770 - accuracy: 0.8291 - val_loss: 0.3471 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3789 - accuracy: 0.8276 - val_loss: 0.3463 - val_accuracy: 0.8415\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3772 - accuracy: 0.8280 - val_loss: 0.3459 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3770 - accuracy: 0.8286 - val_loss: 0.3455 - val_accuracy: 0.8422\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.3451 - val_accuracy: 0.8426\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3737 - accuracy: 0.8295 - val_loss: 0.3446 - val_accuracy: 0.8430\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3734 - accuracy: 0.8295 - val_loss: 0.3442 - val_accuracy: 0.8428\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3737 - accuracy: 0.8290 - val_loss: 0.3438 - val_accuracy: 0.8428\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3434 - val_accuracy: 0.8433\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3704 - accuracy: 0.8307 - val_loss: 0.3431 - val_accuracy: 0.8439\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3716 - accuracy: 0.8294 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3714 - accuracy: 0.8292 - val_loss: 0.3423 - val_accuracy: 0.8442\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3717 - accuracy: 0.8306 - val_loss: 0.3422 - val_accuracy: 0.8444\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3420 - val_accuracy: 0.8445\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3710 - accuracy: 0.8321 - val_loss: 0.3418 - val_accuracy: 0.8444\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3699 - accuracy: 0.8316 - val_loss: 0.3417 - val_accuracy: 0.8444\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3717 - accuracy: 0.8314 - val_loss: 0.3415 - val_accuracy: 0.8443\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3720 - accuracy: 0.8295 - val_loss: 0.3414 - val_accuracy: 0.8444\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3704 - accuracy: 0.8314 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3694 - accuracy: 0.8309 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3692 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3694 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8446\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3718 - accuracy: 0.8302 - val_loss: 0.3407 - val_accuracy: 0.8448\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3686 - accuracy: 0.8329 - val_loss: 0.3406 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 3s 91us/step - loss: 0.3685 - accuracy: 0.8316 - val_loss: 0.3405 - val_accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 3s 101us/step - loss: 0.3708 - accuracy: 0.8329 - val_loss: 0.3405 - val_accuracy: 0.8446\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 3s 102us/step - loss: 0.3726 - accuracy: 0.8296 - val_loss: 0.3404 - val_accuracy: 0.8446\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 3s 111us/step - loss: 0.3708 - accuracy: 0.8315 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 3s 106us/step - loss: 0.3694 - accuracy: 0.8306 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.3675 - accuracy: 0.8309 - val_loss: 0.3402 - val_accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 3s 102us/step - loss: 0.3688 - accuracy: 0.8328 - val_loss: 0.3401 - val_accuracy: 0.8448\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 3s 95us/step - loss: 0.3665 - accuracy: 0.8313 - val_loss: 0.3400 - val_accuracy: 0.8451\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 3s 101us/step - loss: 0.3685 - accuracy: 0.8335 - val_loss: 0.3400 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 3s 105us/step - loss: 0.3690 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 3s 107us/step - loss: 0.3671 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.3673 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 2s 60us/step - loss: 0.3697 - accuracy: 0.8318 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3689 - accuracy: 0.8316 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3669 - accuracy: 0.8320 - val_loss: 0.3398 - val_accuracy: 0.8448\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3680 - accuracy: 0.8323 - val_loss: 0.3397 - val_accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3668 - accuracy: 0.8328 - val_loss: 0.3397 - val_accuracy: 0.8448\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3674 - accuracy: 0.8323 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3679 - accuracy: 0.8328 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 3s 96us/step - loss: 0.3686 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 3s 108us/step - loss: 0.3698 - accuracy: 0.8330 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 3s 104us/step - loss: 0.3651 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3677 - accuracy: 0.8314 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3674 - accuracy: 0.8328 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3687 - accuracy: 0.8299 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3672 - accuracy: 0.8316 - val_loss: 0.3395 - val_accuracy: 0.8451\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 3s 83us/step - loss: 0.3669 - accuracy: 0.8330 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3693 - accuracy: 0.8314 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3672 - accuracy: 0.8322 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3692 - accuracy: 0.8296 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3677 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3661 - accuracy: 0.8300 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3675 - accuracy: 0.8327 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3690 - accuracy: 0.8292 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3671 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.8316 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3686 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3698 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3680 - accuracy: 0.8341 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.3682 - accuracy: 0.8303 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3684 - accuracy: 0.8321 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3687 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3648 - accuracy: 0.8329 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3654 - accuracy: 0.8309 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3682 - accuracy: 0.8319 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3681 - accuracy: 0.8311 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3694 - accuracy: 0.8333 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3686 - accuracy: 0.8318 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3682 - accuracy: 0.8306 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.8328 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3678 - accuracy: 0.8320 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 98/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3713 - accuracy: 0.8297 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 99/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3665 - accuracy: 0.8330 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3660 - accuracy: 0.8332 - val_loss: 0.3393 - val_accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6facf3e358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3xU9Z3/8ddnJpMruUEChIRLQBAUFDQiFKxafyrYKq1tEayt7bp1d3+9uNX2V+m2gq7turXt1t21tra1di0Fb1vFaq1WUVsVJSh3BBKuSSA3kpD73D6/P84kmYQEJpAQPPN5Ph55JHPmnDPfMwfe853PfOd7RFUxxhjjXp6hboAxxpjBZUFvjDEuZ0FvjDEuZ0FvjDEuZ0FvjDEulzDUDegpJydHJ0yYMNTNMMaYD5UNGzbUqGpub/edcUE/YcIEiouLh7oZxhjzoSIi+/u6z0o3xhjjcjEFvYgsEJGdIlIiInf2cv84EVkrIu+LyGYRuSayfIKItIrIxsjPzwf6AIwxxhzfCUs3IuIFHgSuBMqA9SKyRlW3R632XeAJVX1IRM4BXgAmRO4rVdWZA9tsY4wxsYqlRz8bKFHVParqB1YDi3qso0BG5O9MoGLgmmiMMeZUxBL0+cDBqNtlkWXRVgA3iUgZTm/+a1H3FUZKOq+LyCW9PYCI3CoixSJSXF1dHXvrjTHGnFAsQS+9LOs5E9pS4FFVLQCuAR4TEQ9wCBinqrOA24Hfi0hGj21R1YdVtUhVi3Jzex0dZIwx5iTFEvRlwNio2wUcW5q5BXgCQFXfBpKBHFVtV9XayPINQCkw5VQbbYwxJnaxjKNfD0wWkUKgHFgC3NhjnQPAFcCjIjINJ+irRSQXOKKqIRGZCEwG9gxY6407hEMQ8nfdVoVwsOsn0ArBNgi2g3jA6wNPj3+63kTwpUBC0rH39aQKgRZorobmGudvjxc8Pufx2uqhtT6yPMH5EQ9I1JtbT4Kzvieh+/K+eH2QEGkfHccXAgS8CV1tDgWc+6KnD9dQ13Oh2r1NncvDPZ6/gLMvDfVYHtmXhpznLCHZed7kBH2+jn12nItw9H5DEOqlHab/MsZA0ZcGfLcnDHpVDYrIV4E/A17gEVXdJiL3AMWquga4A/iliHwDp6zzRVVVEfkocI+IBIEQ8I+qemTAj8KcvPYmqC2Bmt1Qt88JopQsSEqHo4egZhccKYW2BidoO/6jB9qc3yJdYeHxde1X6B6E4WAkxEJOYHTcDrQ6t41LxPCiZ/pWUDQoQS9n2oVHioqK1L4ZewLhMLQ3OCHtb4LWOmg85ARz4yFoPOz8bjsKiamQOAwS07p6whqG+gNwZC80Vx3/sZKzIGcypAwHX7LTK/UlO+GekOT09IJtkcCO7uWFu/c2Ox6748frc14IOvbp9fXoMXes74301DseL7LfUDCqkeq8Iwi0QbA1tl6lLxXSciAtF3xpkbYGQLzOC11KtrOOhrp6wZ0P1+Mdx4lopH0dz5N4up6Hjt59KOAcf8c7hejnQsRZ5o28kHa8WGo46sW0l3ccXp9zPMc8r15n/VDAeb4CbRz7sVsvPAld5yL6XVP0u6xY3t2YQSEiG1S1qLf7zrgpEEwP4RBUvA+7X4JDm5xwrt/vhEZvEpIhPc/5yRoL/mbnheBoefdAyRwLU66G7AlOkOdMgexCJ5Da6p0efHoepI6w/7zGfMhZ0A+11nrY/ITTQ8scC5n50FwLlVvg0GbY91doqXV6TblTnVCefKVTy0tKd3rrKVmRcB/t9MBPJZh9yZB8zMAoY8yHmAV9b/zNztvipPST2z4UhKptcPBdqNzmBGdHEKcMd8oCXh9sXAnFj4K/sff9ZE+ASVc4Pe9JH4PU4Sd7RMaYOBbfQR/0Ox9ANlc7P5VbYe8bUL7BqWXO/jLM+2dIG+HUWWt2Q83OrpERIX+kTt7o9Mzr9jmllSN7nNonQHKmU5eNHlXSQTxw7vXwka9B1jhoOAgNZc4LwahznW2NMeYUxXfQ/+56pzTSQTww5gIneBvK4a3/guJHYPxHoPw9aKnpe18JKZA93umFT7zU2c/YiyBrvHN/yxHnA9LWukgN/ChMmOes3yF1OOSdPxhHaoyJY/Eb9PUHnJCf9XmY/mlnBEbW+O716UvugNfvg8NbnLr4uLlOECckd40y6KiTJyQe//HSRjg/xhhzmsVv0G9/1vl9ye0wfGLv64ycCp999LQ1yZyZWv0h9tQ0MXV0Bl6PjUAaKlvKGnjgld18tqiAq88dPaRtaQuESPZ5B2x/4bDS5A8SCIYZMSxpwPbbIX6DftszkDez75A3/dLYFqCuOUBeVjI+7+Bez6Z43xF+/NIuJuSksWjmGGZPGE5ts58Xtx3m9Z3VXDolh5vmjEf6MfqopqmdX/9tLweOtHDteWP42NSReASe2lDGT17eRVVjO7npSXx8Rh5XTBtJamLXfx2PgEcEr0fITPGRnZZIWqL3mMcPhsJUNrZT09hOXYufuhY/hxvaKa9voaK+DZ9XGJOVQn5WCmFVDh5p5WBdCwJMzctg6uh0EjweNuyvY8P+Ixxp8XPBuGwumjCcognZTMwZRmKC89xX1Lfy/OZD7Kxs5B8vncRZI4cdc8wlVU088345r+2qYkZ+JjdcNI7zCzIREdoCIfZUNzMhJ7XbsQLsq2kmMcHDmKyUzmWqylMbymhoDfB38wrx9HhBDIf1mGXHEwiFSfAIIkJjW4Afv7SL/3l7HwBrd1bxk8Xns2hm19yKZXUtHG5oI6wQViU9OYGCrFQyUhI40uzntZ3VvLrT+c7IDUVjmX9WTr/a02F/bTM/fHEnz285xPT8DK6fVcB1M8eQ0yOcdx5u5KHXSkj2eZk5NouZ47KYMjK922M2tAb45pObWFdaS5M/iCpcOD6bp//pI/1u14nE5xem6vbDA+fB/1kB878xuI/1IdIWCJGU4OlXQAKs/aCK25/YSF1LAI/A6IxkctOTSEn0kpqYwFkjh/H38wsZmZEMOIH3zMYK3iqtYUxmCuNGpDI6I5n2YJgWfxB/MMywpATSk31kpfoYPyKV9GQf/mCYn/5lFz9/vZScYUk0tQdp8YcYkZZIXYufsMKItERqm/0snT2Wu6+bTmKCh/L6Vn771j6a24NcOD6bovHDGZmRRE1TOzVNfp7fXMHv1h2gLRgiOzWRI81+RqQlkpniY09NM7PGZfGZCwv4664aXt1ZhT944i9kJXo9ZKQ4x5CW5OVIk5/DR50g6ikr1UdeZgrBUJjy+lZa/M4XzzKSEyjITiWsSml1E4GQs3Gyz8P5BVkMT0tkw/46qhrbAUjwCBNz00hJTGDTwXoAkhI8eD3CDz41g0/Oyqc9GGLNxgoeW7efzWUNeATOH5vFjkNHaQuEmRx5QSitbiKsMCYzmR9cP4PLzh5JMBTm56+X8sAruxGEv5tfyFcun0SLP8S3n97MazudmWevn5XPv3/mPHxeDzVN7dz59GZe31XNzLFZzDsrh7NHpbO3tpndlU0cbmijMDeNaaPTGZ2ZwnsH6nirpIYt5Q0ApCUmEFKlNRDi83PG838vO4vbVr/Pu/uOcP9nzqcwJ41fvF7Kyzsq6S3K0hK9tARCqEJuehKhsHKk2c/4EamRF3MhrEqi18PozGTyMpMB4Z29tbxdWsuemmYmjxzG9DGZeL3Ck8UHSfB4+PSF+Ww62MCW8ga8HmHuxBEsmD6aiwuH89u39/H7dw6QlpSAR4SGVueb3zPyM1lx3blcOD6bA7UtfOnRdzlwpIXPFo0lJy2RjBQfBdkpLJieF9t/vB6O94Wp+Az6N/8TXv4efH0jDC8c3McaIqGwUtvUTkiVUFhJ8HjITU86pvTgD4Z5eXslq9cf4G8lNUzKHca1543h4+flMTEnDY9HUFW2lh/lqQ0H+ePmQ+SmJ3H9Bfl8/LwxPPb2fn7+einT8jK4ee54KhraKDvSQk2znzZ/iGZ/kJ2HG/F6hM/PGc/UvAx+traEPTXNDE9LpD4S0CcyOiMZX4Jw8Egri4sKuOvac/EI/GVHFX/ZXsmEnDQ+PiOPySOH8eOXd/Lg2lLmTBzO2OxU/vB+OQDJPi9N7cd+k9UjsGhmPl+5/CwmjEjljd3VPL7+IIePtvOPH53IgumjO1/8GtsCbDrYQCjy/0ZV0cjvQEhpaA1Q1+znSIufxrYgjW1BmtoCZKcmkp+dQl5mCiPTk8hOSyQ71cfIjGSGJXX1mFWdfQhCZmrXlBL+YJg9NU34g2Gmjs7o7LmrKvtrW9h4sJ5dlY3sqmykriXA5Wfn8onzxpDs8/L1VU4wfmzqSDaXNVDT1M6UUcNYXDSW684fw8iMZI62BXhuUwVrNlaQnpzAOXkZFAxP5eE39lBS1cSnZuVTWt3E5rIGPnFeHokJHv73vXJyhiURCIVpD4ZYtnAaDa0BfvLyLi6dksuNF4/jX/6wlaNtAa6flc+OQ0fZXN7QGch5mcmMykhmT3UTR9uc85LgEWaNy+KiCcPxeoSmdueF/zMXFjBrXDbglNJufayYv+52Bkdkpvi4ee54iiLbCFDfGqCivpWyulYyU3xcMW0k08dkEgiHeXHrYVauO8CWcueFzuMR2oPhbi/gSQkeLpownLNGDqO0uomt5Q00tAZYXDSWb1w5hVGRTsuuykaeeb+cF7ceZk9NM0Dnv/XbrphMVqqPfbUtvFVaw3+9UsLho218/Lw81pXWEgwrP7/pQuZOGpjP7izoe3r4ckDh1tcG93FOQVN7kO8/v53GtiA3XDSWeZO6v9Vsag+yp7qJPdXNVDW24Q+G8YeccN9x6CgfHG7s7Bl2SPA4pQGn9xyisT1IdWM7jW1BxmQms3BGHlvKG1i/70jnf8b0pASSfB5qmvwkJni4YupIDjW0sTHSYwRYOnscy689p8+a5f7aZh54ZTfPvF9OWOHsUel848opXH3uKIJhpbyuleqmdpITvKQkekn0emj2BznaGqCuxU9pdTOlVU0cPtrGF+ZOYMH0E9dn//e9Mu58egseDyy5aBxf/uhERmcks/NwIxsO1HG0NUDOsERGpCVx9uh0xg5PPYmz9OEQDIX5j7/s4uE39vCRSTn8/SWFzD8rJ6Z3bu3BEP/1SgkPvV5KZoqPez85nWtmOD3OTQfr+cELO1DgvutnMDHXeTew6t0D/MsftnSe6weWzmTqaGeQQ32Ln/21LUzISSMzxXkhU1UOH22jvK6VqXkZ3V74+tIWCHH/n3eSn5XCDReNJS2GbY5HValrcV4c/KEw547JICnB2+3+9mC4z3/jqsquyibeLq1h3lk5TB517HdwmtuDPLi2hF/9dS9jspJ55IsXdT5nA8GCPlpn2eZumP/Pg/c4J/D6rmrK6loIh50e4ayx2UzPz0BEKK9v5ZZH17O7qon05ATqWwKMG57KOXkZHGpopby+lZqmXsbl47zdn5aXwbS8DCblpuHzevCIEAiHKa9r5WBdK1VH20j2eRmWlEBmqo+rzhnFJZNzO3v7hxva+MuOSqoa22lsC9DUFuS8sVlcd96Yzl5maXUTf9pyiMmj0mP+YGxPdRMV9W18ZNKIk6qP9teB2hbSkryD8uHWh5Gq9rss12F/bTOZKT6yUk8wuizitZ1VbDrYwD9cOnFAP7R0g6qjbaQlJZzyi1NPFvTR3nwAXr4LbtvUfQz7afSbN/dy93Pbj1k+dXQ6H5+Rx2/f3k97IMR/f+4CLi4czp+3HY6UEtrIz0qhIDuFguxUJuUOY1JuGnlZKSQleDo/vDLGxB+b1CzajudgzKwhC/k/bTnEPX/czlXnjOLeT07H4xGCIeWVDyp5Yv1BfvzyLsYOT2HVly/ufPu3aGZ+txEGxhjTH/EX9PUHYMqCIXnod/ce4bbHN3LBuGz+c+msbm9pP3fxeD538XgOHmlhxLDEY4a0GWPMyYq/NGlvPPnJynpQVd4ureWRN/fxzt5arpg6khsvHs9FE7K7lVAONbTyu3X7+Z+39lOQncKvvlDUZ93SzR8KGmOGRnwFfSjoXB4uqf/T8AZDYX7xxh7+uPkQyT4Pw5ISqDzaxq7KJoanJXLZ2SN5ZUcVz2ysYPyIVAqyU0hLTMAfCvPX3TWoKldMG8Xya88hOy22D7SMMWYgxFfQd0wH3M8e/e7KRu54chObyxqYPWE4ST4PTe1BslIS+eGnz+O6mc545RZ/kD9uPsSftx6mvjVAbVML/lCYv59fyE1zxltv3RgzJOIr6NsjQX+CC2s0tAZ4ZUclpZFx6q98UEVaopcHb7yAj5/X97fWUhMTWFw0lsVFYwey1cYYc0riK+jbjjq/j9OjD4WVL/z6HTaVOV9tHj88lUXnj+H/LZhKbrqNxzbGfPjEV9C3n7h089jb+9hU1sB918/g+gsKOr9qbowxH1ZxGvS9l24ON7Txo5d2ccnkHG64aKx9+cgY4wrx1V1tP37p5u7nthEIhbn3k9Mt5I0xrhFnQd936eaVHZX8aethvn7FZMaPSDvNDTPGmMETZ0Hf0aPvXrppag/yvWe2MmXUML58iV2IxBjjLnFYoxdI7N5j/+GLH3DoaBtP3fgR+/DVGOM68ZVq7Y1Obz6q/l687wiPrdvPzXMncOH47CFsnDHGDI44DPqu+nx70LkE2pjMFL519dlD2DBjjBk8cVa6Odot6H+2tpTS6mZ++3ezB/wiAMYYc6aIvx591PQHazZVcOmUXC6dkjuEjTLGmMEVX0Hf1tWjbw+G2F/bzPkFmUPcKGOMGVwxBb2ILBCRnSJSIiJ39nL/OBFZKyLvi8hmEbkm6r5lke12isjVA9n4fouq0e+taSasMGnkwF2c1xhjzkQnLEyLiBd4ELgSKAPWi8gaVY2+6Ol3gSdU9SEROQd4AZgQ+XsJcC4wBviLiExR1dBAH0hMooK+pKoJgMkjB+YiJMYYc6aKpUc/GyhR1T2q6gdWA4t6rKNAR/E7E6iI/L0IWK2q7aq6FyiJ7G9odAyvxAl6EZiYa9+CNca4WyxBnw8cjLpdFlkWbQVwk4iU4fTmv9aPbRGRW0WkWESKq6urY2x6P4VDEGju1qMfm53a5yX9jDHGLWIJ+t5m99Iet5cCj6pqAXAN8JiIeGLcFlV9WFWLVLUoN3eQRsD0mP6gpKqJs6w+b4yJA7EEfRkQfcmkArpKMx1uAZ4AUNW3gWQgJ8ZtT4+oCc1CYWVPTbMFvTEmLsQS9OuBySJSKCKJOB+urumxzgHgCgARmYYT9NWR9ZaISJKIFAKTgXcHqvH9EhX0ZXUt+INhzsq1oDfGuN8JR92oalBEvgr8GfACj6jqNhG5ByhW1TXAHcAvReQbOKWZL6qqAttE5AlgOxAEvjKkI24AktLZXemMuLGhlcaYeBDT9/5V9QWcD1mjl90V9fd2YF4f234f+P4ptHFgRF1dqqTcCXor3Rhj4kH8fDO2rcH5nZROSVUTI9OTyEzxDW2bjDHmNIifoO/o0Sdn2IgbY0xcibug18RhlFrQG2PiSJwFvVDVnkBje9CC3hgTN+Ir6JPS2V3VAmBDK40xcSPugr6kyinhWI/eGBMv4ijoG5yhldVNZCQnkJueNNQtMsaY0yKOgr6xc2jlWSOHIdLbNDzGGOM+cRf0+2paKMyxso0xJn7EVdCHEtOpbGyjIDtlqFtjjDGnTVwFfaukogr5WRb0xpj4ET9B33aURk0GIN969MaYOBIfQR+5ulRdyAn4MdajN8bEkfgI+sj0B7XBRADyMpOHsjXGGHNaxVXQV/kTyRmWZNeJNcbElbgK+opWH/lZ1ps3xsSXuAr6shav1eeNMXEnToL+KAD7mxIs6I0xcSeugr4mmGRj6I0xcSdOgt4p3TRpivXojTFxJ76CnhTr0Rtj4k5cBX0zyfatWGNM3ImPoG87SrsnlSRfAtmpvqFujTHGnFbxEfTtjbR40hiTlWLz0Btj4k6cBP1RGtXq88aY+BQnQd9IfSjZgt4YE5fiIujDbUepDyXZ0EpjTFyKi6APtjbQiI2hN8bEJ3cHvSpU70JaamnSVCvdGGPiUsJQN2DAtDXAU7d03Q4H4fAWaKnBB5RqHnMt6I0xcSimoBeRBcADgBf4lare1+P+/wAuj9xMBUaqalbkvhCwJXLfAVW9biAafgwNQ0ttdKNg8pUwbi6PluXxy3V+7shMGpSHNsaYM9kJg15EvMCDwJVAGbBeRNao6vaOdVT1G1Hrfw2YFbWLVlWdOXBN7kNKNty6tte7tu3ZRO6wapIS7IIjxpj4E0uNfjZQoqp7VNUPrAYWHWf9pcCqgWjcQKloaLWpD4wxcSuWoM8HDkbdLossO4aIjAcKgVejFieLSLGIrBORT/ax3a2RdYqrq6tjbHrsyutabcSNMSZuxRL0vc0ZoH2suwR4SlVDUcvGqWoRcCPwUxGZdMzOVB9W1SJVLcrNzY2hSbFraA1wsK6ViTlpA7pfY4z5sIgl6MuAsVG3C4CKPtZdQo+yjapWRH7vAV6je/1+0P11dzWhsHLplIF9ATHGmA+LWIJ+PTBZRApFJBEnzNf0XElEzgaygbejlmWLSFLk7xxgHrC957aD6dUPqshK9TFrXPbpfFhjjDljnHDUjaoGReSrwJ9xhlc+oqrbROQeoFhVO0J/KbBaVaPLOtOAX4hIGOdF5b7o0TqDLRxWXt9ZzaVTcvF6bNZKY0x8imkcvaq+ALzQY9ldPW6v6GW7t4AZp9C+U7KprJ7aZj8fmzpyqJpgjDFDztVTIKz9oAqPYPV5Y0xcc3XQv7qzigvHZ5OVmjjUTTHGmCHj2qCvOtrG1vKjXG5lG2NMnHNt0K/dWQVg9XljTNxzbdC/+kEVYzKTOXtU+lA3xRhjhpQrgz4cVv62u4bLpo60i4EbY+KeK4PeHwrT7A9RYBOZGWOMO4O+PRgGINHrysMzxph+cWUS+iNBn5TgysMzxph+cWUS+kORHr0FvTHGuDTogxb0xhjTwZVJ2Bn0Xrt0oDHGuDvorUdvjDEuDfqQc4ErC3pjjHFp0NvwSmOM6eLKJLTSjTHGdHFlEto4emOM6eLKJLRx9MYY08WVSWg9emOM6eLKJGy3Gr0xxnRyZRL6bdSNMcZ0cmUS2qgbY4zp4soktA9jjTGmiyuT0L4wZYwxXVyZhP5gmESvxy4jaIwxuDnorWxjjDGAW4M+FLKgN8aYCFemYUfpxhhjjJuD3nr0xhgDuDXoQxb0xhjTwZVpaKUbY4zpElMaisgCEdkpIiUicmcv9/+HiGyM/OwSkfqo+24Wkd2Rn5sHsvF9abfSjTHGdEo40Qoi4gUeBK4EyoD1IrJGVbd3rKOq34ha/2vArMjfw4HlQBGgwIbItnUDehQ9tAfDNnOlMcZExJKGs4ESVd2jqn5gNbDoOOsvBVZF/r4aeFlVj0TC/WVgwak0OBb2YawxxnSJJQ3zgYNRt8siy44hIuOBQuDV/mwrIreKSLGIFFdXV8fS7uPyW4/eGGM6xZKGvc0joH2suwR4SlVD/dlWVR9W1SJVLcrNzY2hScdno26MMaZLLGlYBoyNul0AVPSx7hK6yjb93XbA2KgbY4zpEksargcmi0ihiCTihPmaniuJyNlANvB21OI/A1eJSLaIZANXRZYNKqvRG2NMlxOOulHVoIh8FSegvcAjqrpNRO4BilW1I/SXAqtVVaO2PSIi/4rzYgFwj6oeGdhDOJaVbowxpssJgx5AVV8AXuix7K4et1f0se0jwCMn2b6T4pRuvKfzIY0x5ozlym6vlW6MMaaL69JQVa10Y4wxUVyXhh3Xi7Vx9MYY43BdGvrterHGGNON69KwM+itR2+MMYAbgz5kQW+MMdFcl4btAavRG2NMNNelofXojTGmO9eloX0Ya4wx3bkuDdvtw1hjjOnGdWloo26MMaY716WhfWHKGGO6c10adtXobVIzY4wBNwe99eiNMQZwY9CHnKsYWtAbY4zDdWloPXpjjOnOdWlo4+iNMaY716WhjaM3xpjuXJeGNrzSGGO6c10adkxqZqUbY4xxuC4N/aEwPq/g8chQN8UYY84I7gv6YNh688YYE8V1iegP2oXBjTEmmusS0YLeGGO6c10i+kMW9MYYE811iWg1emOM6c51idgeDJOYYDNXGmNMB9cFvZVujDGmO9cloj8YIslKN8YY08l1iWijbowxpruYElFEFojIThEpEZE7+1hnsYhsF5FtIvL7qOUhEdkY+VkzUA3vi5VujDGmu4QTrSAiXuBB4EqgDFgvImtUdXvUOpOBZcA8Va0TkZFRu2hV1ZkD3O4+2agbY4zpLpZEnA2UqOoeVfUDq4FFPdb5MvCgqtYBqGrVwDYzdu1WujHGmG5iScR84GDU7bLIsmhTgCki8qaIrBORBVH3JYtIcWT5J3t7ABG5NbJOcXV1db8OoCd/MGxTFBtjTJQTlm6A3qaB1F72Mxm4DCgA/ioi01W1HhinqhUiMhF4VUS2qGppt52pPgw8DFBUVNRz3/1iH8YaY0x3sSRiGTA26nYBUNHLOs+qakBV9wI7cYIfVa2I/N4DvAbMOsU2H5cFvTHGdBdLIq4HJotIoYgkAkuAnqNnngEuBxCRHJxSzh4RyRaRpKjl84DtDKJ2G3VjjDHdnLB0o6pBEfkq8GfACzyiqttE5B6gWFXXRO67SkS2AyHgW6paKyIfAX4hImGcF5X7okfrDDRVdWr0NurGGGM6xVKjR1VfAF7oseyuqL8VuD3yE73OW8CMU29mbAIhp7xvPXpjjOniqkTsuDC4Bb0xxnRxVSL6g3ZhcGOM6clVidgZ9DZNsTHGdHJp0LvqsIwx5pS4KhH9oRBgQW+MMdFclYjtVqM3xphjuCoRO4Le5roxxpgurkpEq9EbY8yxXJWIfuvRG2PMMVyViNajN8aYY8U0BcKHhX0z1pjBFwgEKCsro62tbaibEpeSk5MpKCjA5/PFvI27gt5G3Rgz6MrKykhPT2fChAmI9Ha5CjNYVJXa2lrKysooLCyMeTtXJaKVbowZfG1tbYwYMcJCfgiICCNGjOj3uylXJWK7lW6MOS0s5IfOyTz3rkrEzlE3XpvrxhhjOrgy6K1Hb4x71dfX87Of/eyktr3mmmuor68fsLYsWrSIuU8f/EUAAA1XSURBVHPnHnedYcOGDdjjnSxXJaIFvTHudzJBr6qEw2FeeOEFsrKyBqwd7733HvX19ezdu3dA9jlY3DXqJhTC6xG8HqsfGnM63P3cNrZXHB3QfZ4zJoPl157b5/133nknpaWlzJw5kyuvvJLly5ezaNEi6urqCAQC3HvvvSxatIh9+/axcOFCLr/8ct5++22eeeYZLr30UoqLi2lqamLhwoXMnz+ft956i/z8fJ599llSUlL45S9/ycMPP4zf7+ess87iscceIzU19Zh2PP3001x77bWMGjWK1atXs2zZMgD27t3LjTfeSDAYZMGCBZ3rNzU19dnOBQsWMH/+fNatW8f555/Pl770JZYvX05VVRUrV65k9uzZp/Scuqrr6w+GbWilMS533333MWnSJDZu3Mj9999PcnIyf/jDH3jvvfdYu3Ytd9xxB87VTWHnzp184Qtf4P3332f8+PHd9rN7926+8pWvsG3bNrKysnj66acBuP7661m/fj2bNm1i2rRp/PrXv+61HatWrWLp0qUsXbqUVatWdS6/7bbb+Kd/+ifWr1/P6NGjO5cfr50lJSXcdtttbN68mQ8++IDf//73/O1vf+NHP/oRP/jBD075OXNVj749GLayjTGn0fF63qeLqvKd73yHN954A4/HQ3l5OZWVlQCMHz+eOXPm9LpdYWEhM2fOBODCCy9k3759AGzdupXvfve71NfX09TUxNVXX33MtpWVlZSUlDB//nxEhISEBLZu3cr06dN58803O180Pv/5z/Ptb3/7hO0sLCxkxgzn8trnnnsuV1xxBSLCjBkzOtt1KlyVin4LemPizsqVK6murmbDhg1s3LiRUaNGdY4zT0tL63O7pKSkzr+9Xi/BYBCAL37xi/z3f/83W7ZsYfny5b2OWX/88cepq6ujsLCQCRMmsG/fPlavXt15f29DII/Xzui2eDyeztsej6ezXafCValopRtj3C89PZ3GxsbO2w0NDYwcORKfz8fatWvZv3//Ke2/sbGRvLw8AoEAK1eu7HWdVatW8eKLL7Jv3z727dvHhg0bOoN+3rx5nX9Hbz/Q7ewPV6VieyhMks9Vh2SM6WHEiBHMmzeP6dOn861vfYvPfe5zFBcXU1RUxMqVK5k6deop7f9f//Vfufjii7nyyit73de+ffs4cOBAt5JQYWEhGRkZvPPOOzzwwAM8+OCDXHTRRTQ0NHSuM9Dt7A/p+DDgTFFUVKTFxcUnte2X/6eYg0daePGfPzrArTLGdNixYwfTpk0b6mbEtd7OgYhsUNWi3tZ3VffXHwzbXPTGGNODq1LRPow1xphjuSoV/SELemOM6clVqWijbowx5liuSkUr3RhjzLFclYpO6camKDbGmGjuCnor3RjjeqcyTTHAT3/6U1paWvq8v7q6Gp/Pxy9+8Ys+13n00Uf56le/etJtON1iSkURWSAiO0WkRETu7GOdxSKyXUS2icjvo5bfLCK7Iz83D1TDe2Nz3RjjfoMd9E8++SRz5szpNlHZh90JJzUTES/wIHAlUAasF5E1qro9ap3JwDJgnqrWicjIyPLhwHKgCFBgQ2TbuoE/FPAHQzaO3pjT6U93wuEtA7vP0TNg4X193t1zmuL777+f+++/nyeeeIL29nY+9alPcffdd9Pc3MzixYspKysjFArxve99j8rKSioqKrj88svJyclh7dq1x+x/1apV/PjHP+bGG2+kvLyc/Px8AH7zm9/wb//2b+Tl5TFlypTO+Wiee+457r33Xvx+PyNGjGDlypWMGjWKFStWsHfvXg4dOsSuXbv4yU9+wrp16/jTn/5Efn4+zz33HD6fb2Cfuz7EkoqzgRJV3aOqfmA1sKjHOl8GHuwIcFWtiiy/GnhZVY9E7nsZWMAgsR69Me7Xc5ril156id27d/Puu++yceNGNmzYwBtvvMGLL77ImDFj2LRpE1u3bmXBggV8/etfZ8yYMaxdu7bXkD948CCHDx9m9uzZLF68mMcffxyAQ4cOsXz5ct58801efvlltm/v7Od2ziP//vvvs2TJEn74wx923ldaWsrzzz/Ps88+y0033cTll1/Oli1bSElJ4fnnnx/8JysilmmK84GDUbfLgIt7rDMFQETeBLzAClV9sY9t83s+gIjcCtwKMG7cuFjb3o2qOh/GWo3emNPnOD3v0+Wll17ipZdeYtasWYBzgY/du3dzySWX8M1vfpNvf/vbfOITn+CSSy454b5Wr17N4sWLAViyZAm33HILt99+O++88w6XXXYZubm5ANxwww3s2rULgLKyMm644QYOHTqE3++nsLCwc38LFy7E5/MxY8YMQqFQ54VIBmr64VjFEvS9Xa6p5wQ5CcBk4DKgAPiriEyPcVtU9WHgYXDmuomhTccIhhVVu4ygMfFGVVm2bBn/8A//cMx9GzZs4IUXXmDZsmVcddVV3HXXXcfd16pVq6isrOycdbKiooLdu3cDvU89DPC1r32N22+/neuuu47XXnuNFStWdN4XPd2wz+fr3MdATT8cq1hSsQwYG3W7AKjoZZ1nVTWgqnuBnTjBH8u2A6LjerFWozfG3XpOU3z11VfzyCOP0NTUBEB5eTlVVVVUVFSQmprKTTfdxDe/+U3ee++9XrfvsHPnTpqbmykvL++cfnjZsmWsXr2aiy++mNdee43a2loCgQBPPvlk53YNDQ2ddfzf/va3g3noJy2WHv16YLKIFALlwBLgxh7rPAMsBR4VkRycUs4eoBT4gYhkR9a7CudD2wFnFwY3Jj5ET1O8cOFC7r//fnbs2MHcuXMBGDZsGL/73e8oKSnhW9/6Vmdv+qGHHgLg1ltvZeHCheTl5XWr069atYpPfepT3R7r05/+NEuWLOF73/seK1asYO7cueTl5XHBBRcQCoUAWLFiBZ/97GfJz89nzpw5Z+SFwmOaplhErgF+ilN/f0RVvy8i9wDFqrpGnPcjP8b5oDUEfF9VV0e2/TvgO5FdfV9Vf3O8xzrZaYobWgN85w9bWFw0lkun5PZ7e2NMbGya4qHX32mKXTUfvTFm8FnQD724no/eGGPMsSzojTH9dqZVAuLJyTz3FvTGmH5JTk6mtrbWwn4IqCq1tbUkJyf3a7tYRt0YY0yngoICysrKqK6uHuqmxKXk5GQKCgr6tY0FvTGmX3w+X7dvf5ozn5VujDHG5SzojTHG5SzojTHG5c64L0yJSDWw/xR2kQPUDFBzPizi8ZghPo87Ho8Z4vO4+3vM41W112kBzrigP1UiUtzXt8PcKh6PGeLzuOPxmCE+j3sgj9lKN8YY43IW9MYY43JuDPqHh7oBQyAejxni87jj8ZghPo97wI7ZdTV6Y4wx3bmxR2+MMSaKBb0xxrica4JeRBaIyE4RKRGRO4e6PYNFRMaKyFoR2SEi20Tktsjy4SLysojsjvzOPtG+PmxExCsi74vIHyO3C0XkncgxPy4iiUPdxoEmIlki8pSIfBA553Pdfq5F5BuRf9tbRWSViCS78VyLyCMiUiUiW6OW9XpuxfGfkXzbLCIX9OexXBH0IuIFHgQWAucAS0XknKFt1aAJAneo6jRgDvCVyLHeCbyiqpOBVyK33eY2YEfU7X8H/iNyzHXALUPSqsH1APCiqk4Fzsc5fteeaxHJB74OFKnqdJzLly7Bnef6UZzLr0br69wuBCZHfm4FHurPA7ki6IHZQImq7lFVP7AaWDTEbRoUqnpIVd+L/N2I8x8/H+d4Oy5B/1vgk0PTwsEhIgXAx4FfRW4L8DHgqcgqbjzmDOCjwK8BVNWvqvW4/FzjzKqbIiIJQCpwCBeea1V9AzjSY3Ff53YR8D/qWAdkiUherI/llqDPBw5G3S6LLHM1EZkAzALeAUap6iFwXgyAkUPXskHxU+D/AeHI7RFAvaoGI7fdeM4nAtXAbyIlq1+JSBouPteqWg78CDiAE/ANwAbcf6479HVuTynj3BL00ssyV48bFZFhwNPAP6vq0aFuz2ASkU8AVaq6IXpxL6u67ZwnABcAD6nqLKAZF5VpehOpSS8CCoExQBpO2aInt53rEzmlf+9uCfoyYGzU7QKgYojaMuhExIcT8itV9X8jiys73spFflcNVfsGwTzgOhHZh1OW+xhODz8r8vYe3HnOy4AyVX0ncvspnOB387n+P8BeVa1W1QDwv8BHcP+57tDXuT2ljHNL0K8HJkc+mU/E+fBmzRC3aVBEatO/Bnao6k+i7loD3Bz5+2bg2dPdtsGiqstUtUBVJ+Cc21dV9XPAWuAzkdVcdcwAqnoYOCgiZ0cWXQFsx8XnGqdkM0dEUiP/1juO2dXnOkpf53YN8IXI6Js5QENHiScmquqKH+AaYBdQCvzLULdnEI9zPs5bts3AxsjPNTg161eA3ZHfw4e6rYN0/JcBf4z8PRF4FygBngSShrp9g3C8M4HiyPl+Bsh2+7kG7gY+ALYCjwFJbjzXwCqczyECOD32W/o6tzilmwcj+bYFZ1RSzI9lUyAYY4zLuaV0Y4wxpg8W9MYY43IW9MYY43IW9MYY43IW9MYY43IW9MYY43IW9MYY43L/H60wXOGrZZRAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do do modelu \n",
    "```python\n",
    "model.add(Dropout(0.8))\n",
    "```\n",
    "po każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5660 - val_loss: 0.6709 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.7139 - accuracy: 0.3962 - val_loss: 0.7082 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.6502 - accuracy: 0.5472 - val_loss: 0.6445 - val_accuracy: 0.7234\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.6412 - accuracy: 0.6981 - val_loss: 0.6156 - val_accuracy: 0.7447\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.5896 - accuracy: 0.8679 - val_loss: 0.6071 - val_accuracy: 0.7234\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 307us/step - loss: 0.5594 - accuracy: 0.7925 - val_loss: 0.6047 - val_accuracy: 0.7660\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.5359 - accuracy: 0.7736 - val_loss: 0.5546 - val_accuracy: 0.7660\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 692us/step - loss: 0.4880 - accuracy: 0.8113 - val_loss: 0.5149 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.4530 - accuracy: 0.8113 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 343us/step - loss: 0.4214 - accuracy: 0.8302 - val_loss: 0.5066 - val_accuracy: 0.7660\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3916 - accuracy: 0.8491 - val_loss: 0.4883 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3588 - accuracy: 0.8491 - val_loss: 0.4813 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3372 - accuracy: 0.8491 - val_loss: 0.4880 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3286 - accuracy: 0.8491 - val_loss: 0.4974 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3210 - accuracy: 0.8491 - val_loss: 0.5088 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3101 - accuracy: 0.8679 - val_loss: 0.5273 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2997 - accuracy: 0.8679 - val_loss: 0.5382 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2946 - accuracy: 0.8679 - val_loss: 0.5421 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2903 - accuracy: 0.8679 - val_loss: 0.5349 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 0.2728 - accuracy: 0.8679 - val_loss: 0.5011 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.4666 - val_accuracy: 0.8298\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2646 - accuracy: 0.8868 - val_loss: 0.4487 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2642 - accuracy: 0.8868 - val_loss: 0.4556 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2467 - accuracy: 0.8868 - val_loss: 0.4555 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2418 - accuracy: 0.9057 - val_loss: 0.4695 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2402 - accuracy: 0.9057 - val_loss: 0.4872 - val_accuracy: 0.8298\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2410 - accuracy: 0.9057 - val_loss: 0.4863 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2367 - accuracy: 0.9057 - val_loss: 0.4677 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2310 - accuracy: 0.8868 - val_loss: 0.4485 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2361 - accuracy: 0.9057 - val_loss: 0.4436 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.4669 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2256 - accuracy: 0.8868 - val_loss: 0.4905 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 751us/step - loss: 0.2218 - accuracy: 0.9057 - val_loss: 0.4892 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2175 - accuracy: 0.9057 - val_loss: 0.4910 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2157 - accuracy: 0.9057 - val_loss: 0.4887 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.2149 - accuracy: 0.8868 - val_loss: 0.4783 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.2114 - accuracy: 0.8868 - val_loss: 0.4790 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.2095 - accuracy: 0.8868 - val_loss: 0.4740 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2077 - accuracy: 0.8868 - val_loss: 0.4778 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2060 - accuracy: 0.8868 - val_loss: 0.4780 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2058 - accuracy: 0.9057 - val_loss: 0.4709 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2027 - accuracy: 0.8868 - val_loss: 0.4763 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1997 - accuracy: 0.9057 - val_loss: 0.4868 - val_accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1997 - accuracy: 0.9057 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2005 - accuracy: 0.9057 - val_loss: 0.4905 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1976 - accuracy: 0.9057 - val_loss: 0.4671 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1934 - accuracy: 0.9057 - val_loss: 0.4561 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1949 - accuracy: 0.9057 - val_loss: 0.4421 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1942 - accuracy: 0.9057 - val_loss: 0.4501 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1890 - accuracy: 0.9245 - val_loss: 0.4562 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.4664 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1847 - accuracy: 0.9057 - val_loss: 0.4861 - val_accuracy: 0.8085\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1874 - accuracy: 0.9434 - val_loss: 0.4975 - val_accuracy: 0.8085\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1880 - accuracy: 0.9434 - val_loss: 0.4833 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1825 - accuracy: 0.9245 - val_loss: 0.4753 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.4608 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1818 - accuracy: 0.9245 - val_loss: 0.4382 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1855 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1847 - accuracy: 0.9245 - val_loss: 0.4647 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1782 - accuracy: 0.9245 - val_loss: 0.4749 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1731 - accuracy: 0.9434 - val_loss: 0.4601 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1701 - accuracy: 0.9434 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1703 - accuracy: 0.9245 - val_loss: 0.4209 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1692 - accuracy: 0.9245 - val_loss: 0.4244 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1679 - accuracy: 0.9245 - val_loss: 0.4249 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1640 - accuracy: 0.9434 - val_loss: 0.4132 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1650 - accuracy: 0.9434 - val_loss: 0.4085 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1649 - accuracy: 0.9434 - val_loss: 0.3938 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1642 - accuracy: 0.9245 - val_loss: 0.3991 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1585 - accuracy: 0.9434 - val_loss: 0.4306 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1594 - accuracy: 0.9811 - val_loss: 0.4427 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1568 - accuracy: 0.9811 - val_loss: 0.4257 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1542 - accuracy: 0.9623 - val_loss: 0.4012 - val_accuracy: 0.8511\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1501 - accuracy: 0.9245 - val_loss: 0.3946 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1501 - accuracy: 0.9245 - val_loss: 0.3983 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1520 - accuracy: 0.9434 - val_loss: 0.4185 - val_accuracy: 0.8298\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1433 - accuracy: 0.9623 - val_loss: 0.4168 - val_accuracy: 0.8298\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1431 - accuracy: 0.9623 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1442 - accuracy: 0.9623 - val_loss: 0.3901 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.3932 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1352 - accuracy: 0.9623 - val_loss: 0.4091 - val_accuracy: 0.8723\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1357 - accuracy: 0.9811 - val_loss: 0.4125 - val_accuracy: 0.8511\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1320 - accuracy: 0.9811 - val_loss: 0.3911 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1279 - accuracy: 0.9623 - val_loss: 0.3733 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1309 - accuracy: 0.9623 - val_loss: 0.3575 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1285 - accuracy: 0.9623 - val_loss: 0.3694 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1234 - accuracy: 0.9623 - val_loss: 0.3669 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1190 - accuracy: 0.9811 - val_loss: 0.3748 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1193 - accuracy: 0.9811 - val_loss: 0.3851 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1196 - accuracy: 0.9811 - val_loss: 0.3628 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1138 - accuracy: 0.9811 - val_loss: 0.3434 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1103 - accuracy: 0.9811 - val_loss: 0.3236 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1075 - accuracy: 0.9811 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1065 - accuracy: 0.9811 - val_loss: 0.3062 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.1037 - accuracy: 0.9811 - val_loss: 0.2998 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1004 - accuracy: 0.9811 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0953 - accuracy: 0.9811 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0936 - accuracy: 0.9811 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0898 - accuracy: 0.9811 - val_loss: 0.2777 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0887 - accuracy: 0.9811 - val_loss: 0.2565 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0864 - accuracy: 0.9811 - val_loss: 0.2498 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0831 - accuracy: 0.9811 - val_loss: 0.2522 - val_accuracy: 0.8936\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0791 - accuracy: 0.9811 - val_loss: 0.2653 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0807 - accuracy: 0.9811 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0780 - accuracy: 0.9811 - val_loss: 0.2509 - val_accuracy: 0.8936\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 0.0720 - accuracy: 0.9811 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0706 - accuracy: 0.9811 - val_loss: 0.2194 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0697 - accuracy: 0.9811 - val_loss: 0.2157 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.96 - 0s 510us/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0634 - accuracy: 0.9811 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 397us/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0472 - accuracy: 0.9811 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0425 - accuracy: 0.9811 - val_loss: 0.2084 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 732us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9362\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9149\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 486us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9362\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9149\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9149\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9149\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 384us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9149\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9149\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9149\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9149\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9362\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9149\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9149\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 674us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 510us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 534us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 485us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 742us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 473us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 587us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 397us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 295us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 315us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 247us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 737us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 465us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 557us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 448us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 507us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 447us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 754us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 328us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 532us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 286us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 8.7944e-04 - accuracy: 1.00 - 0s 295us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 805us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.9960e-04 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8571e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8943e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.8706e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 9.6970e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.5447e-04 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.6565e-04 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 9.7161e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 9.2803e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.3436e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 9.7484e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 510us/step - loss: 9.3502e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 9.1319e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 9.1184e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 9.1946e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.3781e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0889e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 9.3812e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.8627e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 9.0914e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.7748e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7298e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.6785e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 8.8733e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 8.5873e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.5609e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 8.7141e-04 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 8.4705e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 8.5990e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 8.5121e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.3893e-04 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.7774e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.4253e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 7.3765e-04 - accuracy: 1.00 - 0s 510us/step - loss: 8.8682e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2285e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.6128e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2567e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.4942e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.2893e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.0047e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.9346e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.0067e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9443e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.9252e-04 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 7.9930e-04 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 8.4386e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 7.9923e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 8.2327e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.6456e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.6376e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.6493e-04 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.7398e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.4788e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.4420e-04 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.5446e-04 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.6789e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 7.6126e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.4630e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.4327e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.3272e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 7.1927e-04 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2175e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.1091e-04 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.1123e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2352e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.3595e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.3143e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.1648e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.8400e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 6.7314e-04 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.2385e-04 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 7.6885e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 7.1498e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.3717e-04 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.7602e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 7.0739e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.8077e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.6787e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 7.0308e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.7191e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.5998e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.6071e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 6.5650e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.6940e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.5475e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 6.3918e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 490us/step - loss: 6.3688e-04 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.4532e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3318e-04 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3406e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 6.4459e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 652us/step - loss: 6.2658e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 6.2335e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 487us/step - loss: 6.2904e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.1561e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.1239e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 754us/step - loss: 6.1495e-04 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 228us/step - loss: 6.2779e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 6.2555e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 6.2143e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.3030e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.9768e-04 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.0289e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.9137e-04 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.9070e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.2658e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 6.2248e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.9506e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.7761e-04 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.6628e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 5.9052e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 6.2084e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.9529e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 5.5963e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.6357e-04 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 6.2472e-04 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 6.0384e-04 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.8872e-04 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.6022e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 5.5059e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 5.5547e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.8528e-04 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.6470e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4401e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4032e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.7029e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 855us/step - loss: 5.5906e-04 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 416us/step - loss: 5.3668e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.5889e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.3463e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 5.2795e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 435us/step - loss: 5.3512e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.4637e-04 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 634us/step - loss: 5.3074e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.1127e-04 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 371us/step - loss: 5.5154e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 5.2329e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 5.2467e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 5.1716e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 795us/step - loss: 5.0800e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 5.0277e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 5.0116e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 801us/step - loss: 5.0174e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 5.0039e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.0395e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.9104e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.8998e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.8735e-04 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 4.9032e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 5.2587e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 5.0607e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.9102e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 5.0039e-04 - accuracy: 1.0000 - val_loss: 0.3153 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.8974e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.8871e-04 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.7170e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7858e-04 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6784e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6713e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6646e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6483e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6245e-04 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.7129e-04 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5719e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.6296e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5411e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5396e-04 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.5989e-04 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.6668e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.5497e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4511e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4438e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4807e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4752e-04 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.4435e-04 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.3817e-04 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 4.3495e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.3364e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.3262e-04 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 420us/step - loss: 4.3192e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.3079e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.3427e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2615e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2397e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 695us/step - loss: 4.2847e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 316us/step - loss: 4.2280e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2903e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2578e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.3524e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.2535e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.1658e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.1186e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.2920e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 4.1561e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 4.2040e-04 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 4.0515e-04 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 4.0317e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 4.0143e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.9946e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 723us/step - loss: 3.9867e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 4.0498e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 4.0893e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9449e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.9298e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9139e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.9891e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 461us/step - loss: 4.0041e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 3.8757e-04 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 3.9133e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.8443e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.8350e-04 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.9400e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8362e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.7994e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8043e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.9283e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.8587e-04 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 513us/step - loss: 3.7651e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 404us/step - loss: 3.7337e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 5.3739e-04 - accuracy: 1.00 - 0s 720us/step - loss: 3.7255e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.7868e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.7796e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.7371e-04 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6891e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6515e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.7596e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6375e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6631e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.7378e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 3.6422e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6966e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.6737e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6029e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.6509e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.5774e-04 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.5174e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.6336e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.5086e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5406e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4735e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5750e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5132e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 572us/step - loss: 3.4713e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.4240e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.4284e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.4991e-04 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.5167e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.4526e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.3988e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3536e-04 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 3.4735e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4309e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.3219e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.4250e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 3.3644e-04 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.3051e-04 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2624e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.2533e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2718e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.2877e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.3372e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2881e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.2870e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2014e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1798e-04 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1557e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2826e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 3.2356e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.1410e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 3.1167e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 675us/step - loss: 3.1042e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.2225e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.1313e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0958e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 4.4655e-04 - accuracy: 1.00 - 0s 491us/step - loss: 3.0659e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0519e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0454e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0432e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1007e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 3.0303e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0099e-04 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 3.1202e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0084e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 3.0495e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9802e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9730e-04 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 3.0142e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.9428e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.9373e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.9797e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9124e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.9428e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.9817e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8994e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9119e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.9724e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.8929e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8632e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8471e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8579e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8654e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8427e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.8227e-04 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7945e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8699e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8269e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 2.7755e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7601e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.7401e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7545e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 568us/step - loss: 2.7912e-04 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.8910e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.8191e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 2.7770e-04 - accuracy: 1.00 - 0s 491us/step - loss: 2.8758e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6977e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6907e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7090e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.6989e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.7929e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.6699e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.6565e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6281e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6207e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6826e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6327e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6506e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.6117e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5610e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.6253e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.5489e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.5404e-04 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5258e-04 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5226e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 2.5166e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 2.5546e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5127e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4903e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5767e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.5001e-04 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.5156e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4740e-04 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 2.4518e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 2.5291e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4568e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4658e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.4314e-04 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 2.4996e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 2.4534e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.4640e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4628e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.4235e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3823e-04 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3775e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3711e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3650e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.3507e-04 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3453e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3350e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3309e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3242e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3494e-04 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3702e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.3021e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3271e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.2798e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2725e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2680e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2600e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2850e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 2.2351e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 2.2533e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2723e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.2659e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 2.2657e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.3121e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 369us/step - loss: 2.2416e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2048e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.1899e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2651e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2106e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1848e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.2170e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1452e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1382e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 729us/step - loss: 2.1318e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 394us/step - loss: 2.1732e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.1156e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1107e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1463e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.1391e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0901e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0839e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 2.0786e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.1091e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0699e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0586e-04 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0559e-04 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0524e-04 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0765e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0578e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0363e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0873e-04 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0826e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0223e-04 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 2.0145e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 2.0440e-04 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 737us/step - loss: 2.0359e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.9944e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.9874e-04 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.9985e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 400us/step - loss: 1.9770e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9761e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9759e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9724e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 833us/step - loss: 1.9661e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 1.9918e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9712e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9909e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9427e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9516e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9240e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9217e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9329e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9502e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9423e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9367e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9284e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.9258e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.9098e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8922e-04 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 1.8773e-04 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8692e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8642e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8985e-04 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8569e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8519e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8394e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8362e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8613e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8719e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 672us/step - loss: 1.8423e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8606e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8358e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8032e-04 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.8080e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 1.8544e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7986e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.8139e-04 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7809e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.8198e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7691e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7903e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7596e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7562e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7526e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7480e-04 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7627e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7831e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7287e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7512e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7215e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7126e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7153e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7149e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.7104e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7200e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.7422e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6833e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6756e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.6727e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6632e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.6961e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 671us/step - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6871e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6412e-04 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6575e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6411e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6295e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6259e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 1.6911e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6743e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6430e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.5969e-04 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 472us/step - loss: 1.6591e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6103e-04 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 1.6077e-04 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.6095e-04 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 1.5899e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6fae1d4da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.9897 - accuracy: 0.4528 - val_loss: 0.7418 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.9950 - accuracy: 0.4717 - val_loss: 0.7347 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.8332 - accuracy: 0.5472 - val_loss: 0.7301 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.8709 - accuracy: 0.5472 - val_loss: 0.7127 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.9477 - accuracy: 0.4717 - val_loss: 0.6976 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.6766 - accuracy: 0.6415 - val_loss: 0.6836 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.7315 - accuracy: 0.5094 - val_loss: 0.6782 - val_accuracy: 0.5106\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.8481 - accuracy: 0.5472 - val_loss: 0.6762 - val_accuracy: 0.5106\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 318us/step - loss: 0.8545 - accuracy: 0.5094 - val_loss: 0.6761 - val_accuracy: 0.4681\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.7238 - accuracy: 0.6604 - val_loss: 0.6766 - val_accuracy: 0.4468\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.7778 - accuracy: 0.5660 - val_loss: 0.6777 - val_accuracy: 0.4468\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 1.0900 - accuracy: 0.4340 - val_loss: 0.6788 - val_accuracy: 0.4468\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.9844 - accuracy: 0.5660 - val_loss: 0.6820 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.7549 - accuracy: 0.5849 - val_loss: 0.6828 - val_accuracy: 0.4468\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.9162 - accuracy: 0.5472 - val_loss: 0.6797 - val_accuracy: 0.4468\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8701 - accuracy: 0.5472 - val_loss: 0.6806 - val_accuracy: 0.4468\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8573 - accuracy: 0.5283 - val_loss: 0.6696 - val_accuracy: 0.4468\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8857 - accuracy: 0.4528 - val_loss: 0.6579 - val_accuracy: 0.4681\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6849 - accuracy: 0.6038 - val_loss: 0.6429 - val_accuracy: 0.5745\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8416 - accuracy: 0.5094 - val_loss: 0.6284 - val_accuracy: 0.7447\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8626 - accuracy: 0.4906 - val_loss: 0.6166 - val_accuracy: 0.7447\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8759 - accuracy: 0.5283 - val_loss: 0.6043 - val_accuracy: 0.7872\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.7794 - accuracy: 0.5660 - val_loss: 0.5952 - val_accuracy: 0.7447\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6293 - accuracy: 0.6981 - val_loss: 0.5875 - val_accuracy: 0.7660\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.7485 - accuracy: 0.6226 - val_loss: 0.5809 - val_accuracy: 0.7447\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.8101 - accuracy: 0.4906 - val_loss: 0.5737 - val_accuracy: 0.7660\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6079 - accuracy: 0.6981 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6634 - accuracy: 0.6226 - val_loss: 0.5617 - val_accuracy: 0.7660\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.7192 - accuracy: 0.6038 - val_loss: 0.5572 - val_accuracy: 0.7872\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.6647 - accuracy: 0.6792 - val_loss: 0.5523 - val_accuracy: 0.7872\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5835 - accuracy: 0.6792 - val_loss: 0.5435 - val_accuracy: 0.7872\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.7519 - accuracy: 0.4906 - val_loss: 0.5350 - val_accuracy: 0.7660\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.6633 - accuracy: 0.6226 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4808 - accuracy: 0.6604 - val_loss: 0.5161 - val_accuracy: 0.7447\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.7398 - accuracy: 0.6038 - val_loss: 0.5079 - val_accuracy: 0.7660\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.7273 - accuracy: 0.6415 - val_loss: 0.5002 - val_accuracy: 0.7447\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.5552 - accuracy: 0.7736 - val_loss: 0.4937 - val_accuracy: 0.7447\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4855 - accuracy: 0.7547 - val_loss: 0.4886 - val_accuracy: 0.7447\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.6528 - accuracy: 0.6604 - val_loss: 0.4840 - val_accuracy: 0.7447\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.6343 - accuracy: 0.6226 - val_loss: 0.4816 - val_accuracy: 0.7447\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.5697 - accuracy: 0.6792 - val_loss: 0.4795 - val_accuracy: 0.7660\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3995 - accuracy: 0.8302 - val_loss: 0.4772 - val_accuracy: 0.7660\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5173 - accuracy: 0.6792 - val_loss: 0.4737 - val_accuracy: 0.7660\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.5327 - accuracy: 0.7925 - val_loss: 0.4720 - val_accuracy: 0.7660\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4738 - accuracy: 0.7170 - val_loss: 0.4704 - val_accuracy: 0.7660\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4184 - accuracy: 0.8679 - val_loss: 0.4706 - val_accuracy: 0.7660\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5552 - accuracy: 0.7170 - val_loss: 0.4706 - val_accuracy: 0.7660\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4275 - accuracy: 0.7358 - val_loss: 0.4723 - val_accuracy: 0.7660\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5171 - accuracy: 0.7547 - val_loss: 0.4704 - val_accuracy: 0.7660\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4649 - accuracy: 0.7358 - val_loss: 0.4695 - val_accuracy: 0.7447\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.5591 - accuracy: 0.7547 - val_loss: 0.4702 - val_accuracy: 0.7447\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4846 - accuracy: 0.7547 - val_loss: 0.4727 - val_accuracy: 0.7660\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3910 - accuracy: 0.8302 - val_loss: 0.4758 - val_accuracy: 0.7660\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4140 - accuracy: 0.8113 - val_loss: 0.4784 - val_accuracy: 0.7660\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3882 - accuracy: 0.8491 - val_loss: 0.4819 - val_accuracy: 0.7660\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3953 - accuracy: 0.8113 - val_loss: 0.4856 - val_accuracy: 0.7660\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4460 - accuracy: 0.7925 - val_loss: 0.4889 - val_accuracy: 0.7660\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4390 - accuracy: 0.7736 - val_loss: 0.4901 - val_accuracy: 0.7660\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3653 - accuracy: 0.8491 - val_loss: 0.4929 - val_accuracy: 0.7660\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4190 - accuracy: 0.8491 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4289 - accuracy: 0.8113 - val_loss: 0.4970 - val_accuracy: 0.7660\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4462 - accuracy: 0.7736 - val_loss: 0.5006 - val_accuracy: 0.7872\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3745 - accuracy: 0.8679 - val_loss: 0.5034 - val_accuracy: 0.7872\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.4255 - accuracy: 0.8679 - val_loss: 0.5074 - val_accuracy: 0.7872\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.5151 - accuracy: 0.8113 - val_loss: 0.5116 - val_accuracy: 0.7872\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.4174 - accuracy: 0.8113 - val_loss: 0.5147 - val_accuracy: 0.7872\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.3044 - accuracy: 0.8491 - val_loss: 0.5180 - val_accuracy: 0.7872\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 457us/step - loss: 0.4111 - accuracy: 0.8302 - val_loss: 0.5198 - val_accuracy: 0.7872\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3487 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7872\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3722 - accuracy: 0.8302 - val_loss: 0.5226 - val_accuracy: 0.7872\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3272 - accuracy: 0.8679 - val_loss: 0.5219 - val_accuracy: 0.7872\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.3694 - accuracy: 0.8302 - val_loss: 0.5201 - val_accuracy: 0.7872\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2850 - accuracy: 0.8679 - val_loss: 0.5182 - val_accuracy: 0.7872\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3987 - accuracy: 0.8302 - val_loss: 0.5151 - val_accuracy: 0.7872\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3362 - accuracy: 0.8868 - val_loss: 0.5114 - val_accuracy: 0.7872\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2963 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.7872\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3406 - accuracy: 0.8679 - val_loss: 0.5094 - val_accuracy: 0.7872\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3969 - accuracy: 0.9057 - val_loss: 0.5087 - val_accuracy: 0.7872\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.4745 - accuracy: 0.8302 - val_loss: 0.5061 - val_accuracy: 0.7872\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3143 - accuracy: 0.9057 - val_loss: 0.5034 - val_accuracy: 0.8085\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3753 - accuracy: 0.8113 - val_loss: 0.5006 - val_accuracy: 0.8085\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2643 - accuracy: 0.8679 - val_loss: 0.4995 - val_accuracy: 0.8085\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2997 - accuracy: 0.8868 - val_loss: 0.4991 - val_accuracy: 0.8085\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3815 - accuracy: 0.8679 - val_loss: 0.4992 - val_accuracy: 0.8085\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3342 - accuracy: 0.9057 - val_loss: 0.4995 - val_accuracy: 0.8085\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3477 - accuracy: 0.8491 - val_loss: 0.5001 - val_accuracy: 0.8085\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3834 - accuracy: 0.8679 - val_loss: 0.5015 - val_accuracy: 0.8085\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3284 - accuracy: 0.8679 - val_loss: 0.5049 - val_accuracy: 0.7872\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.5099 - val_accuracy: 0.7872\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3223 - accuracy: 0.8679 - val_loss: 0.5145 - val_accuracy: 0.7872\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3232 - accuracy: 0.8679 - val_loss: 0.5216 - val_accuracy: 0.7872\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 928us/step - loss: 0.2587 - accuracy: 0.8868 - val_loss: 0.5279 - val_accuracy: 0.7872\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.3410 - accuracy: 0.8679 - val_loss: 0.5299 - val_accuracy: 0.7872\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3142 - accuracy: 0.8868 - val_loss: 0.5289 - val_accuracy: 0.7872\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3000 - accuracy: 0.8491 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3163 - accuracy: 0.8679 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2937 - accuracy: 0.8679 - val_loss: 0.5293 - val_accuracy: 0.7872\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3369 - accuracy: 0.8679 - val_loss: 0.5296 - val_accuracy: 0.7872\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3578 - accuracy: 0.8302 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2698 - accuracy: 0.9057 - val_loss: 0.5255 - val_accuracy: 0.7872\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 623us/step - loss: 0.3068 - accuracy: 0.8679 - val_loss: 0.5224 - val_accuracy: 0.7872\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3077 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7872\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3517 - accuracy: 0.8491 - val_loss: 0.5133 - val_accuracy: 0.7872\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3029 - accuracy: 0.8868 - val_loss: 0.5108 - val_accuracy: 0.7872\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3076 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7872\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2959 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7872\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2669 - accuracy: 0.8491 - val_loss: 0.5139 - val_accuracy: 0.7872\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2985 - accuracy: 0.9057 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2749 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7872\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3182 - accuracy: 0.8679 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2654 - accuracy: 0.9245 - val_loss: 0.5158 - val_accuracy: 0.7872\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.4127 - accuracy: 0.8491 - val_loss: 0.5151 - val_accuracy: 0.7872\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2479 - accuracy: 0.8868 - val_loss: 0.5164 - val_accuracy: 0.7872\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2874 - accuracy: 0.8491 - val_loss: 0.5177 - val_accuracy: 0.7872\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2757 - accuracy: 0.8868 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3033 - accuracy: 0.8868 - val_loss: 0.5138 - val_accuracy: 0.7872\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2821 - accuracy: 0.8679 - val_loss: 0.5126 - val_accuracy: 0.7872\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2828 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.8085\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2791 - accuracy: 0.8491 - val_loss: 0.5105 - val_accuracy: 0.8085\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2928 - accuracy: 0.9057 - val_loss: 0.5124 - val_accuracy: 0.8085\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2488 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.8085\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2432 - accuracy: 0.8679 - val_loss: 0.5187 - val_accuracy: 0.7872\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3135 - accuracy: 0.8679 - val_loss: 0.5210 - val_accuracy: 0.7872\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3887 - accuracy: 0.8491 - val_loss: 0.5199 - val_accuracy: 0.7872\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.4848 - accuracy: 0.8679 - val_loss: 0.5209 - val_accuracy: 0.7872\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3703 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.7872\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3224 - accuracy: 0.8679 - val_loss: 0.5285 - val_accuracy: 0.7872\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3717 - accuracy: 0.8302 - val_loss: 0.5318 - val_accuracy: 0.7872\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2823 - accuracy: 0.9057 - val_loss: 0.5367 - val_accuracy: 0.7872\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3186 - accuracy: 0.8868 - val_loss: 0.5422 - val_accuracy: 0.7872\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2766 - accuracy: 0.9057 - val_loss: 0.5444 - val_accuracy: 0.7872\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2973 - accuracy: 0.9057 - val_loss: 0.5434 - val_accuracy: 0.7872\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3345 - accuracy: 0.8868 - val_loss: 0.5431 - val_accuracy: 0.7872\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.3724 - accuracy: 0.8679 - val_loss: 0.5379 - val_accuracy: 0.7872\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2695 - accuracy: 0.9057 - val_loss: 0.5308 - val_accuracy: 0.7872\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2573 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7872\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2699 - accuracy: 0.8868 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2874 - accuracy: 0.9057 - val_loss: 0.5099 - val_accuracy: 0.7872\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.5044 - val_accuracy: 0.7872\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2908 - accuracy: 0.8679 - val_loss: 0.5007 - val_accuracy: 0.8085\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3179 - accuracy: 0.8679 - val_loss: 0.5004 - val_accuracy: 0.8085\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 0.5005 - val_accuracy: 0.8085\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2704 - accuracy: 0.8868 - val_loss: 0.4984 - val_accuracy: 0.8085\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3317 - accuracy: 0.8491 - val_loss: 0.4968 - val_accuracy: 0.8085\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2278 - accuracy: 0.9245 - val_loss: 0.4948 - val_accuracy: 0.7872\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2827 - accuracy: 0.8491 - val_loss: 0.4946 - val_accuracy: 0.7872\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2728 - accuracy: 0.9057 - val_loss: 0.4953 - val_accuracy: 0.7872\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2897 - accuracy: 0.8868 - val_loss: 0.4976 - val_accuracy: 0.7872\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2943 - accuracy: 0.9057 - val_loss: 0.5002 - val_accuracy: 0.7872\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2958 - accuracy: 0.9245 - val_loss: 0.5037 - val_accuracy: 0.7872\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2575 - accuracy: 0.8868 - val_loss: 0.5077 - val_accuracy: 0.7872\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2632 - accuracy: 0.8679 - val_loss: 0.5110 - val_accuracy: 0.7872\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3288 - accuracy: 0.8679 - val_loss: 0.5158 - val_accuracy: 0.7872\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2536 - accuracy: 0.8679 - val_loss: 0.5193 - val_accuracy: 0.7872\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2707 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.8085\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2822 - accuracy: 0.8868 - val_loss: 0.5282 - val_accuracy: 0.8085\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2138 - accuracy: 0.9245 - val_loss: 0.5333 - val_accuracy: 0.8085\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3193 - accuracy: 0.8868 - val_loss: 0.5370 - val_accuracy: 0.8298\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3026 - accuracy: 0.9245 - val_loss: 0.5379 - val_accuracy: 0.8298\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2359 - accuracy: 0.8868 - val_loss: 0.5341 - val_accuracy: 0.8298\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2726 - accuracy: 0.8868 - val_loss: 0.5282 - val_accuracy: 0.8298\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2773 - accuracy: 0.8679 - val_loss: 0.5237 - val_accuracy: 0.8085\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 487us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5203 - val_accuracy: 0.8085\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2494 - accuracy: 0.9245 - val_loss: 0.5140 - val_accuracy: 0.8085\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2832 - accuracy: 0.8868 - val_loss: 0.5084 - val_accuracy: 0.8085\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2865 - accuracy: 0.9057 - val_loss: 0.5024 - val_accuracy: 0.7872\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2636 - accuracy: 0.9245 - val_loss: 0.4979 - val_accuracy: 0.7872\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3237 - accuracy: 0.8302 - val_loss: 0.4940 - val_accuracy: 0.8085\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3139 - accuracy: 0.8868 - val_loss: 0.4921 - val_accuracy: 0.8085\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3158 - accuracy: 0.8491 - val_loss: 0.4950 - val_accuracy: 0.7872\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2135 - accuracy: 0.9057 - val_loss: 0.4984 - val_accuracy: 0.7872\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3235 - accuracy: 0.8868 - val_loss: 0.5038 - val_accuracy: 0.8298\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2384 - accuracy: 0.8868 - val_loss: 0.5081 - val_accuracy: 0.8298\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2479 - accuracy: 0.8868 - val_loss: 0.5122 - val_accuracy: 0.8298\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1986 - accuracy: 0.9057 - val_loss: 0.5167 - val_accuracy: 0.8298\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2770 - accuracy: 0.9057 - val_loss: 0.5189 - val_accuracy: 0.8298\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2159 - accuracy: 0.9434 - val_loss: 0.5189 - val_accuracy: 0.8298\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2835 - accuracy: 0.8868 - val_loss: 0.5192 - val_accuracy: 0.8298\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2996 - accuracy: 0.9057 - val_loss: 0.5204 - val_accuracy: 0.8298\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2322 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.8298\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3049 - accuracy: 0.8302 - val_loss: 0.5239 - val_accuracy: 0.8298\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3272 - accuracy: 0.9057 - val_loss: 0.5257 - val_accuracy: 0.8298\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2440 - accuracy: 0.9245 - val_loss: 0.5209 - val_accuracy: 0.8298\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2550 - accuracy: 0.9434 - val_loss: 0.5156 - val_accuracy: 0.8298\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2263 - accuracy: 0.8868 - val_loss: 0.5091 - val_accuracy: 0.8298\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 679us/step - loss: 0.2894 - accuracy: 0.9057 - val_loss: 0.5023 - val_accuracy: 0.8298\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2769 - accuracy: 0.8868 - val_loss: 0.4954 - val_accuracy: 0.8085\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2469 - accuracy: 0.8679 - val_loss: 0.4923 - val_accuracy: 0.8085\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2336 - accuracy: 0.8868 - val_loss: 0.4901 - val_accuracy: 0.8085\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.4878 - val_accuracy: 0.8085\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2426 - accuracy: 0.8679 - val_loss: 0.4872 - val_accuracy: 0.8085\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2607 - accuracy: 0.9057 - val_loss: 0.4873 - val_accuracy: 0.8085\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2174 - accuracy: 0.9057 - val_loss: 0.4872 - val_accuracy: 0.8085\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2830 - accuracy: 0.9057 - val_loss: 0.4882 - val_accuracy: 0.8085\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2816 - accuracy: 0.8491 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2436 - accuracy: 0.9434 - val_loss: 0.4939 - val_accuracy: 0.8298\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2957 - accuracy: 0.8491 - val_loss: 0.4988 - val_accuracy: 0.8298\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2241 - accuracy: 0.8868 - val_loss: 0.5012 - val_accuracy: 0.8298\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2855 - accuracy: 0.8868 - val_loss: 0.5041 - val_accuracy: 0.8298\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.87 - 0s 548us/step - loss: 0.3720 - accuracy: 0.8491 - val_loss: 0.5079 - val_accuracy: 0.8298\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2375 - accuracy: 0.8868 - val_loss: 0.5095 - val_accuracy: 0.8298\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2415 - accuracy: 0.8679 - val_loss: 0.5074 - val_accuracy: 0.8298\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.84 - 0s 548us/step - loss: 0.2379 - accuracy: 0.8679 - val_loss: 0.5042 - val_accuracy: 0.8298\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2760 - accuracy: 0.9057 - val_loss: 0.4971 - val_accuracy: 0.8298\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2347 - accuracy: 0.9057 - val_loss: 0.4900 - val_accuracy: 0.8298\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2528 - accuracy: 0.9245 - val_loss: 0.4831 - val_accuracy: 0.8085\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2144 - accuracy: 0.9245 - val_loss: 0.4778 - val_accuracy: 0.8085\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2482 - accuracy: 0.8868 - val_loss: 0.4750 - val_accuracy: 0.8085\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1848 - accuracy: 0.9245 - val_loss: 0.4732 - val_accuracy: 0.8085\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2555 - accuracy: 0.9434 - val_loss: 0.4712 - val_accuracy: 0.8085\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2163 - accuracy: 0.9057 - val_loss: 0.4689 - val_accuracy: 0.8085\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 548us/step - loss: 0.2434 - accuracy: 0.9057 - val_loss: 0.4660 - val_accuracy: 0.8085\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2389 - accuracy: 0.9057 - val_loss: 0.4646 - val_accuracy: 0.8085\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2522 - accuracy: 0.8868 - val_loss: 0.4638 - val_accuracy: 0.8085\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2522 - accuracy: 0.8679 - val_loss: 0.4641 - val_accuracy: 0.8085\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.87 - 0s 548us/step - loss: 0.1871 - accuracy: 0.9057 - val_loss: 0.4634 - val_accuracy: 0.8085\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2612 - accuracy: 0.8679 - val_loss: 0.4641 - val_accuracy: 0.8085\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1947 - accuracy: 0.9245 - val_loss: 0.4657 - val_accuracy: 0.8085\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2067 - accuracy: 0.9245 - val_loss: 0.4680 - val_accuracy: 0.8085\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2380 - accuracy: 0.9057 - val_loss: 0.4704 - val_accuracy: 0.8085\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3159 - accuracy: 0.8679 - val_loss: 0.4735 - val_accuracy: 0.8085\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2379 - accuracy: 0.8868 - val_loss: 0.4748 - val_accuracy: 0.8085\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2383 - accuracy: 0.9245 - val_loss: 0.4759 - val_accuracy: 0.8085\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2363 - accuracy: 0.8868 - val_loss: 0.4772 - val_accuracy: 0.8085\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1814 - accuracy: 0.9434 - val_loss: 0.4779 - val_accuracy: 0.8085\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2562 - accuracy: 0.8868 - val_loss: 0.4813 - val_accuracy: 0.8085\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1971 - accuracy: 0.9623 - val_loss: 0.4818 - val_accuracy: 0.8085\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1855 - accuracy: 0.9623 - val_loss: 0.4830 - val_accuracy: 0.8085\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 542us/step - loss: 0.3259 - accuracy: 0.8868 - val_loss: 0.4854 - val_accuracy: 0.8085\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3278 - accuracy: 0.8491 - val_loss: 0.4859 - val_accuracy: 0.8085\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1710 - accuracy: 0.9434 - val_loss: 0.4872 - val_accuracy: 0.8085\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3408 - accuracy: 0.8679 - val_loss: 0.4877 - val_accuracy: 0.8085\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3031 - accuracy: 0.8868 - val_loss: 0.4850 - val_accuracy: 0.8085\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2376 - accuracy: 0.9057 - val_loss: 0.4823 - val_accuracy: 0.8085\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2219 - accuracy: 0.9245 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2339 - accuracy: 0.9057 - val_loss: 0.4816 - val_accuracy: 0.8085\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1951 - accuracy: 0.9057 - val_loss: 0.4814 - val_accuracy: 0.8085\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2355 - accuracy: 0.8868 - val_loss: 0.4814 - val_accuracy: 0.8085\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2910 - accuracy: 0.8868 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.4809 - val_accuracy: 0.8085\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2119 - accuracy: 0.9245 - val_loss: 0.4795 - val_accuracy: 0.8085\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2055 - accuracy: 0.9057 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2208 - accuracy: 0.9057 - val_loss: 0.4786 - val_accuracy: 0.8085\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2259 - accuracy: 0.8868 - val_loss: 0.4783 - val_accuracy: 0.8085\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2013 - accuracy: 0.9057 - val_loss: 0.4778 - val_accuracy: 0.8085\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2219 - accuracy: 0.8868 - val_loss: 0.4787 - val_accuracy: 0.8085\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2778 - accuracy: 0.9057 - val_loss: 0.4764 - val_accuracy: 0.8085\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2325 - accuracy: 0.9057 - val_loss: 0.4756 - val_accuracy: 0.8085\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 898us/step - loss: 0.1888 - accuracy: 0.9245 - val_loss: 0.4757 - val_accuracy: 0.8085\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 504us/step - loss: 0.1695 - accuracy: 0.9245 - val_loss: 0.4748 - val_accuracy: 0.8085\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.4735 - val_accuracy: 0.8085\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2088 - accuracy: 0.9434 - val_loss: 0.4722 - val_accuracy: 0.8085\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2391 - accuracy: 0.8868 - val_loss: 0.4713 - val_accuracy: 0.8085\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2023 - accuracy: 0.9057 - val_loss: 0.4709 - val_accuracy: 0.8085\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2298 - accuracy: 0.9057 - val_loss: 0.4680 - val_accuracy: 0.8085\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3353 - accuracy: 0.8679 - val_loss: 0.4664 - val_accuracy: 0.8085\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1884 - accuracy: 0.9434 - val_loss: 0.4638 - val_accuracy: 0.8085\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3606 - accuracy: 0.8679 - val_loss: 0.4620 - val_accuracy: 0.8085\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2600 - accuracy: 0.8491 - val_loss: 0.4590 - val_accuracy: 0.8085\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2143 - accuracy: 0.8868 - val_loss: 0.4577 - val_accuracy: 0.8085\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1754 - accuracy: 0.8868 - val_loss: 0.4572 - val_accuracy: 0.8085\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2475 - accuracy: 0.9057 - val_loss: 0.4564 - val_accuracy: 0.8085\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2414 - accuracy: 0.9434 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1785 - accuracy: 0.9434 - val_loss: 0.4556 - val_accuracy: 0.8085\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 0.4552 - val_accuracy: 0.8085\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1746 - accuracy: 0.9245 - val_loss: 0.4549 - val_accuracy: 0.8085\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1999 - accuracy: 0.9245 - val_loss: 0.4542 - val_accuracy: 0.8085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2149 - accuracy: 0.9057 - val_loss: 0.4545 - val_accuracy: 0.8085\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1930 - accuracy: 0.9057 - val_loss: 0.4559 - val_accuracy: 0.8085\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3012 - accuracy: 0.8679 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2456 - accuracy: 0.9057 - val_loss: 0.4582 - val_accuracy: 0.8085\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 634us/step - loss: 0.2324 - accuracy: 0.8679 - val_loss: 0.4619 - val_accuracy: 0.8085\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2372 - accuracy: 0.9057 - val_loss: 0.4661 - val_accuracy: 0.8085\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2845 - accuracy: 0.8868 - val_loss: 0.4688 - val_accuracy: 0.8298\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2563 - accuracy: 0.9057 - val_loss: 0.4690 - val_accuracy: 0.8298\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2149 - accuracy: 0.9057 - val_loss: 0.4694 - val_accuracy: 0.8298\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2099 - accuracy: 0.9057 - val_loss: 0.4700 - val_accuracy: 0.8298\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1907 - accuracy: 0.9057 - val_loss: 0.4701 - val_accuracy: 0.8298\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2077 - accuracy: 0.9057 - val_loss: 0.4680 - val_accuracy: 0.8298\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 779us/step - loss: 0.1886 - accuracy: 0.9623 - val_loss: 0.4651 - val_accuracy: 0.8298\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2610 - accuracy: 0.9434 - val_loss: 0.4633 - val_accuracy: 0.8298\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1804 - accuracy: 0.9245 - val_loss: 0.4615 - val_accuracy: 0.8085\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 345us/step - loss: 0.2265 - accuracy: 0.9245 - val_loss: 0.4602 - val_accuracy: 0.8085\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.4567 - val_accuracy: 0.8085\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2394 - accuracy: 0.9434 - val_loss: 0.4538 - val_accuracy: 0.8085\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 902us/step - loss: 0.2573 - accuracy: 0.8679 - val_loss: 0.4519 - val_accuracy: 0.8085\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.4512 - val_accuracy: 0.8085\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 609us/step - loss: 0.1992 - accuracy: 0.9245 - val_loss: 0.4505 - val_accuracy: 0.8085\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2736 - accuracy: 0.8868 - val_loss: 0.4482 - val_accuracy: 0.8085\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2588 - accuracy: 0.8491 - val_loss: 0.4471 - val_accuracy: 0.8085\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2310 - accuracy: 0.9245 - val_loss: 0.4450 - val_accuracy: 0.8085\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1986 - accuracy: 0.9057 - val_loss: 0.4442 - val_accuracy: 0.8085\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2104 - accuracy: 0.9057 - val_loss: 0.4429 - val_accuracy: 0.8085\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2476 - accuracy: 0.9057 - val_loss: 0.4418 - val_accuracy: 0.8085\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1714 - accuracy: 0.9057 - val_loss: 0.4404 - val_accuracy: 0.8085\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2134 - accuracy: 0.9245 - val_loss: 0.4376 - val_accuracy: 0.8085\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1839 - accuracy: 0.9245 - val_loss: 0.4369 - val_accuracy: 0.8085\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1630 - accuracy: 0.9623 - val_loss: 0.4367 - val_accuracy: 0.8085\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2013 - accuracy: 0.9245 - val_loss: 0.4366 - val_accuracy: 0.8085\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2811 - accuracy: 0.8868 - val_loss: 0.4366 - val_accuracy: 0.8085\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2796 - accuracy: 0.8868 - val_loss: 0.4347 - val_accuracy: 0.8085\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2183 - accuracy: 0.9057 - val_loss: 0.4352 - val_accuracy: 0.8085\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.1856 - accuracy: 0.9434 - val_loss: 0.4369 - val_accuracy: 0.8085\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1952 - accuracy: 0.9245 - val_loss: 0.4376 - val_accuracy: 0.8085\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2303 - accuracy: 0.9057 - val_loss: 0.4366 - val_accuracy: 0.8085\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1417 - accuracy: 0.9434 - val_loss: 0.4345 - val_accuracy: 0.8085\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1792 - accuracy: 0.9434 - val_loss: 0.4340 - val_accuracy: 0.8085\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 727us/step - loss: 0.2355 - accuracy: 0.9057 - val_loss: 0.4341 - val_accuracy: 0.8085\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1911 - accuracy: 0.8868 - val_loss: 0.4347 - val_accuracy: 0.8085\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1989 - accuracy: 0.9434 - val_loss: 0.4370 - val_accuracy: 0.8085\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2468 - accuracy: 0.9057 - val_loss: 0.4386 - val_accuracy: 0.8085\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.2186 - accuracy: 0.9057 - val_loss: 0.4411 - val_accuracy: 0.8085\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2125 - accuracy: 0.9245 - val_loss: 0.4422 - val_accuracy: 0.8085\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2224 - accuracy: 0.8868 - val_loss: 0.4423 - val_accuracy: 0.8085\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2225 - accuracy: 0.8868 - val_loss: 0.4430 - val_accuracy: 0.8085\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1794 - accuracy: 0.9434 - val_loss: 0.4437 - val_accuracy: 0.8085\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1547 - accuracy: 0.9434 - val_loss: 0.4449 - val_accuracy: 0.8085\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2255 - accuracy: 0.8868 - val_loss: 0.4454 - val_accuracy: 0.8085\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2459 - accuracy: 0.8868 - val_loss: 0.4442 - val_accuracy: 0.8085\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2310 - accuracy: 0.9057 - val_loss: 0.4450 - val_accuracy: 0.8085\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2330 - accuracy: 0.9245 - val_loss: 0.4451 - val_accuracy: 0.8085\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1527 - accuracy: 0.9623 - val_loss: 0.4443 - val_accuracy: 0.8085\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2054 - accuracy: 0.9057 - val_loss: 0.4436 - val_accuracy: 0.8085\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1786 - accuracy: 0.9434 - val_loss: 0.4412 - val_accuracy: 0.8085\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2231 - accuracy: 0.9434 - val_loss: 0.4376 - val_accuracy: 0.8085\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2333 - accuracy: 0.8868 - val_loss: 0.4366 - val_accuracy: 0.8085\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2124 - accuracy: 0.9623 - val_loss: 0.4361 - val_accuracy: 0.8085\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2615 - accuracy: 0.8679 - val_loss: 0.4364 - val_accuracy: 0.8085\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2443 - accuracy: 0.8868 - val_loss: 0.4356 - val_accuracy: 0.8085\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2101 - accuracy: 0.9434 - val_loss: 0.4383 - val_accuracy: 0.8085\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1841 - accuracy: 0.9434 - val_loss: 0.4390 - val_accuracy: 0.8085\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2163 - accuracy: 0.8868 - val_loss: 0.4400 - val_accuracy: 0.8085\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2514 - accuracy: 0.9245 - val_loss: 0.4408 - val_accuracy: 0.8085\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2199 - accuracy: 0.9057 - val_loss: 0.4412 - val_accuracy: 0.8085\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2465 - accuracy: 0.8868 - val_loss: 0.4417 - val_accuracy: 0.8298\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2456 - accuracy: 0.9245 - val_loss: 0.4404 - val_accuracy: 0.8085\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.1920 - accuracy: 0.8868 - val_loss: 0.4371 - val_accuracy: 0.8085\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.1570 - accuracy: 0.9434 - val_loss: 0.4350 - val_accuracy: 0.8085\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.2268 - accuracy: 0.8868 - val_loss: 0.4344 - val_accuracy: 0.8085\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2184 - accuracy: 0.9434 - val_loss: 0.4326 - val_accuracy: 0.8085\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 350us/step - loss: 0.1997 - accuracy: 0.9245 - val_loss: 0.4308 - val_accuracy: 0.8085\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2233 - accuracy: 0.9057 - val_loss: 0.4283 - val_accuracy: 0.8085\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1691 - accuracy: 0.9245 - val_loss: 0.4253 - val_accuracy: 0.8085\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1518 - accuracy: 0.9434 - val_loss: 0.4245 - val_accuracy: 0.8085\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2128 - accuracy: 0.9245 - val_loss: 0.4260 - val_accuracy: 0.8085\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2052 - accuracy: 0.9245 - val_loss: 0.4259 - val_accuracy: 0.8085\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1867 - accuracy: 0.9245 - val_loss: 0.4272 - val_accuracy: 0.8085\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1783 - accuracy: 0.9245 - val_loss: 0.4301 - val_accuracy: 0.8085\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2195 - accuracy: 0.9245 - val_loss: 0.4338 - val_accuracy: 0.8085\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2213 - accuracy: 0.9057 - val_loss: 0.4384 - val_accuracy: 0.8085\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1899 - accuracy: 0.9245 - val_loss: 0.4419 - val_accuracy: 0.8298\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2123 - accuracy: 0.9434 - val_loss: 0.4467 - val_accuracy: 0.8298\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2015 - accuracy: 0.9057 - val_loss: 0.4513 - val_accuracy: 0.8298\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1586 - accuracy: 0.9245 - val_loss: 0.4536 - val_accuracy: 0.8298\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2179 - accuracy: 0.9057 - val_loss: 0.4551 - val_accuracy: 0.8298\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1645 - accuracy: 0.9434 - val_loss: 0.4558 - val_accuracy: 0.8298\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1772 - accuracy: 0.9245 - val_loss: 0.4556 - val_accuracy: 0.8298\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2074 - accuracy: 0.9057 - val_loss: 0.4548 - val_accuracy: 0.8298\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1738 - accuracy: 0.9057 - val_loss: 0.4536 - val_accuracy: 0.8298\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1704 - accuracy: 0.9245 - val_loss: 0.4517 - val_accuracy: 0.8298\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1609 - accuracy: 0.9245 - val_loss: 0.4503 - val_accuracy: 0.8298\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1069 - accuracy: 0.9623 - val_loss: 0.4502 - val_accuracy: 0.8298\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2157 - accuracy: 0.9245 - val_loss: 0.4474 - val_accuracy: 0.8085\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2183 - accuracy: 0.9057 - val_loss: 0.4454 - val_accuracy: 0.8085\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1593 - accuracy: 0.9245 - val_loss: 0.4422 - val_accuracy: 0.8085\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 761us/step - loss: 0.1853 - accuracy: 0.9245 - val_loss: 0.4400 - val_accuracy: 0.8085\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.2165 - accuracy: 0.8868 - val_loss: 0.4389 - val_accuracy: 0.8085\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1315 - accuracy: 0.9623 - val_loss: 0.4394 - val_accuracy: 0.8085\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1786 - accuracy: 0.9245 - val_loss: 0.4386 - val_accuracy: 0.8085\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1499 - accuracy: 0.9623 - val_loss: 0.4382 - val_accuracy: 0.8085\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2260 - accuracy: 0.9245 - val_loss: 0.4381 - val_accuracy: 0.8085\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2172 - accuracy: 0.8868 - val_loss: 0.4382 - val_accuracy: 0.8298\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1438 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 390us/step - loss: 0.2385 - accuracy: 0.9245 - val_loss: 0.4372 - val_accuracy: 0.8298\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2094 - accuracy: 0.9057 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.3001 - accuracy: 0.9057 - val_loss: 0.4358 - val_accuracy: 0.8298\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.4363 - val_accuracy: 0.8085\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1680 - accuracy: 0.9434 - val_loss: 0.4361 - val_accuracy: 0.8085\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1822 - accuracy: 0.9245 - val_loss: 0.4354 - val_accuracy: 0.8085\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 590us/step - loss: 0.1485 - accuracy: 0.9434 - val_loss: 0.4339 - val_accuracy: 0.8085\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1753 - accuracy: 0.9434 - val_loss: 0.4335 - val_accuracy: 0.8085\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1637 - accuracy: 0.9623 - val_loss: 0.4312 - val_accuracy: 0.8085\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.4307 - val_accuracy: 0.8085\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1828 - accuracy: 0.9245 - val_loss: 0.4307 - val_accuracy: 0.8085\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1688 - accuracy: 0.9245 - val_loss: 0.4304 - val_accuracy: 0.8085\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1962 - accuracy: 0.9434 - val_loss: 0.4312 - val_accuracy: 0.8085\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1918 - accuracy: 0.9245 - val_loss: 0.4323 - val_accuracy: 0.8085\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1825 - accuracy: 0.9057 - val_loss: 0.4322 - val_accuracy: 0.8298\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2072 - accuracy: 0.9057 - val_loss: 0.4324 - val_accuracy: 0.8298\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1344 - accuracy: 0.9434 - val_loss: 0.4349 - val_accuracy: 0.8298\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1510 - accuracy: 0.9434 - val_loss: 0.4362 - val_accuracy: 0.8298\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1885 - accuracy: 0.9245 - val_loss: 0.4367 - val_accuracy: 0.8298\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2320 - accuracy: 0.9623 - val_loss: 0.4378 - val_accuracy: 0.8298\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.2708 - accuracy: 0.9057 - val_loss: 0.4365 - val_accuracy: 0.8298\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1973 - accuracy: 0.9623 - val_loss: 0.4338 - val_accuracy: 0.8298\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2261 - accuracy: 0.8868 - val_loss: 0.4305 - val_accuracy: 0.8298\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.1581 - accuracy: 0.9623 - val_loss: 0.4292 - val_accuracy: 0.8298\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2136 - accuracy: 0.8868 - val_loss: 0.4270 - val_accuracy: 0.8298\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1603 - accuracy: 0.9434 - val_loss: 0.4248 - val_accuracy: 0.8298\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1784 - accuracy: 0.8868 - val_loss: 0.4236 - val_accuracy: 0.8298\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2189 - accuracy: 0.8868 - val_loss: 0.4211 - val_accuracy: 0.8511\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1957 - accuracy: 0.9245 - val_loss: 0.4173 - val_accuracy: 0.8511\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2018 - accuracy: 0.9057 - val_loss: 0.4151 - val_accuracy: 0.8511\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2178 - accuracy: 0.9434 - val_loss: 0.4149 - val_accuracy: 0.8511\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1310 - accuracy: 0.9623 - val_loss: 0.4137 - val_accuracy: 0.8511\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2074 - accuracy: 0.8679 - val_loss: 0.4150 - val_accuracy: 0.8511\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2039 - accuracy: 0.9057 - val_loss: 0.4171 - val_accuracy: 0.8511\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1731 - accuracy: 0.9245 - val_loss: 0.4193 - val_accuracy: 0.8298\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2864 - accuracy: 0.8679 - val_loss: 0.4203 - val_accuracy: 0.8298\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1977 - accuracy: 0.9245 - val_loss: 0.4227 - val_accuracy: 0.8298\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1695 - accuracy: 0.9623 - val_loss: 0.4242 - val_accuracy: 0.8298\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2500 - accuracy: 0.9245 - val_loss: 0.4236 - val_accuracy: 0.8298\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1718 - accuracy: 0.9434 - val_loss: 0.4231 - val_accuracy: 0.8298\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1499 - accuracy: 0.9623 - val_loss: 0.4224 - val_accuracy: 0.8298\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1649 - accuracy: 0.9623 - val_loss: 0.4206 - val_accuracy: 0.8298\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.4179 - val_accuracy: 0.8298\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2143 - accuracy: 0.9245 - val_loss: 0.4164 - val_accuracy: 0.8298\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2116 - accuracy: 0.9057 - val_loss: 0.4159 - val_accuracy: 0.8298\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1573 - accuracy: 0.9434 - val_loss: 0.4154 - val_accuracy: 0.8298\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.1864 - accuracy: 0.9434 - val_loss: 0.4151 - val_accuracy: 0.8298\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2261 - accuracy: 0.8868 - val_loss: 0.4135 - val_accuracy: 0.8298\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2653 - accuracy: 0.8868 - val_loss: 0.4104 - val_accuracy: 0.8298\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.4070 - val_accuracy: 0.8511\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1874 - accuracy: 0.9057 - val_loss: 0.4033 - val_accuracy: 0.8511\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2144 - accuracy: 0.9057 - val_loss: 0.3989 - val_accuracy: 0.8298\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1614 - accuracy: 0.9434 - val_loss: 0.3978 - val_accuracy: 0.8298\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2090 - accuracy: 0.9057 - val_loss: 0.3978 - val_accuracy: 0.8298\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1742 - accuracy: 0.9245 - val_loss: 0.3975 - val_accuracy: 0.8298\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1798 - accuracy: 0.9623 - val_loss: 0.3965 - val_accuracy: 0.8298\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1859 - accuracy: 0.9434 - val_loss: 0.3980 - val_accuracy: 0.8298\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1517 - accuracy: 0.9245 - val_loss: 0.3999 - val_accuracy: 0.8298\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.4017 - val_accuracy: 0.8511\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2422 - accuracy: 0.9057 - val_loss: 0.4016 - val_accuracy: 0.8511\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1387 - accuracy: 0.9623 - val_loss: 0.4022 - val_accuracy: 0.8511\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1812 - accuracy: 0.9245 - val_loss: 0.4032 - val_accuracy: 0.8511\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1748 - accuracy: 0.9245 - val_loss: 0.4042 - val_accuracy: 0.8511\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1608 - accuracy: 0.9434 - val_loss: 0.4040 - val_accuracy: 0.8511\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1645 - accuracy: 0.9245 - val_loss: 0.4035 - val_accuracy: 0.8511\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2062 - accuracy: 0.9434 - val_loss: 0.4034 - val_accuracy: 0.8511\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1552 - accuracy: 0.9811 - val_loss: 0.4027 - val_accuracy: 0.8511\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2140 - accuracy: 0.9057 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2645 - accuracy: 0.9057 - val_loss: 0.4018 - val_accuracy: 0.8511\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.1574 - accuracy: 0.9434 - val_loss: 0.4018 - val_accuracy: 0.8511\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1943 - accuracy: 0.9057 - val_loss: 0.4026 - val_accuracy: 0.8511\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1479 - accuracy: 0.9434 - val_loss: 0.4025 - val_accuracy: 0.8511\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1307 - accuracy: 0.9623 - val_loss: 0.4022 - val_accuracy: 0.8511\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1833 - accuracy: 0.9245 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1559 - accuracy: 0.9623 - val_loss: 0.4020 - val_accuracy: 0.8511\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1913 - accuracy: 0.9245 - val_loss: 0.4021 - val_accuracy: 0.8511\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1205 - accuracy: 0.9811 - val_loss: 0.4025 - val_accuracy: 0.8511\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2095 - accuracy: 0.9434 - val_loss: 0.4028 - val_accuracy: 0.8511\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1839 - accuracy: 0.9245 - val_loss: 0.4055 - val_accuracy: 0.8511\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2096 - accuracy: 0.9245 - val_loss: 0.4075 - val_accuracy: 0.8511\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1642 - accuracy: 0.9434 - val_loss: 0.4093 - val_accuracy: 0.8511\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2044 - accuracy: 0.9245 - val_loss: 0.4098 - val_accuracy: 0.8511\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1724 - accuracy: 0.9434 - val_loss: 0.4106 - val_accuracy: 0.8511\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1771 - accuracy: 0.9434 - val_loss: 0.4091 - val_accuracy: 0.8511\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1201 - accuracy: 0.9811 - val_loss: 0.4066 - val_accuracy: 0.8511\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1809 - accuracy: 0.9245 - val_loss: 0.4043 - val_accuracy: 0.8511\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1996 - accuracy: 0.9057 - val_loss: 0.4031 - val_accuracy: 0.8511\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 364us/step - loss: 0.1755 - accuracy: 0.9434 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1441 - accuracy: 0.9623 - val_loss: 0.4001 - val_accuracy: 0.8511\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2333 - accuracy: 0.8868 - val_loss: 0.3975 - val_accuracy: 0.8511\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1374 - accuracy: 0.9623 - val_loss: 0.3971 - val_accuracy: 0.8511\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 710us/step - loss: 0.1178 - accuracy: 0.9245 - val_loss: 0.3974 - val_accuracy: 0.8511\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.3982 - val_accuracy: 0.8511\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 322us/step - loss: 0.1848 - accuracy: 0.9245 - val_loss: 0.4016 - val_accuracy: 0.8511\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1806 - accuracy: 0.9245 - val_loss: 0.4041 - val_accuracy: 0.8511\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.4063 - val_accuracy: 0.8511\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1693 - accuracy: 0.9434 - val_loss: 0.4083 - val_accuracy: 0.8511\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.2049 - accuracy: 0.9057 - val_loss: 0.4079 - val_accuracy: 0.8511\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1462 - accuracy: 0.9623 - val_loss: 0.4067 - val_accuracy: 0.8511\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1252 - accuracy: 0.9623 - val_loss: 0.4056 - val_accuracy: 0.8511\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1598 - accuracy: 0.9434 - val_loss: 0.4062 - val_accuracy: 0.8511\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1157 - accuracy: 0.9623 - val_loss: 0.4071 - val_accuracy: 0.8511\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1476 - accuracy: 0.9434 - val_loss: 0.4055 - val_accuracy: 0.8511\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1784 - accuracy: 0.9245 - val_loss: 0.4034 - val_accuracy: 0.8511\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1553 - accuracy: 0.9434 - val_loss: 0.4028 - val_accuracy: 0.8511\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2165 - accuracy: 0.8868 - val_loss: 0.4021 - val_accuracy: 0.8511\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1875 - accuracy: 0.8868 - val_loss: 0.4039 - val_accuracy: 0.8511\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1535 - accuracy: 0.9434 - val_loss: 0.4057 - val_accuracy: 0.8511\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1918 - accuracy: 0.9434 - val_loss: 0.4053 - val_accuracy: 0.8511\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1968 - accuracy: 0.9245 - val_loss: 0.4031 - val_accuracy: 0.8511\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1099 - accuracy: 0.9623 - val_loss: 0.4017 - val_accuracy: 0.8511\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1659 - accuracy: 0.9434 - val_loss: 0.4000 - val_accuracy: 0.8511\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1700 - accuracy: 0.9434 - val_loss: 0.4010 - val_accuracy: 0.8511\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1589 - accuracy: 0.9245 - val_loss: 0.4037 - val_accuracy: 0.8511\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1343 - accuracy: 0.9623 - val_loss: 0.4069 - val_accuracy: 0.8511\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2157 - accuracy: 0.9434 - val_loss: 0.4099 - val_accuracy: 0.8511\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 834us/step - loss: 0.1855 - accuracy: 0.9245 - val_loss: 0.4129 - val_accuracy: 0.8511\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 566us/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.4153 - val_accuracy: 0.8511\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1346 - accuracy: 0.9623 - val_loss: 0.4156 - val_accuracy: 0.8511\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1592 - accuracy: 0.9434 - val_loss: 0.4156 - val_accuracy: 0.8511\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2075 - accuracy: 0.9057 - val_loss: 0.4137 - val_accuracy: 0.8511\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1648 - accuracy: 0.9057 - val_loss: 0.4130 - val_accuracy: 0.8511\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1448 - accuracy: 0.9245 - val_loss: 0.4102 - val_accuracy: 0.8511\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1514 - accuracy: 0.9434 - val_loss: 0.4081 - val_accuracy: 0.8511\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1314 - accuracy: 0.9623 - val_loss: 0.4065 - val_accuracy: 0.8511\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1537 - accuracy: 0.9245 - val_loss: 0.4061 - val_accuracy: 0.8511\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1861 - accuracy: 0.9434 - val_loss: 0.4052 - val_accuracy: 0.8511\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1568 - accuracy: 0.9245 - val_loss: 0.4033 - val_accuracy: 0.8511\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1369 - accuracy: 0.9434 - val_loss: 0.3984 - val_accuracy: 0.8511\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1554 - accuracy: 0.9434 - val_loss: 0.3946 - val_accuracy: 0.8511\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1338 - accuracy: 0.9434 - val_loss: 0.3912 - val_accuracy: 0.8511\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1540 - accuracy: 0.9057 - val_loss: 0.3892 - val_accuracy: 0.8511\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1060 - accuracy: 0.9811 - val_loss: 0.3869 - val_accuracy: 0.8511\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2172 - accuracy: 0.9434 - val_loss: 0.3838 - val_accuracy: 0.8511\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1556 - accuracy: 0.9245 - val_loss: 0.3804 - val_accuracy: 0.8723\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1568 - accuracy: 0.9057 - val_loss: 0.3784 - val_accuracy: 0.8723\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1938 - accuracy: 0.9434 - val_loss: 0.3761 - val_accuracy: 0.8723\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1380 - accuracy: 0.9434 - val_loss: 0.3746 - val_accuracy: 0.8723\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1309 - accuracy: 0.9623 - val_loss: 0.3745 - val_accuracy: 0.8723\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2078 - accuracy: 0.9057 - val_loss: 0.3759 - val_accuracy: 0.8723\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1229 - accuracy: 0.9623 - val_loss: 0.3776 - val_accuracy: 0.8723\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2001 - accuracy: 0.9245 - val_loss: 0.3775 - val_accuracy: 0.8723\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1185 - accuracy: 0.9623 - val_loss: 0.3774 - val_accuracy: 0.8723\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2337 - accuracy: 0.8868 - val_loss: 0.3777 - val_accuracy: 0.8723\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1463 - accuracy: 0.9245 - val_loss: 0.3788 - val_accuracy: 0.8723\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.3795 - val_accuracy: 0.8723\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1325 - accuracy: 0.9434 - val_loss: 0.3795 - val_accuracy: 0.8723\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1422 - accuracy: 0.9434 - val_loss: 0.3795 - val_accuracy: 0.8723\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1017 - accuracy: 0.9623 - val_loss: 0.3801 - val_accuracy: 0.8511\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1628 - accuracy: 0.9245 - val_loss: 0.3816 - val_accuracy: 0.8511\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1767 - accuracy: 0.9434 - val_loss: 0.3836 - val_accuracy: 0.8511\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1401 - accuracy: 0.9434 - val_loss: 0.3865 - val_accuracy: 0.8511\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1431 - accuracy: 0.9434 - val_loss: 0.3901 - val_accuracy: 0.8511\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 391us/step - loss: 0.1624 - accuracy: 0.9434 - val_loss: 0.3930 - val_accuracy: 0.8511\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 811us/step - loss: 0.1026 - accuracy: 0.9623 - val_loss: 0.3944 - val_accuracy: 0.8511\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 0.1436 - accuracy: 0.9623 - val_loss: 0.3952 - val_accuracy: 0.8511\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1693 - accuracy: 0.9434 - val_loss: 0.3987 - val_accuracy: 0.8723\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.1506 - accuracy: 0.9434 - val_loss: 0.4040 - val_accuracy: 0.8723\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2009 - accuracy: 0.9245 - val_loss: 0.4065 - val_accuracy: 0.8723\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1484 - accuracy: 0.9434 - val_loss: 0.4045 - val_accuracy: 0.8723\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0934 - accuracy: 0.9623 - val_loss: 0.4017 - val_accuracy: 0.8511\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1321 - accuracy: 0.9623 - val_loss: 0.3971 - val_accuracy: 0.8511\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1554 - accuracy: 0.9434 - val_loss: 0.3947 - val_accuracy: 0.8511\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1290 - accuracy: 0.9623 - val_loss: 0.3927 - val_accuracy: 0.8511\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1139 - accuracy: 0.9623 - val_loss: 0.3909 - val_accuracy: 0.8511\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.3868 - val_accuracy: 0.8511\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1430 - accuracy: 0.9434 - val_loss: 0.3848 - val_accuracy: 0.8511\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1345 - accuracy: 0.9434 - val_loss: 0.3847 - val_accuracy: 0.8511\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2001 - accuracy: 0.8868 - val_loss: 0.3852 - val_accuracy: 0.8511\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1000 - accuracy: 0.9623 - val_loss: 0.3839 - val_accuracy: 0.8511\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.3850 - val_accuracy: 0.8511\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1312 - accuracy: 0.9434 - val_loss: 0.3862 - val_accuracy: 0.8511\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1201 - accuracy: 0.9245 - val_loss: 0.3851 - val_accuracy: 0.8511\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2018 - accuracy: 0.9245 - val_loss: 0.3820 - val_accuracy: 0.8511\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1350 - accuracy: 0.9623 - val_loss: 0.3799 - val_accuracy: 0.8511\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1692 - accuracy: 0.9434 - val_loss: 0.3783 - val_accuracy: 0.8511\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1554 - accuracy: 0.9623 - val_loss: 0.3773 - val_accuracy: 0.8511\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1022 - accuracy: 0.9434 - val_loss: 0.3747 - val_accuracy: 0.8511\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1340 - accuracy: 0.9434 - val_loss: 0.3703 - val_accuracy: 0.8723\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1597 - accuracy: 0.9623 - val_loss: 0.3662 - val_accuracy: 0.8723\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1205 - accuracy: 0.9623 - val_loss: 0.3625 - val_accuracy: 0.8723\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1329 - accuracy: 0.9623 - val_loss: 0.3599 - val_accuracy: 0.8723\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1365 - accuracy: 0.9811 - val_loss: 0.3587 - val_accuracy: 0.8723\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1864 - accuracy: 0.9245 - val_loss: 0.3595 - val_accuracy: 0.8723\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1668 - accuracy: 0.9434 - val_loss: 0.3590 - val_accuracy: 0.8723\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 568us/step - loss: 0.1263 - accuracy: 0.9245 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1325 - accuracy: 0.9623 - val_loss: 0.3648 - val_accuracy: 0.8723\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1043 - accuracy: 0.9623 - val_loss: 0.3696 - val_accuracy: 0.8723\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0771 - accuracy: 0.9811 - val_loss: 0.3738 - val_accuracy: 0.8723\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1054 - accuracy: 0.9623 - val_loss: 0.3761 - val_accuracy: 0.8723\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1067 - accuracy: 0.9623 - val_loss: 0.3770 - val_accuracy: 0.8723\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1146 - accuracy: 0.9623 - val_loss: 0.3779 - val_accuracy: 0.8723\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0909 - accuracy: 0.9623 - val_loss: 0.3769 - val_accuracy: 0.8723\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1055 - accuracy: 0.9623 - val_loss: 0.3765 - val_accuracy: 0.8723\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1308 - accuracy: 0.9057 - val_loss: 0.3759 - val_accuracy: 0.8723\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1101 - accuracy: 0.9623 - val_loss: 0.3778 - val_accuracy: 0.8723\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1298 - accuracy: 0.9623 - val_loss: 0.3799 - val_accuracy: 0.8723\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1119 - accuracy: 0.9623 - val_loss: 0.3831 - val_accuracy: 0.8723\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1534 - accuracy: 0.9623 - val_loss: 0.3882 - val_accuracy: 0.8723\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1328 - accuracy: 0.9623 - val_loss: 0.3909 - val_accuracy: 0.8723\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1375 - accuracy: 0.9434 - val_loss: 0.3940 - val_accuracy: 0.8723\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1722 - accuracy: 0.9245 - val_loss: 0.3999 - val_accuracy: 0.8511\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1590 - accuracy: 0.9623 - val_loss: 0.4050 - val_accuracy: 0.8723\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1327 - accuracy: 0.9434 - val_loss: 0.4060 - val_accuracy: 0.8723\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1266 - accuracy: 0.9811 - val_loss: 0.4055 - val_accuracy: 0.8723\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0971 - accuracy: 0.9811 - val_loss: 0.4030 - val_accuracy: 0.8723\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1094 - accuracy: 0.9623 - val_loss: 0.3973 - val_accuracy: 0.8723\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1404 - accuracy: 0.9623 - val_loss: 0.3896 - val_accuracy: 0.8723\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0817 - accuracy: 0.9811 - val_loss: 0.3810 - val_accuracy: 0.8936\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1300 - accuracy: 0.9434 - val_loss: 0.3698 - val_accuracy: 0.8723\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1447 - accuracy: 0.9434 - val_loss: 0.3572 - val_accuracy: 0.8723\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.1353 - accuracy: 0.9623 - val_loss: 0.3468 - val_accuracy: 0.8723\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1806 - accuracy: 0.9434 - val_loss: 0.3367 - val_accuracy: 0.8723\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.3285 - val_accuracy: 0.8723\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1156 - accuracy: 0.9434 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1606 - accuracy: 0.9434 - val_loss: 0.3201 - val_accuracy: 0.8723\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1338 - accuracy: 0.9811 - val_loss: 0.3210 - val_accuracy: 0.8723\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1367 - accuracy: 0.9434 - val_loss: 0.3221 - val_accuracy: 0.8723\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1029 - accuracy: 0.9811 - val_loss: 0.3222 - val_accuracy: 0.8723\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1446 - accuracy: 0.9434 - val_loss: 0.3221 - val_accuracy: 0.8723\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2196 - accuracy: 0.9057 - val_loss: 0.3213 - val_accuracy: 0.8936\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1200 - accuracy: 0.9434 - val_loss: 0.3218 - val_accuracy: 0.8936\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1392 - accuracy: 0.9245 - val_loss: 0.3219 - val_accuracy: 0.8936\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0766 - accuracy: 0.9811 - val_loss: 0.3206 - val_accuracy: 0.8936\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1606 - accuracy: 0.9245 - val_loss: 0.3223 - val_accuracy: 0.8936\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1276 - accuracy: 0.9623 - val_loss: 0.3225 - val_accuracy: 0.8723\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1314 - accuracy: 0.9811 - val_loss: 0.3218 - val_accuracy: 0.8723\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1349 - accuracy: 0.9057 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0917 - accuracy: 0.9623 - val_loss: 0.3208 - val_accuracy: 0.8723\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 566us/step - loss: 0.0939 - accuracy: 0.9811 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1332 - accuracy: 0.9434 - val_loss: 0.3213 - val_accuracy: 0.8723\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1413 - accuracy: 0.9245 - val_loss: 0.3241 - val_accuracy: 0.8723\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1277 - accuracy: 0.9811 - val_loss: 0.3254 - val_accuracy: 0.8723\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1290 - accuracy: 0.9623 - val_loss: 0.3260 - val_accuracy: 0.8723\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0925 - accuracy: 0.9623 - val_loss: 0.3268 - val_accuracy: 0.8723\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1258 - accuracy: 0.9434 - val_loss: 0.3274 - val_accuracy: 0.8723\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0829 - accuracy: 0.9811 - val_loss: 0.3278 - val_accuracy: 0.8723\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0910 - accuracy: 0.9623 - val_loss: 0.3283 - val_accuracy: 0.8723\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1755 - accuracy: 0.8868 - val_loss: 0.3291 - val_accuracy: 0.8723\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1382 - accuracy: 0.9623 - val_loss: 0.3281 - val_accuracy: 0.8723\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0938 - accuracy: 0.9623 - val_loss: 0.3281 - val_accuracy: 0.8723\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1800 - accuracy: 0.9245 - val_loss: 0.3294 - val_accuracy: 0.8723\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1152 - accuracy: 0.9623 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0982 - accuracy: 0.9623 - val_loss: 0.3276 - val_accuracy: 0.8723\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0986 - accuracy: 0.9245 - val_loss: 0.3263 - val_accuracy: 0.8723\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1225 - accuracy: 0.9434 - val_loss: 0.3261 - val_accuracy: 0.8723\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1246 - accuracy: 0.9434 - val_loss: 0.3291 - val_accuracy: 0.8723\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1364 - accuracy: 0.9434 - val_loss: 0.3320 - val_accuracy: 0.8723\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1583 - accuracy: 0.9245 - val_loss: 0.3354 - val_accuracy: 0.8723\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1189 - accuracy: 0.9434 - val_loss: 0.3385 - val_accuracy: 0.8723\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1038 - accuracy: 0.9811 - val_loss: 0.3391 - val_accuracy: 0.8723\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1325 - accuracy: 0.9623 - val_loss: 0.3396 - val_accuracy: 0.8723\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1173 - accuracy: 0.9623 - val_loss: 0.3396 - val_accuracy: 0.8723\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1908 - accuracy: 0.9434 - val_loss: 0.3386 - val_accuracy: 0.8723\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1500 - accuracy: 0.9434 - val_loss: 0.3368 - val_accuracy: 0.8723\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1506 - accuracy: 0.9245 - val_loss: 0.3359 - val_accuracy: 0.8723\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1301 - accuracy: 0.9623 - val_loss: 0.3322 - val_accuracy: 0.8723\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1100 - accuracy: 0.9057 - val_loss: 0.3307 - val_accuracy: 0.8723\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 403us/step - loss: 0.0989 - accuracy: 0.9811 - val_loss: 0.3276 - val_accuracy: 0.8723\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1435 - accuracy: 0.9245 - val_loss: 0.3275 - val_accuracy: 0.8723\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0818 - accuracy: 0.9811 - val_loss: 0.3284 - val_accuracy: 0.8723\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1541 - accuracy: 0.9245 - val_loss: 0.3272 - val_accuracy: 0.8723\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1319 - accuracy: 0.9811 - val_loss: 0.3266 - val_accuracy: 0.8723\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0825 - accuracy: 0.9811 - val_loss: 0.3245 - val_accuracy: 0.8723\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1578 - accuracy: 0.9434 - val_loss: 0.3204 - val_accuracy: 0.8723\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0996 - accuracy: 0.9623 - val_loss: 0.3184 - val_accuracy: 0.8723\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0988 - accuracy: 0.9623 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1075 - accuracy: 0.9434 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1601 - accuracy: 0.9245 - val_loss: 0.3148 - val_accuracy: 0.8723\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1396 - accuracy: 0.9057 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1688 - accuracy: 0.9245 - val_loss: 0.3158 - val_accuracy: 0.8723\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1972 - accuracy: 0.9434 - val_loss: 0.3157 - val_accuracy: 0.8723\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.1303 - accuracy: 0.9434 - val_loss: 0.3156 - val_accuracy: 0.8723\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1014 - accuracy: 0.9434 - val_loss: 0.3172 - val_accuracy: 0.8723\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0808 - accuracy: 0.9811 - val_loss: 0.3195 - val_accuracy: 0.8723\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0793 - accuracy: 0.9811 - val_loss: 0.3197 - val_accuracy: 0.8723\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1205 - accuracy: 0.9811 - val_loss: 0.3194 - val_accuracy: 0.8723\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1535 - accuracy: 0.9434 - val_loss: 0.3181 - val_accuracy: 0.8723\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1440 - accuracy: 0.9811 - val_loss: 0.3146 - val_accuracy: 0.8723\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1081 - accuracy: 0.9434 - val_loss: 0.3111 - val_accuracy: 0.8723\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1311 - accuracy: 0.9434 - val_loss: 0.3085 - val_accuracy: 0.8723\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0787 - accuracy: 0.9623 - val_loss: 0.3068 - val_accuracy: 0.8723\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 418us/step - loss: 0.1263 - accuracy: 0.9623 - val_loss: 0.3045 - val_accuracy: 0.8723\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1116 - accuracy: 0.9623 - val_loss: 0.3026 - val_accuracy: 0.8723\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1576 - accuracy: 0.9434 - val_loss: 0.3008 - val_accuracy: 0.8723\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1033 - accuracy: 0.9434 - val_loss: 0.2986 - val_accuracy: 0.8723\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1429 - accuracy: 0.9623 - val_loss: 0.2953 - val_accuracy: 0.8723\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1177 - accuracy: 0.9434 - val_loss: 0.2897 - val_accuracy: 0.8723\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1056 - accuracy: 0.9623 - val_loss: 0.2875 - val_accuracy: 0.8723\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1186 - accuracy: 0.9434 - val_loss: 0.2884 - val_accuracy: 0.8723\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1293 - accuracy: 0.9434 - val_loss: 0.2903 - val_accuracy: 0.8723\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1117 - accuracy: 0.9623 - val_loss: 0.2905 - val_accuracy: 0.8723\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0991 - accuracy: 0.9434 - val_loss: 0.2904 - val_accuracy: 0.8723\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0963 - accuracy: 0.9811 - val_loss: 0.2898 - val_accuracy: 0.8723\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1400 - accuracy: 0.9434 - val_loss: 0.2924 - val_accuracy: 0.8723\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0985 - accuracy: 0.9623 - val_loss: 0.2964 - val_accuracy: 0.8723\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0773 - accuracy: 0.9811 - val_loss: 0.2995 - val_accuracy: 0.8723\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 579us/step - loss: 0.1388 - accuracy: 0.9434 - val_loss: 0.3024 - val_accuracy: 0.8723\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1106 - accuracy: 0.9623 - val_loss: 0.3034 - val_accuracy: 0.8723\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0734 - accuracy: 0.9623 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1353 - accuracy: 0.9434 - val_loss: 0.3074 - val_accuracy: 0.8723\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0959 - accuracy: 0.9623 - val_loss: 0.3133 - val_accuracy: 0.8723\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 764us/step - loss: 0.0685 - accuracy: 0.9623 - val_loss: 0.3168 - val_accuracy: 0.8723\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 568us/step - loss: 0.1124 - accuracy: 0.9434 - val_loss: 0.3188 - val_accuracy: 0.8723\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1113 - accuracy: 0.9623 - val_loss: 0.3194 - val_accuracy: 0.8723\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0824 - accuracy: 0.9434 - val_loss: 0.3183 - val_accuracy: 0.8723\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0692 - accuracy: 0.9623 - val_loss: 0.3163 - val_accuracy: 0.8723\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0986 - accuracy: 0.9811 - val_loss: 0.3109 - val_accuracy: 0.8723\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1013 - accuracy: 0.9434 - val_loss: 0.3062 - val_accuracy: 0.8723\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1163 - accuracy: 0.9623 - val_loss: 0.3044 - val_accuracy: 0.8723\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1051 - accuracy: 0.9623 - val_loss: 0.3043 - val_accuracy: 0.8723\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1361 - accuracy: 0.9434 - val_loss: 0.3006 - val_accuracy: 0.8723\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.1136 - accuracy: 0.9434 - val_loss: 0.2961 - val_accuracy: 0.8723\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1174 - accuracy: 0.9623 - val_loss: 0.2916 - val_accuracy: 0.8723\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1020 - accuracy: 0.9623 - val_loss: 0.2892 - val_accuracy: 0.8723\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1528 - accuracy: 0.9245 - val_loss: 0.2885 - val_accuracy: 0.8936\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0766 - accuracy: 0.9623 - val_loss: 0.2850 - val_accuracy: 0.8936\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0978 - accuracy: 0.9811 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1275 - accuracy: 0.9245 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1787 - accuracy: 0.9434 - val_loss: 0.2801 - val_accuracy: 0.8936\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1559 - accuracy: 0.9434 - val_loss: 0.2785 - val_accuracy: 0.8936\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0821 - accuracy: 0.9811 - val_loss: 0.2816 - val_accuracy: 0.8936\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0972 - accuracy: 0.9623 - val_loss: 0.2837 - val_accuracy: 0.8936\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0925 - accuracy: 0.9623 - val_loss: 0.2861 - val_accuracy: 0.8936\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0706 - accuracy: 0.9623 - val_loss: 0.2871 - val_accuracy: 0.8936\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 0.2927 - val_accuracy: 0.8936\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1227 - accuracy: 0.9623 - val_loss: 0.2964 - val_accuracy: 0.8936\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0743 - accuracy: 0.9623 - val_loss: 0.2972 - val_accuracy: 0.8936\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1482 - accuracy: 0.9434 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0747 - accuracy: 0.9623 - val_loss: 0.2933 - val_accuracy: 0.8936\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.2911 - val_accuracy: 0.8723\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1305 - accuracy: 0.9623 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 636us/step - loss: 0.1161 - accuracy: 0.9623 - val_loss: 0.2848 - val_accuracy: 0.8723\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1445 - accuracy: 0.9623 - val_loss: 0.2824 - val_accuracy: 0.8723\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1440 - accuracy: 0.9434 - val_loss: 0.2812 - val_accuracy: 0.8723\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0621 - accuracy: 0.9623 - val_loss: 0.2817 - val_accuracy: 0.8723\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0905 - accuracy: 0.9434 - val_loss: 0.2818 - val_accuracy: 0.8723\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1053 - accuracy: 0.9623 - val_loss: 0.2813 - val_accuracy: 0.8723\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.8723\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0765 - accuracy: 0.9623 - val_loss: 0.2779 - val_accuracy: 0.8723\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 604us/step - loss: 0.0799 - accuracy: 0.9623 - val_loss: 0.2790 - val_accuracy: 0.8723\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1468 - accuracy: 0.9245 - val_loss: 0.2788 - val_accuracy: 0.8723\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.8723\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1353 - accuracy: 0.9434 - val_loss: 0.2845 - val_accuracy: 0.8723\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0590 - accuracy: 0.9623 - val_loss: 0.2879 - val_accuracy: 0.8723\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1293 - accuracy: 0.9434 - val_loss: 0.2909 - val_accuracy: 0.8936\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1771 - accuracy: 0.9434 - val_loss: 0.2935 - val_accuracy: 0.8936\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1293 - accuracy: 0.9623 - val_loss: 0.2948 - val_accuracy: 0.8936\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1313 - accuracy: 0.9623 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.2966 - val_accuracy: 0.8936\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1130 - accuracy: 0.9434 - val_loss: 0.2919 - val_accuracy: 0.8936\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1532 - accuracy: 0.9434 - val_loss: 0.2849 - val_accuracy: 0.8936\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1274 - accuracy: 0.9434 - val_loss: 0.2744 - val_accuracy: 0.8936\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1126 - accuracy: 0.9623 - val_loss: 0.2658 - val_accuracy: 0.8936\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0787 - accuracy: 0.9811 - val_loss: 0.2607 - val_accuracy: 0.8936\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1139 - accuracy: 0.9811 - val_loss: 0.2612 - val_accuracy: 0.8936\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1177 - accuracy: 0.9434 - val_loss: 0.2652 - val_accuracy: 0.8936\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0838 - accuracy: 0.9434 - val_loss: 0.2693 - val_accuracy: 0.8936\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1304 - accuracy: 0.9245 - val_loss: 0.2716 - val_accuracy: 0.8936\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0710 - accuracy: 0.9623 - val_loss: 0.2721 - val_accuracy: 0.8936\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0770 - accuracy: 0.9623 - val_loss: 0.2719 - val_accuracy: 0.8936\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1765 - accuracy: 0.9057 - val_loss: 0.2715 - val_accuracy: 0.8936\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0974 - accuracy: 0.9434 - val_loss: 0.2678 - val_accuracy: 0.8936\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0667 - accuracy: 0.9434 - val_loss: 0.2598 - val_accuracy: 0.8936\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0739 - accuracy: 0.9623 - val_loss: 0.2558 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1022 - accuracy: 0.9623 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1284 - accuracy: 0.9623 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1914 - accuracy: 0.9434 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1041 - accuracy: 0.9623 - val_loss: 0.2556 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0867 - accuracy: 0.9623 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1249 - accuracy: 0.9434 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1271 - accuracy: 0.9434 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1404 - accuracy: 0.9434 - val_loss: 0.2715 - val_accuracy: 0.8936\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1619 - accuracy: 0.9057 - val_loss: 0.2746 - val_accuracy: 0.8936\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1078 - accuracy: 0.9434 - val_loss: 0.2789 - val_accuracy: 0.8723\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0791 - accuracy: 0.9811 - val_loss: 0.2844 - val_accuracy: 0.8723\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.8723\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.2985 - val_accuracy: 0.8723\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0723 - accuracy: 0.9623 - val_loss: 0.3012 - val_accuracy: 0.8723\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1026 - accuracy: 0.9245 - val_loss: 0.2998 - val_accuracy: 0.8723\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1201 - accuracy: 0.9623 - val_loss: 0.2953 - val_accuracy: 0.8723\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0857 - accuracy: 0.9811 - val_loss: 0.2901 - val_accuracy: 0.8723\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1224 - accuracy: 0.9623 - val_loss: 0.2810 - val_accuracy: 0.8936\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0637 - accuracy: 0.9811 - val_loss: 0.2739 - val_accuracy: 0.8936\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0624 - accuracy: 0.9623 - val_loss: 0.2691 - val_accuracy: 0.8936\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1027 - accuracy: 0.9623 - val_loss: 0.2649 - val_accuracy: 0.8936\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0652 - accuracy: 0.9623 - val_loss: 0.2655 - val_accuracy: 0.8936\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0595 - accuracy: 0.9811 - val_loss: 0.2691 - val_accuracy: 0.8936\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1684 - accuracy: 0.9434 - val_loss: 0.2759 - val_accuracy: 0.8936\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 0.2805 - val_accuracy: 0.8936\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0913 - accuracy: 0.9434 - val_loss: 0.2822 - val_accuracy: 0.8723\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.2843 - val_accuracy: 0.8723\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 625us/step - loss: 0.1035 - accuracy: 0.9623 - val_loss: 0.2856 - val_accuracy: 0.8723\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0982 - accuracy: 0.9623 - val_loss: 0.2827 - val_accuracy: 0.8936\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0685 - accuracy: 0.9811 - val_loss: 0.2807 - val_accuracy: 0.8936\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0939 - accuracy: 0.9434 - val_loss: 0.2818 - val_accuracy: 0.8936\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0801 - accuracy: 0.9623 - val_loss: 0.2815 - val_accuracy: 0.8936\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0705 - accuracy: 0.9623 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 596us/step - loss: 0.0910 - accuracy: 0.9623 - val_loss: 0.2779 - val_accuracy: 0.8936\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0670 - accuracy: 0.9623 - val_loss: 0.2717 - val_accuracy: 0.8936\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0832 - accuracy: 0.9623 - val_loss: 0.2653 - val_accuracy: 0.8936\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0527 - accuracy: 0.9811 - val_loss: 0.2620 - val_accuracy: 0.8936\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 397us/step - loss: 0.0708 - accuracy: 0.9623 - val_loss: 0.2591 - val_accuracy: 0.8936\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0878 - accuracy: 0.9623 - val_loss: 0.2560 - val_accuracy: 0.8936\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1313 - accuracy: 0.9434 - val_loss: 0.2535 - val_accuracy: 0.8936\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1005 - accuracy: 0.9434 - val_loss: 0.2492 - val_accuracy: 0.8936\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0949 - accuracy: 0.9623 - val_loss: 0.2477 - val_accuracy: 0.8936\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.2511 - val_accuracy: 0.8936\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 720us/step - loss: 0.0886 - accuracy: 0.9623 - val_loss: 0.2555 - val_accuracy: 0.8936\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0942 - accuracy: 0.9623 - val_loss: 0.2560 - val_accuracy: 0.8936\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0512 - accuracy: 0.9811 - val_loss: 0.2562 - val_accuracy: 0.8936\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0944 - accuracy: 0.9434 - val_loss: 0.2630 - val_accuracy: 0.8936\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.2640 - val_accuracy: 0.8936\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0958 - accuracy: 0.9623 - val_loss: 0.2643 - val_accuracy: 0.8936\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 416us/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.2685 - val_accuracy: 0.8936\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0534 - accuracy: 0.9623 - val_loss: 0.2744 - val_accuracy: 0.8936\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1002 - accuracy: 0.9811 - val_loss: 0.2758 - val_accuracy: 0.8936\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0871 - accuracy: 0.9623 - val_loss: 0.2779 - val_accuracy: 0.8936\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0443 - accuracy: 0.9811 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1239 - accuracy: 0.9623 - val_loss: 0.2805 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 603us/step - loss: 0.0636 - accuracy: 0.9811 - val_loss: 0.2801 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 0.2750 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0875 - accuracy: 0.9623 - val_loss: 0.2681 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1145 - accuracy: 0.9245 - val_loss: 0.2608 - val_accuracy: 0.8936\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.2576 - val_accuracy: 0.8936\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0602 - accuracy: 0.9623 - val_loss: 0.2513 - val_accuracy: 0.8936\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 511us/step - loss: 0.0637 - accuracy: 0.9623 - val_loss: 0.2466 - val_accuracy: 0.8936\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0860 - accuracy: 0.9623 - val_loss: 0.2438 - val_accuracy: 0.8936\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1077 - accuracy: 0.9434 - val_loss: 0.2390 - val_accuracy: 0.8936\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0827 - accuracy: 0.9434 - val_loss: 0.2356 - val_accuracy: 0.8936\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0481 - accuracy: 0.9811 - val_loss: 0.2345 - val_accuracy: 0.8936\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.2324 - val_accuracy: 0.8936\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.2296 - val_accuracy: 0.8936\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0837 - accuracy: 0.9623 - val_loss: 0.2269 - val_accuracy: 0.8936\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1279 - accuracy: 0.9623 - val_loss: 0.2264 - val_accuracy: 0.8936\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 767us/step - loss: 0.0458 - accuracy: 0.9811 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1013 - accuracy: 0.9434 - val_loss: 0.2276 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.2329 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 0.1260 - accuracy: 0.9057 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0754 - accuracy: 0.9623 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0646 - accuracy: 0.9811 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 775us/step - loss: 0.0771 - accuracy: 0.9623 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1145 - accuracy: 0.9623 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0768 - accuracy: 0.9623 - val_loss: 0.2659 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0713 - accuracy: 0.9623 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 607us/step - loss: 0.0704 - accuracy: 0.9623 - val_loss: 0.2728 - val_accuracy: 0.8936\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1214 - accuracy: 0.9434 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0689 - accuracy: 0.9623 - val_loss: 0.2791 - val_accuracy: 0.8936\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 774us/step - loss: 0.0383 - accuracy: 0.9811 - val_loss: 0.2848 - val_accuracy: 0.8936\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0938 - accuracy: 0.9434 - val_loss: 0.2890 - val_accuracy: 0.8936\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.2904 - val_accuracy: 0.8936\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1250 - accuracy: 0.9623 - val_loss: 0.2885 - val_accuracy: 0.8936\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0318 - accuracy: 0.9811 - val_loss: 0.2823 - val_accuracy: 0.8936\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0573 - accuracy: 0.9623 - val_loss: 0.2766 - val_accuracy: 0.8936\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0775 - accuracy: 0.9623 - val_loss: 0.2713 - val_accuracy: 0.8936\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0778 - accuracy: 0.9623 - val_loss: 0.2689 - val_accuracy: 0.8936\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0435 - accuracy: 0.9811 - val_loss: 0.2667 - val_accuracy: 0.8936\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0968 - accuracy: 0.9623 - val_loss: 0.2646 - val_accuracy: 0.8936\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0627 - accuracy: 0.9623 - val_loss: 0.2621 - val_accuracy: 0.8936\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0513 - accuracy: 0.9623 - val_loss: 0.2591 - val_accuracy: 0.8936\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.2576 - val_accuracy: 0.8936\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0787 - accuracy: 0.9623 - val_loss: 0.2542 - val_accuracy: 0.8936\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1027 - accuracy: 0.9245 - val_loss: 0.2550 - val_accuracy: 0.8936\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1119 - accuracy: 0.9434 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0812 - accuracy: 0.9623 - val_loss: 0.2621 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0924 - accuracy: 0.9434 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0796 - accuracy: 0.9811 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1345 - accuracy: 0.9245 - val_loss: 0.2651 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.2649 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0880 - accuracy: 0.9623 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.2543 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0776 - accuracy: 0.9623 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0687 - accuracy: 0.9623 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0338 - accuracy: 0.9811 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0673 - accuracy: 0.9623 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0871 - accuracy: 0.9623 - val_loss: 0.2463 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0638 - accuracy: 0.9811 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0454 - accuracy: 0.9811 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0797 - accuracy: 0.9623 - val_loss: 0.2478 - val_accuracy: 0.8936\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1086 - accuracy: 0.9434 - val_loss: 0.2471 - val_accuracy: 0.8936\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0534 - accuracy: 0.9623 - val_loss: 0.2465 - val_accuracy: 0.8936\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1122 - accuracy: 0.9623 - val_loss: 0.2439 - val_accuracy: 0.8936\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0417 - accuracy: 0.9811 - val_loss: 0.2402 - val_accuracy: 0.8936\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.2383 - val_accuracy: 0.8936\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0344 - accuracy: 0.9811 - val_loss: 0.2374 - val_accuracy: 0.8936\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0844 - accuracy: 0.9434 - val_loss: 0.2359 - val_accuracy: 0.8936\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.8936\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.8936\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0491 - accuracy: 0.9811 - val_loss: 0.2353 - val_accuracy: 0.8936\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0880 - accuracy: 0.9623 - val_loss: 0.2354 - val_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1150 - accuracy: 0.9623 - val_loss: 0.2341 - val_accuracy: 0.8936\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0562 - accuracy: 0.9623 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0749 - accuracy: 0.9623 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0707 - accuracy: 0.9623 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0458 - accuracy: 0.9811 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0450 - accuracy: 0.9811 - val_loss: 0.2169 - val_accuracy: 0.9362\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9362\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0440 - accuracy: 0.9623 - val_loss: 0.2209 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0806 - accuracy: 0.9623 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0891 - accuracy: 0.9811 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0768 - accuracy: 0.9434 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.8936\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0697 - accuracy: 0.9623 - val_loss: 0.2653 - val_accuracy: 0.8936\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0697 - accuracy: 0.9434 - val_loss: 0.2732 - val_accuracy: 0.8936\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0391 - accuracy: 0.9811 - val_loss: 0.2783 - val_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0386 - accuracy: 0.9811 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0474 - accuracy: 0.9623 - val_loss: 0.2836 - val_accuracy: 0.8936\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0725 - accuracy: 0.9623 - val_loss: 0.2861 - val_accuracy: 0.8936\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.96 - 0s 548us/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.2875 - val_accuracy: 0.8936\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.2887 - val_accuracy: 0.8936\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0832 - accuracy: 0.9623 - val_loss: 0.2881 - val_accuracy: 0.8936\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 0.2897 - val_accuracy: 0.8936\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.2927 - val_accuracy: 0.8936\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 567us/step - loss: 0.0694 - accuracy: 0.9623 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0563 - accuracy: 0.9623 - val_loss: 0.3044 - val_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0313 - accuracy: 0.9811 - val_loss: 0.3081 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0668 - accuracy: 0.9811 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1006 - accuracy: 0.9811 - val_loss: 0.3096 - val_accuracy: 0.8936\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0728 - accuracy: 0.9623 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.2989 - val_accuracy: 0.8936\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1093 - accuracy: 0.9434 - val_loss: 0.2892 - val_accuracy: 0.8936\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.2832 - val_accuracy: 0.8936\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.8936\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1253 - accuracy: 0.9434 - val_loss: 0.2768 - val_accuracy: 0.8936\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1131 - accuracy: 0.9623 - val_loss: 0.2842 - val_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0283 - accuracy: 0.9811 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0547 - accuracy: 0.9623 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0496 - accuracy: 0.9811 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2091 - accuracy: 0.9434 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1128 - accuracy: 0.9245 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0632 - accuracy: 0.9811 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0699 - accuracy: 0.9434 - val_loss: 0.2764 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1539 - accuracy: 0.9623 - val_loss: 0.2671 - val_accuracy: 0.8936\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0750 - accuracy: 0.9811 - val_loss: 0.2594 - val_accuracy: 0.8936\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0925 - accuracy: 0.9623 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 592us/step - loss: 0.1695 - accuracy: 0.9245 - val_loss: 0.2520 - val_accuracy: 0.8936\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0761 - accuracy: 0.9623 - val_loss: 0.2513 - val_accuracy: 0.8936\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0722 - accuracy: 0.9623 - val_loss: 0.2510 - val_accuracy: 0.8936\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 611us/step - loss: 0.0886 - accuracy: 0.9434 - val_loss: 0.2498 - val_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0607 - accuracy: 0.9811 - val_loss: 0.2545 - val_accuracy: 0.8936\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 579us/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.2584 - val_accuracy: 0.8936\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0413 - accuracy: 0.9811 - val_loss: 0.2604 - val_accuracy: 0.8936\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8936\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0721 - accuracy: 0.9434 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0825 - accuracy: 0.9623 - val_loss: 0.2607 - val_accuracy: 0.8936\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0692 - accuracy: 0.9623 - val_loss: 0.2571 - val_accuracy: 0.8936\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0492 - accuracy: 0.9811 - val_loss: 0.2511 - val_accuracy: 0.8936\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1083 - accuracy: 0.9623 - val_loss: 0.2447 - val_accuracy: 0.8936\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1050 - accuracy: 0.9623 - val_loss: 0.2445 - val_accuracy: 0.8936\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 334us/step - loss: 0.0691 - accuracy: 0.9623 - val_loss: 0.2496 - val_accuracy: 0.8936\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 787us/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 455us/step - loss: 0.0319 - accuracy: 0.9811 - val_loss: 0.2557 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1033 - accuracy: 0.9811 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.2543 - val_accuracy: 0.8936\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.2496 - val_accuracy: 0.8936\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.8936\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.8936\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0830 - accuracy: 0.9623 - val_loss: 0.2396 - val_accuracy: 0.8936\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 0.2361 - val_accuracy: 0.8936\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0909 - accuracy: 0.9811 - val_loss: 0.2354 - val_accuracy: 0.8936\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 588us/step - loss: 0.0799 - accuracy: 0.9623 - val_loss: 0.2358 - val_accuracy: 0.8936\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.8936\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.8936\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0364 - accuracy: 0.9811 - val_loss: 0.2381 - val_accuracy: 0.8936\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0577 - accuracy: 0.9623 - val_loss: 0.2386 - val_accuracy: 0.8936\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.8936\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1323 - accuracy: 0.9623 - val_loss: 0.2401 - val_accuracy: 0.8936\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0575 - accuracy: 0.9623 - val_loss: 0.2405 - val_accuracy: 0.8936\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0446 - accuracy: 0.9811 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0949 - accuracy: 0.9623 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0884 - accuracy: 0.9434 - val_loss: 0.2441 - val_accuracy: 0.8936\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 555us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.8936\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.2488 - val_accuracy: 0.8936\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.8936\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.8936\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 579us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.8936\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8936\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0884 - accuracy: 0.9623 - val_loss: 0.2619 - val_accuracy: 0.8936\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0378 - accuracy: 0.9811 - val_loss: 0.2639 - val_accuracy: 0.8936\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.8936\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.8936\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0360 - accuracy: 0.9811 - val_loss: 0.2675 - val_accuracy: 0.8936\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.8936\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0537 - accuracy: 0.9623 - val_loss: 0.2651 - val_accuracy: 0.8936\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0460 - accuracy: 0.9811 - val_loss: 0.2627 - val_accuracy: 0.8936\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.8936\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0576 - accuracy: 0.9623 - val_loss: 0.2616 - val_accuracy: 0.8936\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.2631 - val_accuracy: 0.8936\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 848us/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.2707 - val_accuracy: 0.8936\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0298 - accuracy: 0.9811 - val_loss: 0.2823 - val_accuracy: 0.8936\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.2924 - val_accuracy: 0.8936\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 582us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1293 - accuracy: 0.9623 - val_loss: 0.3033 - val_accuracy: 0.8936\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1002 - accuracy: 0.9434 - val_loss: 0.3051 - val_accuracy: 0.8936\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1404 - accuracy: 0.9811 - val_loss: 0.3040 - val_accuracy: 0.8936\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0867 - accuracy: 0.9434 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0915 - accuracy: 0.9623 - val_loss: 0.3045 - val_accuracy: 0.8936\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0553 - accuracy: 0.9623 - val_loss: 0.3044 - val_accuracy: 0.8936\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0722 - accuracy: 0.9623 - val_loss: 0.3028 - val_accuracy: 0.8936\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 530us/step - loss: 0.0369 - accuracy: 0.9811 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0809 - accuracy: 0.9623 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8936\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.1133 - accuracy: 0.9434 - val_loss: 0.2815 - val_accuracy: 0.8936\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 689us/step - loss: 0.0273 - accuracy: 0.9811 - val_loss: 0.2733 - val_accuracy: 0.8936\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0419 - accuracy: 0.9811 - val_loss: 0.2677 - val_accuracy: 0.8936\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0593 - accuracy: 0.9623 - val_loss: 0.2641 - val_accuracy: 0.8723\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0678 - accuracy: 0.9623 - val_loss: 0.2636 - val_accuracy: 0.8936\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0823 - accuracy: 0.9623 - val_loss: 0.2624 - val_accuracy: 0.8936\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0797 - accuracy: 0.9434 - val_loss: 0.2626 - val_accuracy: 0.8936\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0370 - accuracy: 0.9623 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6faecd9cc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.plot(history_Adam_1.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam_1.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "\n",
    "# Zad.\n",
    "Do do modelu \n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
    "```\n",
    "\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.8459 - accuracy: 0.5472 - val_loss: 0.8222 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.7898 - accuracy: 0.4906 - val_loss: 0.7719 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.8100 - accuracy: 0.4528 - val_loss: 0.7439 - val_accuracy: 0.6170\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.7288 - accuracy: 0.7547 - val_loss: 0.7805 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.7237 - accuracy: 0.5472 - val_loss: 0.8047 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 265us/step - loss: 0.7268 - accuracy: 0.5472 - val_loss: 0.7371 - val_accuracy: 0.5532\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.6677 - accuracy: 0.7170 - val_loss: 0.6624 - val_accuracy: 0.7234\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 599us/step - loss: 0.6293 - accuracy: 0.8302 - val_loss: 0.6468 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 497us/step - loss: 0.6016 - accuracy: 0.8113 - val_loss: 0.6208 - val_accuracy: 0.7660\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 674us/step - loss: 0.5586 - accuracy: 0.8491 - val_loss: 0.5899 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.5173 - accuracy: 0.8302 - val_loss: 0.5749 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4883 - accuracy: 0.8302 - val_loss: 0.5673 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4609 - accuracy: 0.8491 - val_loss: 0.5721 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4380 - accuracy: 0.8491 - val_loss: 0.5884 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.4286 - accuracy: 0.8679 - val_loss: 0.6098 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.4181 - accuracy: 0.8679 - val_loss: 0.6198 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.4061 - accuracy: 0.8679 - val_loss: 0.6278 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 484us/step - loss: 0.3982 - accuracy: 0.8679 - val_loss: 0.6248 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 745us/step - loss: 0.3880 - accuracy: 0.8679 - val_loss: 0.6190 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3776 - accuracy: 0.8679 - val_loss: 0.6018 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3675 - accuracy: 0.8679 - val_loss: 0.5759 - val_accuracy: 0.8085\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3585 - accuracy: 0.8868 - val_loss: 0.5567 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3532 - accuracy: 0.8868 - val_loss: 0.5451 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3431 - accuracy: 0.8868 - val_loss: 0.5484 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3485 - accuracy: 0.9057 - val_loss: 0.5638 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.3357 - accuracy: 0.9057 - val_loss: 0.5540 - val_accuracy: 0.7872\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3358 - accuracy: 0.8868 - val_loss: 0.5369 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3272 - accuracy: 0.9057 - val_loss: 0.5384 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3245 - accuracy: 0.8868 - val_loss: 0.5456 - val_accuracy: 0.8298\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3206 - accuracy: 0.9057 - val_loss: 0.5478 - val_accuracy: 0.8298\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.3175 - accuracy: 0.9057 - val_loss: 0.5482 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3155 - accuracy: 0.9057 - val_loss: 0.5562 - val_accuracy: 0.8298\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3112 - accuracy: 0.8868 - val_loss: 0.5560 - val_accuracy: 0.8298\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.90 - 0s 548us/step - loss: 0.3107 - accuracy: 0.8868 - val_loss: 0.5647 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3057 - accuracy: 0.8868 - val_loss: 0.5575 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.3029 - accuracy: 0.8868 - val_loss: 0.5541 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.3016 - accuracy: 0.8868 - val_loss: 0.5576 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2983 - accuracy: 0.8868 - val_loss: 0.5540 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2957 - accuracy: 0.9057 - val_loss: 0.5428 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2935 - accuracy: 0.9057 - val_loss: 0.5410 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2920 - accuracy: 0.9057 - val_loss: 0.5416 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2900 - accuracy: 0.9057 - val_loss: 0.5401 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2860 - accuracy: 0.9057 - val_loss: 0.5500 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2841 - accuracy: 0.9057 - val_loss: 0.5612 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2833 - accuracy: 0.9245 - val_loss: 0.5611 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2816 - accuracy: 0.9245 - val_loss: 0.5463 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2778 - accuracy: 0.9057 - val_loss: 0.5324 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2782 - accuracy: 0.9245 - val_loss: 0.5213 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2729 - accuracy: 0.9245 - val_loss: 0.5261 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2709 - accuracy: 0.9245 - val_loss: 0.5233 - val_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.2701 - accuracy: 0.9245 - val_loss: 0.5264 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2667 - accuracy: 0.9434 - val_loss: 0.5145 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.2639 - accuracy: 0.9245 - val_loss: 0.5009 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2613 - accuracy: 0.9245 - val_loss: 0.4945 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2601 - accuracy: 0.9245 - val_loss: 0.4905 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.2571 - accuracy: 0.9245 - val_loss: 0.4945 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2555 - accuracy: 0.9245 - val_loss: 0.5061 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 560us/step - loss: 0.2534 - accuracy: 0.9623 - val_loss: 0.5041 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2501 - accuracy: 0.9623 - val_loss: 0.4940 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2471 - accuracy: 0.9623 - val_loss: 0.4858 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2461 - accuracy: 0.9434 - val_loss: 0.4850 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.2420 - accuracy: 0.9434 - val_loss: 0.4732 - val_accuracy: 0.8511\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 341us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.4681 - val_accuracy: 0.8511\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2382 - accuracy: 0.9245 - val_loss: 0.4711 - val_accuracy: 0.8511\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2350 - accuracy: 0.9623 - val_loss: 0.4860 - val_accuracy: 0.8511\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2325 - accuracy: 0.9623 - val_loss: 0.4938 - val_accuracy: 0.8511\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 303us/step - loss: 0.2317 - accuracy: 0.9623 - val_loss: 0.4896 - val_accuracy: 0.8511\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2285 - accuracy: 0.9623 - val_loss: 0.4731 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.2239 - accuracy: 0.9623 - val_loss: 0.4590 - val_accuracy: 0.8511\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 466us/step - loss: 0.2210 - accuracy: 0.9623 - val_loss: 0.4430 - val_accuracy: 0.8511\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.2196 - accuracy: 0.9623 - val_loss: 0.4295 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 649us/step - loss: 0.2172 - accuracy: 0.9434 - val_loss: 0.4254 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.2139 - accuracy: 0.9623 - val_loss: 0.4342 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2113 - accuracy: 0.9811 - val_loss: 0.4351 - val_accuracy: 0.8936\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.2095 - accuracy: 0.9811 - val_loss: 0.4196 - val_accuracy: 0.8936\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2059 - accuracy: 0.9811 - val_loss: 0.3928 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.2022 - accuracy: 0.9811 - val_loss: 0.3788 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.2008 - accuracy: 0.9623 - val_loss: 0.3753 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1964 - accuracy: 0.9623 - val_loss: 0.3830 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1937 - accuracy: 0.9811 - val_loss: 0.3840 - val_accuracy: 0.8723\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1894 - accuracy: 0.9811 - val_loss: 0.3917 - val_accuracy: 0.8936\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1898 - accuracy: 0.9811 - val_loss: 0.3949 - val_accuracy: 0.8936\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1876 - accuracy: 0.9811 - val_loss: 0.3760 - val_accuracy: 0.8936\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.1816 - accuracy: 0.9811 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1796 - accuracy: 0.9811 - val_loss: 0.3429 - val_accuracy: 0.8723\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1770 - accuracy: 0.9811 - val_loss: 0.3354 - val_accuracy: 0.8936\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1754 - accuracy: 0.9811 - val_loss: 0.3241 - val_accuracy: 0.8936\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 646us/step - loss: 0.1718 - accuracy: 0.9811 - val_loss: 0.3260 - val_accuracy: 0.8936\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1725 - accuracy: 0.9811 - val_loss: 0.3351 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1669 - accuracy: 0.9811 - val_loss: 0.3260 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1636 - accuracy: 0.9811 - val_loss: 0.3183 - val_accuracy: 0.8936\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1608 - accuracy: 0.9811 - val_loss: 0.3153 - val_accuracy: 0.8936\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1607 - accuracy: 0.9811 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1570 - accuracy: 0.9811 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1547 - accuracy: 0.9811 - val_loss: 0.2945 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1533 - accuracy: 0.9811 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1507 - accuracy: 0.9811 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1485 - accuracy: 0.9811 - val_loss: 0.2953 - val_accuracy: 0.9149\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1462 - accuracy: 0.9811 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1447 - accuracy: 0.9811 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1434 - accuracy: 0.9811 - val_loss: 0.2949 - val_accuracy: 0.9149\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1423 - accuracy: 0.9811 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1407 - accuracy: 0.9811 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9149\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1269 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.8936\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 944us/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9362\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9362\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9362\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9362\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9362\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9362\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 887us/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9362\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9362\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9362\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.8936\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.8936\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.8936\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9362\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.8936\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.8936\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.8936\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9362\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.8936\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 604us/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.8936\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.8936\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.8936\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.8936\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 963us/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.8936\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.8936\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.8936\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8936\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.8936\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.8936\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.8936\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.8936\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8936\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.8936\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.8936\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.8936\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.8936\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8936\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.8936\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.8936\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.8936\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.8936\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.8936\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.8936\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.8936\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8936\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.8936\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.8936\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.8936\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8936\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.8936\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.8936\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8936\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8936\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.8936\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.8936\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.8936\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.8936\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8936\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8936\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.8936\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.8936\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.8936\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.8936\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.8936\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.8936\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.8936\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.8936\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.8936\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.8936\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.8936\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8936\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8936\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.8936\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8936\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.8936\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.8936\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.8936\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.8936\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.8936\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.8936\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8936\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 473us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8936\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 692us/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.8936\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.8936\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.00 - 0s 529us/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.8936\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.8936\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8936\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.8936\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.8936\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8936\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.8936\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.8936\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.8936\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8936\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.8936\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8936\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8936\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8936\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8936\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8936\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.8936\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8936\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8936\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.8936\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8936\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 552us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 558us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 1.00 - 0s 585us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 492us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8936\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8936\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.8936\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.8936\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.8936\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 848us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.8936\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 322us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.00 - 0s 897us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 1.00 - 0s 529us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8936\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.8936\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 384us/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 724us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 336us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 801us/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.8936\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.8936\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 410us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 668us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 392us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.8936\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 806us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.8936\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8936\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.8936\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.8936\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.8936\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.8936\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.8936\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.8936\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.8936\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.8936\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 548us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.8936\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 314us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.8936\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 825us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8936\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8936\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.8936\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.8936\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.8936\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.8936\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.8936\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.8936\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.8936\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.8936\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.8936\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.8936\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.8936\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.8936\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 400us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.8936\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.8936\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 649us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.8936\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.8936\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.8936\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8936\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 314us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.8936\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.8936\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 860us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.8936\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 317us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.8936\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.8936\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.8936\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.8936\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 409us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.8936\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.8936\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8936\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8936\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 760us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8936\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8936\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8936\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8936\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 467us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 492us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8936\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 729us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 1.00 - 0s 529us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 354us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 625us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 360us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - 0s 295us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 549us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 315us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 295us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 609us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 578us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 831us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 812us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 680us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 717us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 718us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 829us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.00 - 0s 247us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.00 - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 295us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 776us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 246us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 615us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 656us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 642us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 585us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9362\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 521us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9362\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9362\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9362\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 353us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 676us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 447us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 295us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 590us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 589us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 636us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 491us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9362\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 548us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 623us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 661us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 604us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 566us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9362\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9362\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9362\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9362\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9362\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9362\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9362\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 491us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9362\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9362\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9362\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 529us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 510us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6fb0cdc898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "history_Adam_2 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],), activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(500,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(200,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "# plt.plot(history_Adam_1.history['loss'], label = \"tarina dropout\")\n",
    "# plt.plot(history_Adam_1.history['val_loss'], label = \"test dropout\")\n",
    "\n",
    "plt.plot(history_Adam_2.history['loss'], label = \"tarina l1\")\n",
    "plt.plot(history_Adam_2.history['val_loss'], label = \"test l1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
