{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wielowarstwowa sieć neuronowa\n",
    "\n",
    "(*Multilayer perceptron*, *feedforward neural network*)\n",
    "\n",
    "\n",
    "<img src=\"Grafika/MLP.jpg\" width=\"700\">\n",
    "Źródło: https://www.intechopen.com/source/html/39071/media/f2.jpg\n",
    "\n",
    "\n",
    "**Uwaga:** \"Input layer\" pomimo tego, że ma w nazwie słowo \"warstwa\", to tak naprawdę to nie jest żadna warstwa sieci... To są po prostu dane wejściowe... Niestety przyjęło się literaturze nazywanie tego w ten sposób, co jest mylące :(\n",
    "\n",
    "\n",
    "Sieci uczy sie metodą spadku gradientu (pewnymi wariantami tej metody). Uczenie wykorzystuje algorytm **propagacji wstecznej** (https://en.wikipedia.org/wiki/Backpropagation).\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Uwaga!** Sieci neuronowe absolutnie zawsze wymagają zestandaryzowanych danych! Niezależnie od tego czy wykorzystujemy regularyzację czy nie i niezależnie od typu sieci!\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Wizualizacja obszarów decyzyjnych w zależności od liczby neuronów\n",
    "\n",
    "### (sieć jednowarstwowa)\n",
    "\n",
    "<img src=\"Grafika/nn-from-scratch-hidden-layer-varying-655x1024.png\" width=\"700\">\n",
    "Źródło: http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/nn-from-scratch-hidden-layer-varying-655x1024.png\n",
    "\n",
    "<br>\n",
    "\n",
    "### Fakt matematyczny: jednowarstwową siecią możemy otrzymać dowolny kształt. \n",
    "\n",
    "Co z tego wynika? To, że (teoretycznie) zawsze wystarczy sieć jednowarstwowa (odpowiednio duża). W praktyce rzeczywiście z reguły wystarcza jedna warstwa, ale mimo wszystko zawsze warto sprawdzić czy 2 (lub 3) nie zadziałają przypadkiem lepiej. Przy czym jeżeli dla dwóch wartsw jest gorzej, to nie ma sensu sprawdzać dla większej ilości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "* Wczytaj zbiór danych\n",
    "* Podziel dane na train test\n",
    "* Wykonaj uczenie modeli (dobierz najlepsze parametry)\n",
    "    * LogisticRegression\n",
    "    * LinearSVC\n",
    "    * SVC\n",
    "    * KNeighborsClassifier\n",
    "    * DecisionTreeClassifier\n",
    "    * RandomForestClassifier\n",
    "    * BaggingClassifier\n",
    "    * ExtraTreesClassifier\n",
    "    * AdaBoostClassifier\n",
    "    * GradientBoostingClassifier\n",
    "    * VotingClassifier\n",
    "    * xgboost.XGBClassifier\n",
    "* Porównaj wyniki na zbiorze uczącym    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "0.3489583333333333\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('Dane/pima-indians-diabetes.data', delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "print(X.shape)\n",
    "print(np.mean(Y))\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.001, 'preprocessing': StandardScaler()}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', LinearSVC(C=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10,\n",
       " 'classifier__gamma': 0.001,\n",
       " 'preprocessing': StandardScaler()}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2 = Pipeline([('preprocessing', StandardScaler()), ('classifier', SVC(C=1, probability=True))])\n",
    "\n",
    "param_grid_2 = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe_2, param_grid_2, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 1, 'preprocessing': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_3 = Pipeline([('preprocessing', StandardScaler()), ('classifier', LogisticRegression(C=1))])\n",
    "\n",
    "param_grid_3 = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(pipe_3, param_grid_3, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_4 = Pipeline([('preprocessing', StandardScaler()), ('classifier', KNeighborsClassifier(n_neighbors=2, metric='euclidean'))])\n",
    "\n",
    "param_grid_4 = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__n_neighbors': [2, 5, 10, 11,12],\n",
    "            'classifier__metric': ['euclidean', 'cityblock', 'cosine']\n",
    "}\n",
    "\n",
    "\n",
    "grid_4 = GridSearchCV(pipe_4, param_grid_4, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eb0e4969a02a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m pipe_5 = Pipeline([('preprocessing', StandardScaler()), \n\u001b[0m\u001b[0;32m      4\u001b[0m                    ('classifier', DecisionTreeClassifier())])\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_5 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "param_grid_5 = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__max_depth': [5,9,10,11,20,30],\n",
    "            'classifier__min_samples_split': [2,3,5,10,20,30,40],\n",
    "            'classifier__max_leaf_nodes': [3,4,10,14,15,16,20,30,40]\n",
    "}\n",
    "\n",
    "\n",
    "grid_5 = GridSearchCV(pipe_5, param_grid_5, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_5.fit(X_train, y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3526fb6a23ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m pipe_6 = Pipeline([('preprocessing', StandardScaler()), \n\u001b[0m\u001b[0;32m      5\u001b[0m                    ('classifier', BaggingClassifier(\n\u001b[0;32m      6\u001b[0m                                     \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_6 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', BaggingClassifier(\n",
    "                                    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "                                    max_samples=100, bootstrap=True, random_state=42))\n",
    "                  ])\n",
    "\n",
    "param_grid_6 = {\n",
    "                'preprocessing': [StandardScaler(), None],\n",
    "                'classifier__n_estimators': [10,50,100],\n",
    "                'classifier__max_samples': [10,20]\n",
    "             }\n",
    "\n",
    "grid_6 = GridSearchCV(pipe_6, param_grid_6, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_6.fit(X_train, y_train)\n",
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9c122d855292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m pipe_7 = Pipeline([('preprocessing', StandardScaler()), \n\u001b[0m\u001b[0;32m      4\u001b[0m                    \u001b[1;33m(\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_7 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', RandomForestClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_7 = {\n",
    "              'preprocessing': [StandardScaler(), None],\n",
    "              'classifier__n_estimators': [10, 50, 100],\n",
    "              'classifier__max_leaf_nodes': [10, 20],\n",
    "              'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_7 = GridSearchCV(pipe_7, param_grid_7, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_7.fit(X_train, y_train)\n",
    "grid_7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 20,\n",
       " 'classifier__max_leaf_nodes': 20,\n",
       " 'classifier__n_estimators': 50,\n",
       " 'preprocessing': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pipe_8 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_8 = {\n",
    "              'preprocessing': [StandardScaler(), None],\n",
    "              'classifier__n_estimators': [10, 50, 100],\n",
    "              'classifier__max_leaf_nodes': [10, 20],\n",
    "              'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_8 = GridSearchCV(pipe_8, param_grid_8, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_8.fit(X_train, y_train)\n",
    "grid_8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.1,\n",
       " 'classifier__n_estimators': 200,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_9 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', AdaBoostClassifier(\n",
    "                        DecisionTreeClassifier(max_depth=1), \n",
    "                        n_estimators=1, learning_rate=0.5, \n",
    "                        algorithm=\"SAMME.R\", random_state=42)\n",
    "                   )\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_9 = {\n",
    "              'preprocessing': [StandardScaler(), None],\n",
    "              'classifier__n_estimators': [50, 100, 200],\n",
    "              'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_9 = GridSearchCV(pipe_9, param_grid_9, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_9.fit(X_train, y_train)\n",
    "grid_9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.2,\n",
       " 'classifier__n_estimators': 50,\n",
       " 'preprocessing': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_10 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', GradientBoostingClassifier(\n",
    "                       n_estimators=1, \n",
    "                      learning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_10 = {\n",
    "              'preprocessing': [StandardScaler(), None],\n",
    "              'classifier__n_estimators': [50, 100, 200],\n",
    "              'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_10 = GridSearchCV(pipe_10, param_grid_10, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_10.fit(X_train, y_train)\n",
    "grid_10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.2,\n",
       " 'classifier__n_estimators': 50,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import xgboost\n",
    "pipe_11 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', xgboost.XGBClassifier(n_estimators=1, \n",
    "                      leaarning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_11 = {\n",
    "              'preprocessing': [StandardScaler(), None],\n",
    "              'classifier__n_estimators': [50, 100, 200],\n",
    "              'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_11 = GridSearchCV(pipe_11, param_grid_11, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_11.fit(X_train, y_train)\n",
    "grid_11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'preprocessing': None,\n",
       " 'classifier__subsample': 0.5,\n",
       " 'classifier__n_estimators': 200,\n",
       " 'classifier__min_child_weight': 1,\n",
       " 'classifier__max_depth': 3,\n",
       " 'classifier__learning_rate': 0.01,\n",
       " 'classifier__gamma': 2,\n",
       " 'classifier__colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator = xgboost.XGBClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_12 = Pipeline([('preprocessing', StandardScaler()), \n",
    "                   ('classifier', xgboost.XGBClassifier(n_jobs=-1))\n",
    "                  ])\n",
    "\n",
    "param_grid_12 = {\n",
    "    'preprocessing': [StandardScaler(), None],\n",
    "    'classifier__max_depth': [3, 5, 8, 10],\n",
    "    'classifier__learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'classifier__n_estimators': [50, 100, 150, 200, 400],\n",
    "    'classifier__gamma': [0, 0.5, 1, 2],\n",
    "    'classifier__colsample_bytree': [1, 0.8, 0.5],\n",
    "    'classifier__subsample': [1, 0.8, 0.5],\n",
    "    'classifier__min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_12 = RandomizedSearchCV(n_iter=30,estimator=pipe_12, \n",
    "                             param_distributions=param_grid_12, \n",
    "                      cv=kfold, \n",
    "                      return_train_score=True)\n",
    "\n",
    "grid_12.fit(X_train, y_train)\n",
    "grid_12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('grid_2', Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probabil...0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.5, verbosity=1))]))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('grid_2', grid_2.best_estimator_), \n",
    "                ('grid_3', grid_3.best_estimator_), \n",
    "                ('grid_4', grid_4.best_estimator_), \n",
    "                ('grid_5', grid_5.best_estimator_), \n",
    "                ('grid_6', grid_6.best_estimator_), \n",
    "                ('grid_7', grid_7.best_estimator_), \n",
    "                ('grid_8', grid_8.best_estimator_), \n",
    "                ('grid_9', grid_9.best_estimator_),\n",
    "                ('grid_10', grid_10.best_estimator_), \n",
    "                ('grid_12', grid_12.best_estimator_)\n",
    "               ],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM linear\n",
      "precision_score: 0.7432432432432432\n",
      "recall_score: 0.5978260869565217\n",
      "f1_score: 0.6626506024096386\n",
      "accuracy_score: 0.7795275590551181\n",
      "roc_auc_score: 0.829777241009125\n",
      "SVM rbf\n",
      "precision_score: 0.7368421052631579\n",
      "recall_score: 0.6086956521739131\n",
      "f1_score: 0.6666666666666666\n",
      "accuracy_score: 0.7795275590551181\n",
      "roc_auc_score: 0.838130703166935\n",
      "LR\n",
      "precision_score: 0.7215189873417721\n",
      "recall_score: 0.6195652173913043\n",
      "f1_score: 0.6666666666666666\n",
      "accuracy_score: 0.7755905511811023\n",
      "roc_auc_score: 0.8299785292538916\n",
      "KNN\n",
      "precision_score: 0.7121212121212122\n",
      "recall_score: 0.5108695652173914\n",
      "f1_score: 0.5949367088607596\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.7864667203435319\n",
      "DecisionTreeClassifier\n",
      "precision_score: 0.6153846153846154\n",
      "recall_score: 0.6086956521739131\n",
      "f1_score: 0.6120218579234973\n",
      "accuracy_score: 0.7204724409448819\n",
      "roc_auc_score: 0.7340646806226516\n",
      "BaggingClassifier\n",
      "precision_score: 0.6730769230769231\n",
      "recall_score: 0.3804347826086957\n",
      "f1_score: 0.48611111111111116\n",
      "accuracy_score: 0.7086614173228346\n",
      "roc_auc_score: 0.8068303811057433\n",
      "RandomForestClassifier\n",
      "precision_score: 0.7083333333333334\n",
      "recall_score: 0.5543478260869565\n",
      "f1_score: 0.6219512195121951\n",
      "accuracy_score: 0.7559055118110236\n",
      "roc_auc_score: 0.8346081588835212\n",
      "ExtraTreesClassifier\n",
      "precision_score: 0.7857142857142857\n",
      "recall_score: 0.4782608695652174\n",
      "f1_score: 0.5945945945945946\n",
      "accuracy_score: 0.7637795275590551\n",
      "roc_auc_score: 0.8369565217391304\n",
      "AdaBoostClassifier\n",
      "precision_score: 0.651685393258427\n",
      "recall_score: 0.6304347826086957\n",
      "f1_score: 0.6408839779005525\n",
      "accuracy_score: 0.7440944881889764\n",
      "roc_auc_score: 0.8137748255501879\n",
      "GradientBoostingClassifier\n",
      "precision_score: 0.648936170212766\n",
      "recall_score: 0.6630434782608695\n",
      "f1_score: 0.6559139784946236\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.8161567364465915\n",
      "XGBClassifier\n",
      "precision_score: 0.6704545454545454\n",
      "recall_score: 0.6413043478260869\n",
      "f1_score: 0.6555555555555556\n",
      "accuracy_score: 0.7559055118110236\n",
      "roc_auc_score: 0.8150831991411701\n",
      "XGBClassifier r2\n",
      "precision_score: 0.6842105263157895\n",
      "recall_score: 0.5652173913043478\n",
      "f1_score: 0.6190476190476191\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.833467525496511\n",
      "voting_clf\n",
      "precision_score: 0.72\n",
      "recall_score: 0.5869565217391305\n",
      "f1_score: 0.6467065868263473\n",
      "accuracy_score: 0.7677165354330708\n",
      "roc_auc_score: 0.8410493827160493\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "models.append(('LR', grid_3.best_estimator_))\n",
    "models.append(('KNN', grid_4.best_estimator_))\n",
    "models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "models.append(('voting_clf', voting_clf))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "    if (name == 'SVM linear'):\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.decision_function(X_test)) ))            \n",
    "    else:\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]) ))\n",
    "    \n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n",
    "    if (name == 'SVM linear'):\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.decision_function(X_test)))        \n",
    "    else:    \n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM linear</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.829777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM rbf</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.838131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.829979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.786467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.734065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.806830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.834608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.836957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.813775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.816157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.815083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier r</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.833468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.646707</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.841049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Method  precision_score  recall_score  f1_score  \\\n",
       "0                   SVM linear         0.743243      0.597826  0.662651   \n",
       "1                      SVM rbf         0.736842      0.608696  0.666667   \n",
       "2                           LR         0.721519      0.619565  0.666667   \n",
       "3                          KNN         0.712121      0.510870  0.594937   \n",
       "4       DecisionTreeClassifier         0.615385      0.608696  0.612022   \n",
       "5            BaggingClassifier         0.673077      0.380435  0.486111   \n",
       "6       RandomForestClassifier         0.708333      0.554348  0.621951   \n",
       "7         ExtraTreesClassifier         0.785714      0.478261  0.594595   \n",
       "8           AdaBoostClassifier         0.651685      0.630435  0.640884   \n",
       "9   GradientBoostingClassifier         0.648936      0.663043  0.655914   \n",
       "10               XGBClassifier         0.670455      0.641304  0.655556   \n",
       "11             XGBClassifier r         0.684211      0.565217  0.619048   \n",
       "12                      voting         0.720000      0.586957  0.646707   \n",
       "\n",
       "    accuracy_score  roc_auc_score  \n",
       "0         0.779528       0.829777  \n",
       "1         0.779528       0.838131  \n",
       "2         0.775591       0.829979  \n",
       "3         0.748031       0.786467  \n",
       "4         0.720472       0.734065  \n",
       "5         0.708661       0.806830  \n",
       "6         0.755906       0.834608  \n",
       "7         0.763780       0.836957  \n",
       "8         0.744094       0.813775  \n",
       "9         0.748031       0.816157  \n",
       "10        0.755906       0.815083  \n",
       "11        0.748031       0.833468  \n",
       "12        0.767717       0.841049  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score,\n",
    "     'roc_auc_score' : roc_auc_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM linear','SVM rbf','LR','KNN', 'DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','XGBClassifier r', 'voting'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier\n",
    "\n",
    "Dodajmy model sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.50% AUC:  0.6955179817498658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier((20,10))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "predictions = y_pred.round()\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", metrics.roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__hidden_layer_sizes': 1000,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_14 = Pipeline([('preprocessing', StandardScaler()), ('classifier', MLPClassifier(activation=\"tanh\",early_stopping=True,validation_fraction=0.15,max_iter=1000))])\n",
    "\n",
    "param_grid_14 = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__hidden_layer_sizes': [(5),(10),(15),(30),(50),(100),(250),(500),(750),(1000),(2000)]\n",
    "}\n",
    "\n",
    "grid_14 = GridSearchCV(pipe_14, param_grid_14, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_14.fit(X_train, y_train)\n",
    "grid_14.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM linear\n",
      "precision_score: 0.7432432432432432\n",
      "recall_score: 0.5978260869565217\n",
      "f1_score: 0.6626506024096386\n",
      "accuracy_score: 0.7795275590551181\n",
      "roc_auc_score: 0.829777241009125\n",
      "SVM rbf\n",
      "precision_score: 0.7368421052631579\n",
      "recall_score: 0.6086956521739131\n",
      "f1_score: 0.6666666666666666\n",
      "accuracy_score: 0.7795275590551181\n",
      "roc_auc_score: 0.838130703166935\n",
      "LR\n",
      "precision_score: 0.7215189873417721\n",
      "recall_score: 0.6195652173913043\n",
      "f1_score: 0.6666666666666666\n",
      "accuracy_score: 0.7755905511811023\n",
      "roc_auc_score: 0.8299785292538916\n",
      "KNN\n",
      "precision_score: 0.7121212121212122\n",
      "recall_score: 0.5108695652173914\n",
      "f1_score: 0.5949367088607596\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.7864667203435319\n",
      "DecisionTreeClassifier\n",
      "precision_score: 0.6153846153846154\n",
      "recall_score: 0.6086956521739131\n",
      "f1_score: 0.6120218579234973\n",
      "accuracy_score: 0.7204724409448819\n",
      "roc_auc_score: 0.7340646806226516\n",
      "BaggingClassifier\n",
      "precision_score: 0.6730769230769231\n",
      "recall_score: 0.3804347826086957\n",
      "f1_score: 0.48611111111111116\n",
      "accuracy_score: 0.7086614173228346\n",
      "roc_auc_score: 0.8068303811057433\n",
      "RandomForestClassifier\n",
      "precision_score: 0.7083333333333334\n",
      "recall_score: 0.5543478260869565\n",
      "f1_score: 0.6219512195121951\n",
      "accuracy_score: 0.7559055118110236\n",
      "roc_auc_score: 0.8346081588835212\n",
      "ExtraTreesClassifier\n",
      "precision_score: 0.7857142857142857\n",
      "recall_score: 0.4782608695652174\n",
      "f1_score: 0.5945945945945946\n",
      "accuracy_score: 0.7637795275590551\n",
      "roc_auc_score: 0.8369565217391304\n",
      "AdaBoostClassifier\n",
      "precision_score: 0.651685393258427\n",
      "recall_score: 0.6304347826086957\n",
      "f1_score: 0.6408839779005525\n",
      "accuracy_score: 0.7440944881889764\n",
      "roc_auc_score: 0.8137748255501879\n",
      "GradientBoostingClassifier\n",
      "precision_score: 0.648936170212766\n",
      "recall_score: 0.6630434782608695\n",
      "f1_score: 0.6559139784946236\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.8161567364465915\n",
      "XGBClassifier\n",
      "precision_score: 0.6704545454545454\n",
      "recall_score: 0.6413043478260869\n",
      "f1_score: 0.6555555555555556\n",
      "accuracy_score: 0.7559055118110236\n",
      "roc_auc_score: 0.8150831991411701\n",
      "XGBClassifier r2\n",
      "precision_score: 0.6842105263157895\n",
      "recall_score: 0.5652173913043478\n",
      "f1_score: 0.6190476190476191\n",
      "accuracy_score: 0.7480314960629921\n",
      "roc_auc_score: 0.833467525496511\n",
      "voting_clf\n",
      "precision_score: 0.72\n",
      "recall_score: 0.5869565217391305\n",
      "f1_score: 0.6467065868263473\n",
      "accuracy_score: 0.7677165354330708\n",
      "roc_auc_score: 0.8410493827160493\n",
      "MLP\n",
      "precision_score: 0.7108433734939759\n",
      "recall_score: 0.6413043478260869\n",
      "f1_score: 0.6742857142857143\n",
      "accuracy_score: 0.7755905511811023\n",
      "roc_auc_score: 0.8256843800322061\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "models.append(('LR', grid_3.best_estimator_))\n",
    "models.append(('KNN', grid_4.best_estimator_))\n",
    "models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "models.append(('voting_clf', voting_clf))\n",
    "models.append(('MLP', grid_14.best_estimator_))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "    if (name == 'SVM linear'):\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.decision_function(X_test)) ))            \n",
    "    else:\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]) ))\n",
    "    \n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n",
    "    if (name == 'SVM linear'):\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.decision_function(X_test)))        \n",
    "    else:    \n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM linear</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.829777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM rbf</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.838131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.829979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.786467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.734065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.806830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.834608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.836957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.813775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.816157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.815083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier r</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.833468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>voting</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.646707</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.841049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.825684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Method  precision_score  recall_score  f1_score  \\\n",
       "0                   SVM linear         0.743243      0.597826  0.662651   \n",
       "1                      SVM rbf         0.736842      0.608696  0.666667   \n",
       "2                           LR         0.721519      0.619565  0.666667   \n",
       "3                          KNN         0.712121      0.510870  0.594937   \n",
       "4       DecisionTreeClassifier         0.615385      0.608696  0.612022   \n",
       "5            BaggingClassifier         0.673077      0.380435  0.486111   \n",
       "6       RandomForestClassifier         0.708333      0.554348  0.621951   \n",
       "7         ExtraTreesClassifier         0.785714      0.478261  0.594595   \n",
       "8           AdaBoostClassifier         0.651685      0.630435  0.640884   \n",
       "9   GradientBoostingClassifier         0.648936      0.663043  0.655914   \n",
       "10               XGBClassifier         0.670455      0.641304  0.655556   \n",
       "11             XGBClassifier r         0.684211      0.565217  0.619048   \n",
       "12                      voting         0.720000      0.586957  0.646707   \n",
       "13                         MLP         0.710843      0.641304  0.674286   \n",
       "\n",
       "    accuracy_score  roc_auc_score  \n",
       "0         0.779528       0.829777  \n",
       "1         0.779528       0.838131  \n",
       "2         0.775591       0.829979  \n",
       "3         0.748031       0.786467  \n",
       "4         0.720472       0.734065  \n",
       "5         0.708661       0.806830  \n",
       "6         0.755906       0.834608  \n",
       "7         0.763780       0.836957  \n",
       "8         0.744094       0.813775  \n",
       "9         0.748031       0.816157  \n",
       "10        0.755906       0.815083  \n",
       "11        0.748031       0.833468  \n",
       "12        0.767717       0.841049  \n",
       "13        0.775591       0.825684  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score,\n",
    "     'roc_auc_score' : roc_auc_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM linear','SVM rbf','LR','KNN', 'DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','XGBClassifier r', 'voting', 'MLP'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytaj dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n",
      "(15060, 41)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Porównaj wyniki sieci na:\n",
    "* oryginalnych danych \n",
    "* na wystandaryzowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=None, test_size=0.1, train_size=None),\n",
       "       error_score='accuracy',\n",
       "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.15, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [5, 10, 15, 30, 50, 100, 250, 500, 750, 1000, 2000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "\n",
    "params = {\"hidden_layer_sizes\": [(5),(10),(15),(30),(50),(100),(250),(500),(750),(1000),(2000)]}\n",
    "\n",
    "nnet = MLPClassifier(activation=\"tanh\",early_stopping=True,validation_fraction=0.15,max_iter=1000)\n",
    "gs = GridSearchCV(cv=ShuffleSplit(n_splits=1,test_size=0.1),error_score=\"accuracy\",estimator=nnet,param_grid=params)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8265604249667995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=None, test_size=0.15, train_size=None),\n",
       "       error_score='accuracy',\n",
       "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.15, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [5, 10, 15, 30, 50, 100, 250, 500, 750, 1000, 2000, 3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"hidden_layer_sizes\": [(5),(10),(15),(30),(50),(100),(250),(500),(750),(1000),(2000),(3000)]}\n",
    "\n",
    "nnet = MLPClassifier(activation=\"tanh\",early_stopping=True,validation_fraction=0.15,max_iter=1000)\n",
    "gs = GridSearchCV(cv=ShuffleSplit(n_splits=1,test_size=0.15),error_score=\"accuracy\",estimator=nnet,param_grid=params)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446879150066401"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
