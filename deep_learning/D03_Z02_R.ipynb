{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import History\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 46], [2, 41], [28, 38], [31, 41], [26], [26], [2, 38], [40, 2], [2, 41], [49, 17, 46, 49]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 46  0  0]\n",
      " [ 2 41  0  0]\n",
      " [28 38  0  0]\n",
      " [31 41  0  0]\n",
      " [26  0  0  0]\n",
      " [26  0  0  0]\n",
      " [ 2 38  0  0]\n",
      " [40  2  0  0]\n",
      " [ 2 41  0  0]\n",
      " [49 17 46 49]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 80.000001\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5526 - accuracy: 0.7778 - val_loss: 0.5826 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5510 - accuracy: 0.7778 - val_loss: 0.5826 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5495 - accuracy: 0.7778 - val_loss: 0.5826 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5480 - accuracy: 0.7778 - val_loss: 0.5826 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5465 - accuracy: 0.7778 - val_loss: 0.5826 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5451 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 0.5436 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5422 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5409 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.5395 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.5382 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5369 - accuracy: 0.7778 - val_loss: 0.5827 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5356 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5343 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5331 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5319 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5307 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5295 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5283 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5272 - accuracy: 0.7778 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5261 - accuracy: 0.7778 - val_loss: 0.5829 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5250 - accuracy: 0.7778 - val_loss: 0.5829 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5239 - accuracy: 0.7778 - val_loss: 0.5829 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5228 - accuracy: 0.7778 - val_loss: 0.5829 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5217 - accuracy: 0.7778 - val_loss: 0.5830 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 223us/step - loss: 0.5206 - accuracy: 0.7778 - val_loss: 0.5830 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5196 - accuracy: 0.7778 - val_loss: 0.5831 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5185 - accuracy: 0.7778 - val_loss: 0.5831 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5175 - accuracy: 0.7778 - val_loss: 0.5832 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5164 - accuracy: 0.7778 - val_loss: 0.5833 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5154 - accuracy: 0.7778 - val_loss: 0.5834 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5144 - accuracy: 0.7778 - val_loss: 0.5835 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5133 - accuracy: 0.7778 - val_loss: 0.5836 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5123 - accuracy: 0.7778 - val_loss: 0.5837 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5113 - accuracy: 0.7778 - val_loss: 0.5838 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5103 - accuracy: 0.7778 - val_loss: 0.5839 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5092 - accuracy: 0.7778 - val_loss: 0.5840 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5082 - accuracy: 0.7778 - val_loss: 0.5841 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5072 - accuracy: 0.7778 - val_loss: 0.5843 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5062 - accuracy: 0.7778 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5052 - accuracy: 0.7778 - val_loss: 0.5845 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5042 - accuracy: 0.7778 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5032 - accuracy: 0.7778 - val_loss: 0.5848 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5021 - accuracy: 0.7778 - val_loss: 0.5850 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5011 - accuracy: 0.7778 - val_loss: 0.5851 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5001 - accuracy: 0.7778 - val_loss: 0.5853 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4991 - accuracy: 0.7778 - val_loss: 0.5854 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4982 - accuracy: 0.7778 - val_loss: 0.5856 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4972 - accuracy: 0.7778 - val_loss: 0.5858 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4962 - accuracy: 0.7778 - val_loss: 0.5859 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4952 - accuracy: 0.7778 - val_loss: 0.5861 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4942 - accuracy: 0.7778 - val_loss: 0.5862 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4932 - accuracy: 0.7778 - val_loss: 0.5864 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4923 - accuracy: 0.7778 - val_loss: 0.5866 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4913 - accuracy: 0.7778 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4903 - accuracy: 0.7778 - val_loss: 0.5869 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4893 - accuracy: 0.7778 - val_loss: 0.5870 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4884 - accuracy: 0.7778 - val_loss: 0.5872 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4874 - accuracy: 0.7778 - val_loss: 0.5873 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4865 - accuracy: 0.7778 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4855 - accuracy: 0.7778 - val_loss: 0.5876 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4846 - accuracy: 0.7778 - val_loss: 0.5878 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4836 - accuracy: 0.7778 - val_loss: 0.5879 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4827 - accuracy: 0.7778 - val_loss: 0.5881 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4817 - accuracy: 0.7778 - val_loss: 0.5882 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4808 - accuracy: 0.7778 - val_loss: 0.5883 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.5885 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.5886 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4780 - accuracy: 0.7778 - val_loss: 0.5887 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.5888 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4762 - accuracy: 0.7778 - val_loss: 0.5890 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.5891 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.5892 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4734 - accuracy: 0.7778 - val_loss: 0.5893 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5894 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5895 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5896 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5897 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5898 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.5899 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.5900 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.5901 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.5902 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.5903 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5904 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.5904 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.5906 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.5908 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.5909 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.5910 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.5910 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5911 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.5912 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 224us/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5913 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5914 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5914 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5915 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.5916 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x43539e3358>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.000001\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 4, 50)             2500      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 2,701\n",
      "Trainable params: 201\n",
      "Non-trainable params: 2,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.5768 - accuracy: 0.7778 - val_loss: 0.7442 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5758 - accuracy: 0.7778 - val_loss: 0.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5747 - accuracy: 0.7778 - val_loss: 0.7452 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5737 - accuracy: 0.7778 - val_loss: 0.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5727 - accuracy: 0.7778 - val_loss: 0.7463 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5717 - accuracy: 0.7778 - val_loss: 0.7468 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.5708 - accuracy: 0.7778 - val_loss: 0.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5698 - accuracy: 0.7778 - val_loss: 0.7479 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5689 - accuracy: 0.7778 - val_loss: 0.7484 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 0.5679 - accuracy: 0.7778 - val_loss: 0.7489 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5670 - accuracy: 0.7778 - val_loss: 0.7495 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5661 - accuracy: 0.7778 - val_loss: 0.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5652 - accuracy: 0.7778 - val_loss: 0.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5643 - accuracy: 0.7778 - val_loss: 0.7511 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5635 - accuracy: 0.7778 - val_loss: 0.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5626 - accuracy: 0.7778 - val_loss: 0.7521 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5617 - accuracy: 0.7778 - val_loss: 0.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5609 - accuracy: 0.7778 - val_loss: 0.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5601 - accuracy: 0.7778 - val_loss: 0.7537 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.5593 - accuracy: 0.7778 - val_loss: 0.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.5585 - accuracy: 0.7778 - val_loss: 0.7548 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5577 - accuracy: 0.7778 - val_loss: 0.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5569 - accuracy: 0.7778 - val_loss: 0.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 0.5561 - accuracy: 0.7778 - val_loss: 0.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5554 - accuracy: 0.7778 - val_loss: 0.7570 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5546 - accuracy: 0.7778 - val_loss: 0.7575 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5539 - accuracy: 0.7778 - val_loss: 0.7580 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 459us/step - loss: 0.5532 - accuracy: 0.7778 - val_loss: 0.7586 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5525 - accuracy: 0.7778 - val_loss: 0.7591 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5518 - accuracy: 0.7778 - val_loss: 0.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.5511 - accuracy: 0.7778 - val_loss: 0.7602 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5504 - accuracy: 0.7778 - val_loss: 0.7608 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5497 - accuracy: 0.7778 - val_loss: 0.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5491 - accuracy: 0.7778 - val_loss: 0.7618 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5484 - accuracy: 0.7778 - val_loss: 0.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5478 - accuracy: 0.7778 - val_loss: 0.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 332us/step - loss: 0.5471 - accuracy: 0.7778 - val_loss: 0.7635 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 299us/step - loss: 0.5465 - accuracy: 0.7778 - val_loss: 0.7640 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5459 - accuracy: 0.7778 - val_loss: 0.7646 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5453 - accuracy: 0.7778 - val_loss: 0.7651 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 335us/step - loss: 0.5447 - accuracy: 0.7778 - val_loss: 0.7657 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5441 - accuracy: 0.7778 - val_loss: 0.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 446us/step - loss: 0.5436 - accuracy: 0.7778 - val_loss: 0.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5430 - accuracy: 0.7778 - val_loss: 0.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5424 - accuracy: 0.7778 - val_loss: 0.7679 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5419 - accuracy: 0.7778 - val_loss: 0.7684 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5413 - accuracy: 0.7778 - val_loss: 0.7690 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5408 - accuracy: 0.7778 - val_loss: 0.7695 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5403 - accuracy: 0.7778 - val_loss: 0.7701 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.5398 - accuracy: 0.7778 - val_loss: 0.7706 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.5392 - accuracy: 0.7778 - val_loss: 0.7712 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5387 - accuracy: 0.7778 - val_loss: 0.7717 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5382 - accuracy: 0.7778 - val_loss: 0.7723 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5378 - accuracy: 0.7778 - val_loss: 0.7729 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5373 - accuracy: 0.7778 - val_loss: 0.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5368 - accuracy: 0.7778 - val_loss: 0.7740 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5363 - accuracy: 0.7778 - val_loss: 0.7745 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5359 - accuracy: 0.7778 - val_loss: 0.7751 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5354 - accuracy: 0.7778 - val_loss: 0.7756 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5349 - accuracy: 0.7778 - val_loss: 0.7762 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5345 - accuracy: 0.7778 - val_loss: 0.7767 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5341 - accuracy: 0.7778 - val_loss: 0.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5336 - accuracy: 0.7778 - val_loss: 0.7779 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5332 - accuracy: 0.7778 - val_loss: 0.7784 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5328 - accuracy: 0.7778 - val_loss: 0.7790 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5324 - accuracy: 0.7778 - val_loss: 0.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5319 - accuracy: 0.7778 - val_loss: 0.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5315 - accuracy: 0.7778 - val_loss: 0.7806 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5311 - accuracy: 0.7778 - val_loss: 0.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5307 - accuracy: 0.7778 - val_loss: 0.7818 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5303 - accuracy: 0.7778 - val_loss: 0.7823 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5300 - accuracy: 0.7778 - val_loss: 0.7829 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5296 - accuracy: 0.7778 - val_loss: 0.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5292 - accuracy: 0.7778 - val_loss: 0.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5288 - accuracy: 0.7778 - val_loss: 0.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5285 - accuracy: 0.7778 - val_loss: 0.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5281 - accuracy: 0.7778 - val_loss: 0.7857 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 436us/step - loss: 0.5277 - accuracy: 0.7778 - val_loss: 0.7862 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5274 - accuracy: 0.7778 - val_loss: 0.7868 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5270 - accuracy: 0.7778 - val_loss: 0.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5267 - accuracy: 0.7778 - val_loss: 0.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5263 - accuracy: 0.7778 - val_loss: 0.7885 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5260 - accuracy: 0.7778 - val_loss: 0.7890 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5257 - accuracy: 0.7778 - val_loss: 0.7896 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5253 - accuracy: 0.7778 - val_loss: 0.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5250 - accuracy: 0.7778 - val_loss: 0.7907 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5247 - accuracy: 0.7778 - val_loss: 0.7912 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 222us/step - loss: 0.5244 - accuracy: 0.7778 - val_loss: 0.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5240 - accuracy: 0.7778 - val_loss: 0.7924 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5237 - accuracy: 0.7778 - val_loss: 0.7929 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5234 - accuracy: 0.7778 - val_loss: 0.7935 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5231 - accuracy: 0.7778 - val_loss: 0.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5228 - accuracy: 0.7778 - val_loss: 0.7946 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5225 - accuracy: 0.7778 - val_loss: 0.7952 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5222 - accuracy: 0.7778 - val_loss: 0.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 359us/step - loss: 0.5219 - accuracy: 0.7778 - val_loss: 0.7963 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5216 - accuracy: 0.7778 - val_loss: 0.7968 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5213 - accuracy: 0.7778 - val_loss: 0.7974 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 333us/step - loss: 0.5210 - accuracy: 0.7778 - val_loss: 0.7980 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 334us/step - loss: 0.5208 - accuracy: 0.7778 - val_loss: 0.7985 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x434a739940>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.999999\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxV5b3v8c8PEqTKIAXUQJDQljKY2RCCiAVFYhABkSqTA8eCimh7KwhoDlg49WC5x2N9SfUqCHrkRDz1MNw2asTG4gQxYLTMiRYhxErgCDKpiTz3j73ZN8NOsjMRsvJ9v155udf07OdhxW9Wnuz1W+acQ0REmr9WTd0BERFpGAp0ERGPUKCLiHiEAl1ExCMU6CIiHhHWVG/cpUsXFxUV1VRvLyLSLG3ZsuWQc65rsG1NFuhRUVHk5uY21duLiDRLZvZ5Vds05SIi4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh5RY6Cb2fNmdtDMtlWx3czsSTMrMLNPzCyx4bspIiI1CeUKfSVwXTXb04De/q/pwNP175aIiNRWjZ9Dd85tNLOoanYZA7zofHV4N5nZhWYW4Zz7ooH6WN5rc+Eff2uUpkVEzopLYiBtcYM32xBz6N2B/WWWC/3rKjGz6WaWa2a5xcXFDfDWIiJyRkPcKWpB1gV9aoZz7lngWYCkpKS6PVmjEX6qiYh4QUNcoRcCPcosRwJFDdCuiIjUQkME+nrgNv+nXVKAo402fy4iIlWqccrFzDKAoUAXMysEFgDhAM65Z4BMYCRQAJwEpjZWZ0VEpGqhfMplYg3bHXBvg/VIRETqRHeKioh4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRIQW6mV1nZrvNrMDM5gbZfqmZZZvZR2b2iZmNbPiuiohIdWoMdDNrDSwF0oD+wEQz619ht3TgFedcAjAB+ENDd1RERKoXyhV6MlDgnPvMOfcd8DIwpsI+Dujgf90RKGq4LoqISChCCfTuwP4yy4X+dWU9Akwxs0IgE7gvWENmNt3Mcs0st7i4uA7dFRGRqoQS6BZknauwPBFY6ZyLBEYC/2Fmldp2zj3rnEtyziV17dq19r0VEZEqhRLohUCPMsuRVJ5SuRN4BcA59wHQFujSEB0UEZHQhIWwz4dAbzPrBRzA90fPSRX22QdcA6w0s374Ar1R5lRufPlBik592hhNi4icFd1+8GPWTPhdg7db4xW6c64UmAm8AezE92mW7Wa20MxG+3d7AJhmZh8DGcAdzrmK0zIiItKIrKlyNykpyeXm5jbJe4uINFdmtsU5lxRsm+4UFRHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHhEWFN3QKQlKykpobCwkG+++aapuyLnmLZt2xIZGUl4eHjIxyjQRZpQYWEh7du3JyoqCjNr6u7IOcI5x+HDhyksLKRXr14hH6cpF5Em9M0339C5c2eFuZRjZnTu3LnWv7kp0EWamMJcgqnL94UCXaQFO3LkCH/4wx/qdOzIkSM5cuRIvd5/xYoVxMfHEx8fT5s2bYiJiSE+Pp65c+eG3Mb+/fu55ZZb6tyHyMjIoONIT0/niSeeqHO7TUFz6CIt2JlAnzFjRsjHOOdwzpGZmVnv9586dSpTp04FICoqiuzsbLp06VJpv9LSUsLCgsdVjx49WL16db374gW6QhdpwebOncunn35KfHw8s2fP5vjx41xzzTUkJiYSExPDunXrANi7dy/9+vVjxowZJCYmsn//fqKiojh06FBg27Rp07jssssYMWIEp06dAuC5555jwIABxMXFcdNNN3Hy5MmQ+5aens5dd93Ftddey9SpU/n0008ZMmQICQkJXH755WzevBmAgoIC4uPjAVi2bBnjx48nNTWV3r17M2/evEB706dPJykpicsuu4yFCxeWe6/FixeTnJzMwIED+eyzzyr1JT8/n9TUVC6//HKuuuoq9uzZU7t/6LNEV+gi54jf/N/t7Cj6ukHb7N+tAwtuuKzK7YsXL2bbtm3k5eUBvivhNWvW0KFDBw4dOkRKSgqjR48GYPfu3axYsSLoFE1+fj4ZGRk899xz3Hzzzbz66qtMmTKFcePGMW3aNMAX0MuXL+e+++4Luf8fffQRGzdupG3btpw8eZI333yTtm3bsmvXLm6//fZAqJf18ccfs3XrVsLCwvjpT3/KfffdR7du3Vi8eDE//OEPKS0tZdiwYYwfP57+/fsD0KlTJ3Jycnj++ef59a9/zdq1a8u1OX36dJYtW8aPf/xj3nvvPWbOnElWVlbI4zhbQgp0M7sO+D3QGljmnFscZJ+bgUcAB3zsnJvUgP0UkbPAOcdDDz3Exo0badWqFQcOHODLL78EoGfPnqSkpAQ9rlevXoGr5Msvv5y9e/cCsG3bNtLT0zly5AjHjx8nNTW1Vv0ZM2YMbdu2BeDbb79l5syZfPzxx4SFhfHpp58GPWb48OG0b98egL59+7Jv3z66detGRkYGy5cvp7S0lKKiInbs2BEI9IkTJwIwefLkSvP3R44cYdOmTdx0002BdaWlpbUax9lSY6CbWWtgKXAtUAh8aGbrnXM7yuzTG5gHDHbOfWVmFzVWh0W8qror6bNl1apVFBcXs2XLFsLDw4mKigp8dO6CCy6o8rjzzjsv8Lp169aBKZc77riDtWvXEhcXx8qVK3n77bdr1Z+y7/lv//Zv9OjRg5deeomSkhLatWsXUl9KS0vJz8/n97//PTk5OVx44YVMmTKl3EcCq/tEiXOOLl26BH6LOZeFMoeeDBQ45z5zzn0HvAyMqbDPNGCpc+4rAOfcwYbtpog0hvbt23Ps2LHA8tGjR7nooosIDw8nOzubzz//vF7tHzt2jIiICEpKSli1alW92jp69CgRERGYGS+88ALOuZCP/frrr2nfvj0dOnTgiy++4I033ii3/cwfVTMyMhg8eHC5bZ06dSIiIoI1a9YAcPr0aT7++ON6jaWxhDLl0h3YX2a5EBhYYZ+fApjZe/imZR5xzr1esSEzmw5MB7j00kvr0l8RaUCdO3dm8ODBREdHk5aWxpw5c7jhhhtISkoiPj6evn371qv9RYsWMXDgQHr27ElMTEy5Hx61NXPmTMaPH09GRgbDhw8vdyVek8TERPr37090dDQ/+tGPKoX2yZMnSU5OxszIyMiodPzLL7/MPffcwyOPPMJ3333HlClTiIuLq/NYGovV9FPOzH4OpDrnfuFfvhVIds7dV2afPwElwM1AJPAOEO2cq/JDqklJSS43N7f+IxBpxnbu3Em/fv2auhtyjgr2/WFmW5xzScH2D2XKpRDoUWY5EigKss8651yJc+7vwG6gd8i9FhGRegsl0D8EeptZLzNrA0wA1lfYZy0wDMDMuuCbgqn8YU4REWk0NQa6c64UmAm8AewEXnHObTezhWY22r/bG8BhM9sBZAOznXOHG6vTIiJSWUifQ3fOZQKZFdbNL/PaAb/2f4mISBPQrf8iIh6hQBcR8QgFukgLVp/yuQBPPPFE0IJbN954I/Hx8fzkJz+hY8eOgRK577//fshtL126tM43I23YsIGxY8cG3VZVuVwvUKCLtGCNFehr1qwhLy+PZcuWMWTIEPLy8sjLy+OKK64ot191NVHuvfdeJk+eXOe+tUQKdJEWrGL5XIAlS5YwYMAAYmNjWbBgAQAnTpzg+uuvJy4ujujoaFavXs2TTz5JUVERw4YNY9iwYSG/Z2RkJIsWLWLw4MGsWbOGZ555JlBi9+c//3mgDkzZB0xceeWVzJ07l+TkZPr06RO40q+qpC74SgWMHTuW/v37c++99wYtFfDCCy+QnJxMfHw8M2bM4PTp03X7hzxHqHyuyLnitbnwj781bJuXxEBapeKoARXL52ZlZZGfn09OTg7OOUaPHs3GjRspLi6mW7du/PnPfwZ8YdmxY0cef/zxKh9KUZ0LLriA9957D4DDhw9z9913A74fMCtXruSee+6pdIxzjpycHNavX8/ChQt5/fXXiYiIqLKk7ubNm9mxYwc9evTg2muvZd26deWmYbZt28aaNWt4//33CQsLY/r06bz88stMmtR8C8Uq0EUkICsri6ysLBISEgA4fvw4+fn5DBkyhFmzZjFnzhxGjRrFkCFD6vU+ZR8Z98knnzB//nyOHDnCsWPHGDVqVNBjxo0bB5Qvz1tdSd2UlBSioqIAmDBhAu+++265QN+wYQMffvghSUm+u+hPnTpFjx5lb4pvfhToIueKaq6kzxbnHPPmzeOuu+6qtG3Lli1kZmYyb948RowYwfz584O0EJqyZXFvu+02XnvtNaKjo1m2bBmbNm0KesyZYlxnSuJC9SV1K5bErbjsnOOf/umfWLRoUZ3Hca7RHLpIC1axfG5qairPP/88x48fB+DAgQMcPHiQoqIizj//fKZMmcKsWbPYunVr0OPr4sSJE1xyySWUlJTwn//5n7U6trqSups2bWLfvn18//33vPLKK1x55ZXljh0+fDivvPIKhw4dAnxTP/v27avXWJqartBFWrCK5XOXLFnCzp07GTRoEADt2rXjpZdeoqCggNmzZ9OqVSvCw8N5+umnAd+j2dLS0oiIiCA7O7tOfVi4cCHJyclceumlREdHl3vwRE2qK6l7xRVX8MADD7B9+3aGDh0aeJTeGTExMSxYsIDhw4dz+vRpwsPDeeaZZ5p1ae8ay+c2FpXPFVH5XKleY5TPFRGRZkCBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAF2nB6lNtceTIkQ1ShnblypW0atWKTz75JLAuOjo6cHt/VR599NGg6wcOHEh8fDyXXnopXbt2DZTuram9sh5++OE6f65+2bJl/OpXv6q0vrS0lAsvvLBObYZKgS7SgtUl0J1znD59mszMzAYLqMjISH7729/W6piqAn3z5s3k5eWxcOFCbrnllkDp3jN1Xc74/vvvq2z7t7/9ba0qSJ4rFOgiLVjF8rnHjx/nmmuuITExkZiYGNatWwfA3r176devHzNmzCAxMZH9+/cTFRXFoUOHAtumTZvGZZddxogRIwIlcJ977rlAadybbropaO10gFGjRrF9+3Z2795daVtGRgYxMTFER0czZ86cQL9PnTpFfHx8yDXTz1whp6enk5ycTE5ODgsWLGDAgAFER0dz9913B0oHTJkyhbVr1wK+HzaPPPIICQkJxMbGsmfPHsBXWmDQoEEkJCQwePBg8vPzA+/1+eefk5qaSp8+ffiXf/mXoP1ZvHgxycnJxMbGsnDhwpDGUBPd+i9yjngs5zF2/c+uBm2z7w/7Mid5TpXbK5bPLS0tZc2aNXTo0IFDhw6RkpISuGV+9+7drFixIugVfX5+PhkZGTz33HPcfPPNvPrqq0yZMoVx48Yxbdo0wFfffPny5dx3332Vjm/VqhUPPvggjz76KC+88EJgfVFREXPmzGHLli106tSJESNGsHbtWhYvXsxTTz0V6Heojh49SmJiYiBk+/Tpw29+8xucc0yaNInXX3+dtLS0SsddfPHFfPTRRzz55JM8/vjjPPPMM/Tr1493332X1q1b8/rrr5Oens7q1asByMnJYdu2bbRp04YBAwYwatQooqOjA+1lZmayb98+Nm/ejHOOkSNH8v7771d6AEht6QpdRAKcczz00EPExsYyfPhwDhw4wJdffglAz549SUlJCXpcr169iI+PB8qXt922bRtDhgwhJiaGVatWsX379irfe9KkSWzatIm///3vgXUffvghQ4cOpWvXroSFhTF58mQ2btxY5/G1adOGG2+8MbD81ltvkZycTFxcHH/961+r7F+w0r1Hjhxh3LhxREdHM2vWrHLHpqam0qlTJy644ALGjh3Lu+++W669rKwsXnvtNRISEkhMTKSgoCBw5V8fukIXOUdUdyV9tqxatYri4mK2bNlCeHg4UVFRgWJZZUveVlS2KFbr1q0DUy533HEHa9euJS4ujpUrV/L2229X2UZYWBgPPPAAjz32WGBdQ9ea+sEPfhAoo3vy5ElmzpzJ1q1b6d69O+np6VUWBgtWuvfhhx8mNTWVGTNmUFBQwHXXXRfYP5TSvenp6dx5550NNjbQFbpIi1ax/O3Ro0e56KKLCA8PJzs7m88//7xe7R87doyIiAhKSkpCeuDzHXfcwYYNGyguLgZ8n1j561//yqFDh/j+++/JyMjgZz/7GQDh4eGUlJTUuW+nTp2iVatWdOnShWPHjvHqq6/W6vijR4/SvXt3wPdJnbKysrI4cuQIJ0+eZN26dQwePLjc9tTUVJYvX86JEycAKCwsDJTxrQ8FukgLVrZ87uzZs5k8eTK5ubkkJSWxatUq+vbtW6/2Fy1axMCBA7n22mtDaqtNmzbcf//9HDx4EICIiAj+9V//lWHDhhEXF0diYiJjxowBfKV7Y2Nj6/wg6c6dO3P77bcTHR3NjTfeyMCBA2t1/Jw5c5g9e3alsAbfM1AnTZpEQkICEydODExHnTFy5EjGjx9PSkoKMTEx3HzzzYEa9PWh8rkiTUjlc6U6Kp8rItJCKdBFRDxCgS4i4hEKdBERj1Cgi4h4REiBbmbXmdluMysws7nV7DfezJyZBf0LrIiINJ4aA93MWgNLgTSgPzDRzPoH2a89cD+wuaE7KSKNoz7lcwGeeOKJKgtuDR06lKSk/39tl5uby9ChQ6ttLy8vj8zMzErr33jjjUAZ3Hbt2tGnTx/i4+O57bbbQu7r999/z5AhQ0Lev6Irr7wyaO2YqsrlNoVQrtCTgQLn3GfOue+Al4ExQfZbBPwOCH7vrIiccxoz0AEOHjzIa6+9FnJ7VQV6ampqoAzumZue8vLyePHFF8vtd+a2/GBat27NO++8E3JfmqNQAr07sL/McqF/XYCZJQA9nHN/qq4hM5tuZrlmlnvm1l4RaToVy+cCLFmyhAEDBhAbG8uCBQsAOHHiBNdffz1xcXFER0ezevVqnnzySYqKihg2bFiVtcNnz54dtHzsN998w9SpU4mJiSEhIYHs7Gy+++475s+fz+rVq4mPjw9ULqzJsmXLmDBhAqNGjSItLY2vv/6aq6++msTERGJjY/nTn3yxVPYBExs2bOCaa65h3Lhx9OnTp9yVflUldcF3i/+gQYOIiYkh2I2RX375JePGjSMpKYnk5GQ2bdoU0hgaSijFuSzIusAIzawV8O/AHTU15Jx7FngWfHeKhtZFkZbhH48+yrc7G7Z87nn9+nLJQw9Vub1i+dysrCzy8/PJycnBOcfo0aPZuHEjxcXFdOvWjT//+c+Ar45Jx44defzxx8nOzqZLly5B2x80aBBr1qwhOzub9u3bB9YvXboUgL/97W/s2rWLESNGsGfPHhYuXEhubi5PPfVUrcb5wQcfkJeXR6dOnSgpKWHdunW0b9+egwcPMnjwYEaNGlXpmK1bt7Jjxw4uuugiUlJS2LRpEykpKfzyl7+ssqTut99+ywcffMBf/vIXfvGLX1Sagrn//vt58MEHSUlJYe/evYwaNYpt27bVaiz1EcoVeiHQo8xyJFBUZrk9EA28bWZ7gRRgvf4wKtL8ZGVlkZWVFSjrumvXLvLz84mJiWHDhg3MmTOHd955h44dO4bcZnp6eqWr9HfffZdbb70VgL59+9KzZ896lY8dMWIEnTp1AnyVDOfMmUNsbCwjRoxg//79QQtfpaSkEBERQevWrcs9oq66kroTJ04E4Oqrr+bgwYOV6q9s2LCBu+++m/j4eMaOHctXX30VqDx5NoRyhf4h0NvMegEHgAnApDMbnXNHgcCPZzN7G5jlnFOhFpFaqO5K+mxxzjFv3jzuuuuuStu2bNlCZmYm8+bNY8SIEcyfPz+kNq+++mr++Z//udz0Q0PXkCpb2vfFF1/k6NGjbN26lbCwMCIjI4OWxa1Y8re0tLTGkrqhlMXNycmhTZs2DTW0WqnxCt05VwrMBN4AdgKvOOe2m9lCMxvd2B0UkcZTsXxuamoqzz//fODK88CBAxw8eJCioiLOP/98pkyZwqxZs9i6dWvQ46vy8MMP87vf/S6wfNVVVwXK6e7Zs4d9+/bRp0+fkNurzpkSwGFhYbz55pscOHAg5GNrKql7Zl7/7bff5uKLL65UI3748OGB6SSg1k9Uqq+QHnDhnMsEMiusC/rj2Tk3tP7dEpGzoWz53LS0NJYsWcLOnTsZNGgQAO3ateOll16ioKCA2bNn06pVK8LDw3n66acBXwnbtLQ0IiIiyM7OrvJ9Ro4cSdeuXQPLM2bM4O677yYmJoawsDBWrlzJeeedx7Bhw1i8eDHx8fHMmzePW265pdZjuvXWW7nhhhtISkoiMTGR3r171+rf40xJ3Z49e1YqqduhQweuuOIKjh07xooVKyodv3TpUu655x5WrFhBaWkpw4YNKxfwjU3lc0WakMrnSnVUPldEpIVSoIuIeIQCXUTEIxToIk2sqf6OJee2unxfKNBFmlDbtm05fPiwQl3Kcc5x+PBh2rZtW6vjQvrYoog0jsjISAoLC1FtI6mobdu2REZG1uoYBbpIEwoPD6dXr15N3Q3xCE25iIh4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDwipEA3s+vMbLeZFZjZ3CDbf21mO8zsEzN7y8x6NnxXRUSkOjUGupm1BpYCaUB/YKKZ9a+w20dAknMuFvgj8LuG7qiIiFQvlCv0ZKDAOfeZc+474GVgTNkdnHPZzrmT/sVNQGTDdlNERGoSSqB3B/aXWS70r6vKncBrwTaY2XQzyzWz3OLi4tB7KSIiNQol0C3IOhd0R7MpQBKwJNh259yzzrkk51xS165dQ++liIjUKCyEfQqBHmWWI4GiijuZ2XDgYeBnzrlvG6Z7IiISqlCu0D8EeptZLzNrA0wA1pfdwcwSgP8DjHbOHWz4boqISE1qDHTnXCkwE3gD2Am84pzbbmYLzWy0f7clQDvgv8wsz8zWV9GciIg0klCmXHDOZQKZFdbNL/N6eAP3S0REakl3ioqIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiESEFupldZ2a7zazAzOYG2X6ema32b99sZlEN3VEREalejYFuZq2BpUAa0B+YaGb9K+x2J/CVc+4nwL8DjzV0R0VEpHphIeyTDBQ45z4DMLOXgTHAjjL7jAEe8b/+I/CUmZlzzjVgXwH4x6OP8u3OXQ3drIjIWXNev75c8tBDDd5uKFMu3YH9ZZYL/euC7uOcKwWOAp0rNmRm080s18xyi4uL69ZjEREJKpQrdAuyruKVdyj74Jx7FngWICkpqU5X743xU01ExAtCuUIvBHqUWY4Eiqrax8zCgI7A/zREB0VEJDShBPqHQG8z62VmbYAJwPoK+6wHbve/Hg/8pTHmz0VEpGo1Trk450rNbCbwBtAaeN45t93MFgK5zrn1wHLgP8ysAN+V+YTG7LSIiFQWyhw6zrlMILPCuvllXn8D/LxhuyYiIrWhO0VFRDxCgS4i4hEKdBERj1Cgi4h4hDXVpwvNrBj4vI6HdwEONWB3mouWOO6WOGZomeNuiWOG2o+7p3Oua7ANTRbo9WFmuc65pKbux9nWEsfdEscMLXPcLXHM0LDj1pSLiIhHKNBFRDyiuQb6s03dgSbSEsfdEscMLXPcLXHM0IDjbpZz6CIiUllzvUIXEZEKFOgiIh7R7AK9pgdWe4GZ9TCzbDPbaWbbzeyX/vU/NLM3zSzf/99OTd3XhmZmrc3sIzP7k3+5l//B4/n+B5G3aeo+NjQzu9DM/mhmu/znfFALOdf/y//9vc3MMsysrdfOt5k9b2YHzWxbmXVBz635POnPtk/MLLG279esAj3EB1Z7QSnwgHOuH5AC3Osf51zgLedcb+At/7LX/BLYWWb5MeDf/WP+Ct8Dyb3m98Drzrm+QBy+8Xv6XJtZd+B+IMk5F42vNPcEvHe+VwLXVVhX1blNA3r7v6YDT9f2zZpVoFPmgdXOue+AMw+s9hTn3BfOua3+18fw/Q/eHd9YX/Dv9gIwtml62DjMLBK4HljmXzbganwPHgdvjrkDcBW+ZwrgnPvOOXcEj59rvzDgB/6nnJ0PfIHHzrdzbiOVn95W1bkdA7zofDYBF5pZRG3er7kFeigPrPYUM4sCEoDNwMXOuS/AF/rARU3Xs0bxBPAgcNq/3Bk44n/wOHjzfP8IKAZW+KealpnZBXj8XDvnDgD/G9iHL8iPAlvw/vmGqs9tvfOtuQV6SA+j9gozawe8CvzKOfd1U/enMZnZKOCgc25L2dVBdvXa+Q4DEoGnnXMJwAk8Nr0SjH/eeAzQC+gGXIBvyqEir53v6tT7+725BXooD6z2BDMLxxfmq5xz/+1f/eWZX8H8/z3YVP1rBIOB0Wa2F99U2tX4rtgv9P9KDt4834VAoXNus3/5j/gC3svnGmA48HfnXLFzrgT4b+AKvH++oepzW+98a26BHsoDq5s9/9zxcmCnc+7xMpvKPoz7dmDd2e5bY3HOzXPORTrnovCd17845yYD2fgePFH18DwAAADeSURBVA4eGzOAc+4fwH4z6+NfdQ2wAw+fa799QIqZne//fj8zbk+fb7+qzu164Db/p11SgKNnpmZC5pxrVl/ASGAP8CnwcFP3p5HGeCW+X7U+AfL8XyPxzSm/BeT7//vDpu5rI41/KPAn/+sfATlAAfBfwHlN3b9GGG88kOs/32uBTi3hXAO/AXYB24D/AM7z2vkGMvD9jaAE3xX4nVWdW3xTLkv92fY3fJ8AqtX76dZ/ERGPaG5TLiIiUgUFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEI/4fA7X9H+2tz54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
