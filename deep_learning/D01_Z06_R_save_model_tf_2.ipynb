{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7523 - val_loss: 0.5142 - val_accuracy: 0.7916\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7749 - val_loss: 0.4797 - val_accuracy: 0.7788\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.7781 - val_loss: 0.4249 - val_accuracy: 0.7834\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.4052 - accuracy: 0.8094 - val_loss: 0.3872 - val_accuracy: 0.8194\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3770 - accuracy: 0.8341 - val_loss: 0.3680 - val_accuracy: 0.8329\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8388 - val_loss: 0.3591 - val_accuracy: 0.8410\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3569 - accuracy: 0.8401 - val_loss: 0.3529 - val_accuracy: 0.8396\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8410 - val_loss: 0.3493 - val_accuracy: 0.8395\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3482 - accuracy: 0.8430 - val_loss: 0.3471 - val_accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3447 - accuracy: 0.8429 - val_loss: 0.3446 - val_accuracy: 0.8402\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8441 - val_loss: 0.3427 - val_accuracy: 0.8420\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8436 - val_loss: 0.3420 - val_accuracy: 0.8402\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8442 - val_loss: 0.3417 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8452 - val_loss: 0.3404 - val_accuracy: 0.8426\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3383 - accuracy: 0.8459 - val_loss: 0.3393 - val_accuracy: 0.8438\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.8459 - val_loss: 0.3393 - val_accuracy: 0.8439\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3369 - accuracy: 0.8457 - val_loss: 0.3374 - val_accuracy: 0.8440\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.8470 - val_loss: 0.3380 - val_accuracy: 0.8450\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8474 - val_loss: 0.3366 - val_accuracy: 0.8429\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3337 - accuracy: 0.8479 - val_loss: 0.3357 - val_accuracy: 0.8442\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.8473 - val_loss: 0.3351 - val_accuracy: 0.8433\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.8471 - val_loss: 0.3355 - val_accuracy: 0.8417\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.8479 - val_loss: 0.3351 - val_accuracy: 0.8436\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3320 - accuracy: 0.8481 - val_loss: 0.3342 - val_accuracy: 0.8439\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8478 - val_loss: 0.3340 - val_accuracy: 0.8428\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3314 - accuracy: 0.8484 - val_loss: 0.3334 - val_accuracy: 0.8435\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.8488 - val_loss: 0.3335 - val_accuracy: 0.8434\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8486 - val_loss: 0.3332 - val_accuracy: 0.8438\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8487 - val_loss: 0.3319 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8495 - val_loss: 0.3316 - val_accuracy: 0.8442\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8488 - val_loss: 0.3315 - val_accuracy: 0.8440\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8492 - val_loss: 0.3315 - val_accuracy: 0.8436\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3287 - accuracy: 0.8497 - val_loss: 0.3310 - val_accuracy: 0.8446\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8489 - val_loss: 0.3313 - val_accuracy: 0.8437\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8496 - val_loss: 0.3308 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3281 - accuracy: 0.8496 - val_loss: 0.3308 - val_accuracy: 0.8437\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8494 - val_loss: 0.3305 - val_accuracy: 0.8448\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8501 - val_loss: 0.3309 - val_accuracy: 0.8437\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3276 - accuracy: 0.8503 - val_loss: 0.3301 - val_accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.8496 - val_loss: 0.3301 - val_accuracy: 0.8446\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.8496 - val_loss: 0.3299 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3270 - accuracy: 0.8504 - val_loss: 0.3299 - val_accuracy: 0.8450\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3269 - accuracy: 0.8502 - val_loss: 0.3297 - val_accuracy: 0.8450\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8501 - val_loss: 0.3297 - val_accuracy: 0.8442\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8503 - val_loss: 0.3296 - val_accuracy: 0.8451\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3267 - accuracy: 0.8497 - val_loss: 0.3296 - val_accuracy: 0.8449\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3267 - accuracy: 0.8503 - val_loss: 0.3296 - val_accuracy: 0.8451\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8498 - val_loss: 0.3295 - val_accuracy: 0.8452\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8505 - val_loss: 0.3293 - val_accuracy: 0.8448\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.8503 - val_loss: 0.3294 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.8503 - val_loss: 0.3293 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.8499 - val_loss: 0.3293 - val_accuracy: 0.8452\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3262 - accuracy: 0.8505 - val_loss: 0.3292 - val_accuracy: 0.8447\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3262 - accuracy: 0.8499 - val_loss: 0.3293 - val_accuracy: 0.8448\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3262 - accuracy: 0.8502 - val_loss: 0.3292 - val_accuracy: 0.8446\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3261 - accuracy: 0.8504 - val_loss: 0.3292 - val_accuracy: 0.8454\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3260 - accuracy: 0.8505 - val_loss: 0.3291 - val_accuracy: 0.8454\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3258 - accuracy: 0.8506 - val_loss: 0.3290 - val_accuracy: 0.8447\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3258 - accuracy: 0.8503 - val_loss: 0.3289 - val_accuracy: 0.8451\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3257 - accuracy: 0.8508 - val_loss: 0.3288 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3257 - accuracy: 0.8501 - val_loss: 0.3289 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8502 - val_loss: 0.3288 - val_accuracy: 0.8450\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8505 - val_loss: 0.3288 - val_accuracy: 0.8453\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8508 - val_loss: 0.3288 - val_accuracy: 0.8453\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8504 - val_loss: 0.3288 - val_accuracy: 0.8449\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.8505 - val_loss: 0.3288 - val_accuracy: 0.8449\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.8504 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.8504 - val_loss: 0.3287 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3255 - accuracy: 0.8504 - val_loss: 0.3287 - val_accuracy: 0.8449\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8503 - val_loss: 0.3287 - val_accuracy: 0.8446\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8504 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8504 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8505 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8505 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8505 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8507 - val_loss: 0.3287 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8505 - val_loss: 0.3287 - val_accuracy: 0.8448\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8506 - val_loss: 0.3287 - val_accuracy: 0.8450\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8508 - val_loss: 0.3286 - val_accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8507 - val_loss: 0.3286 - val_accuracy: 0.8449\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8505 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8507 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8447\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8507 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8507 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8506 - val_loss: 0.3286 - val_accuracy: 0.8448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27b8d2ac48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "save_best_model = ModelCheckpoint(\"/tmp/test_weights.h5\",save_best_only=True)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, save_best_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam 0.0001 LR\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam 0.0001 LR\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 659us/step - loss: 0.3286 - accuracy: 0.8448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32858720421791077, 0.8447543382644653]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"/tmp/test_weights.h5\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Zapisz 3 modele z różnymi parametrami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
