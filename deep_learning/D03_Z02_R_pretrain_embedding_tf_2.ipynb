{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SimpleRNN, LSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import History\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "# Zad. \n",
    "Podążamy za stroną: \n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "mamy jakiś zbiór tekstów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do warstwy **Embedding layer** wchodzi sekwencja intów.\n",
    "\n",
    "* my wykorzystamy reprezenatację Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43, 33], [20, 18], [18, 30], [42, 18], [14], [13], [11, 30], [4, 20], [11, 18], [16, 42, 33, 14]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 33  0  0]\n",
      " [20 18  0  0]\n",
      " [18 30  0  0]\n",
      " [42 18  0  0]\n",
      " [14  0  0  0]\n",
      " [13  0  0  0]\n",
      " [11 30  0  0]\n",
      " [ 4 20  0  0]\n",
      " [11 18  0  0]\n",
      " [16 42 33 14]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Embeding ma rakres 50 i długość wejściową 4. Zmniejszmy embending do wymiaru 8.\n",
    "* Model jest prostym klasyfikatorem binarnym. \n",
    "* Co ważne, wynik z warstwy Embeding będzie wynosił 4 wektory o 8 wymiarach każdy, po jednym dla każdego słowa. \n",
    "* Spłaszczamy to do jednego 32-elementowego wektora, aby przejść do warstwy wyjściowej Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 80.000001\n"
     ]
    }
   ],
   "source": [
    "history_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6429 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6417 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6405 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6394 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6382 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6370 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6358 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6346 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6335 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6323 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6311 - accuracy: 0.7778 - val_loss: 0.5047 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6299 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6287 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6275 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6263 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6251 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6239 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6227 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6215 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6203 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6191 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6179 - accuracy: 0.7778 - val_loss: 0.5029 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6167 - accuracy: 0.7778 - val_loss: 0.5026 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6154 - accuracy: 0.7778 - val_loss: 0.5024 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6142 - accuracy: 0.7778 - val_loss: 0.5021 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6130 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6117 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6105 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6092 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6079 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6067 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6054 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6041 - accuracy: 0.7778 - val_loss: 0.4998 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6028 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6015 - accuracy: 0.7778 - val_loss: 0.4992 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6001 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5988 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5975 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5961 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5948 - accuracy: 0.7778 - val_loss: 0.4976 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5934 - accuracy: 0.8889 - val_loss: 0.4973 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5921 - accuracy: 0.8889 - val_loss: 0.4969 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5907 - accuracy: 0.8889 - val_loss: 0.4966 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5893 - accuracy: 0.8889 - val_loss: 0.4963 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5879 - accuracy: 0.8889 - val_loss: 0.4959 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5865 - accuracy: 0.8889 - val_loss: 0.4956 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5851 - accuracy: 0.8889 - val_loss: 0.4953 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.8889 - val_loss: 0.4949 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5822 - accuracy: 0.8889 - val_loss: 0.4946 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5808 - accuracy: 0.8889 - val_loss: 0.4942 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5794 - accuracy: 0.8889 - val_loss: 0.4938 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5779 - accuracy: 0.8889 - val_loss: 0.4935 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5765 - accuracy: 0.8889 - val_loss: 0.4931 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5750 - accuracy: 0.8889 - val_loss: 0.4927 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5735 - accuracy: 0.8889 - val_loss: 0.4924 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5720 - accuracy: 0.8889 - val_loss: 0.4920 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5705 - accuracy: 0.8889 - val_loss: 0.4916 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5690 - accuracy: 0.8889 - val_loss: 0.4912 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5675 - accuracy: 0.8889 - val_loss: 0.4908 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5660 - accuracy: 0.8889 - val_loss: 0.4904 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5645 - accuracy: 0.8889 - val_loss: 0.4899 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5629 - accuracy: 0.8889 - val_loss: 0.4895 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5614 - accuracy: 0.8889 - val_loss: 0.4891 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5599 - accuracy: 0.8889 - val_loss: 0.4887 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5583 - accuracy: 0.8889 - val_loss: 0.4882 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5567 - accuracy: 0.8889 - val_loss: 0.4878 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5552 - accuracy: 0.8889 - val_loss: 0.4874 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5536 - accuracy: 0.8889 - val_loss: 0.4869 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5520 - accuracy: 0.8889 - val_loss: 0.4865 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5504 - accuracy: 0.8889 - val_loss: 0.4860 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5488 - accuracy: 0.8889 - val_loss: 0.4856 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5472 - accuracy: 0.8889 - val_loss: 0.4852 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5456 - accuracy: 0.8889 - val_loss: 0.4847 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5439 - accuracy: 0.8889 - val_loss: 0.4843 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5423 - accuracy: 0.8889 - val_loss: 0.4839 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5407 - accuracy: 0.8889 - val_loss: 0.4834 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5390 - accuracy: 0.8889 - val_loss: 0.4830 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5373 - accuracy: 0.8889 - val_loss: 0.4826 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5357 - accuracy: 0.8889 - val_loss: 0.4822 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5340 - accuracy: 0.8889 - val_loss: 0.4818 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5323 - accuracy: 0.8889 - val_loss: 0.4814 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5307 - accuracy: 0.8889 - val_loss: 0.4810 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5290 - accuracy: 0.8889 - val_loss: 0.4806 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5273 - accuracy: 0.8889 - val_loss: 0.4802 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5256 - accuracy: 0.8889 - val_loss: 0.4798 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5239 - accuracy: 0.8889 - val_loss: 0.4794 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5221 - accuracy: 0.8889 - val_loss: 0.4790 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5204 - accuracy: 0.8889 - val_loss: 0.4786 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5187 - accuracy: 0.8889 - val_loss: 0.4783 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5170 - accuracy: 0.8889 - val_loss: 0.4779 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5152 - accuracy: 0.8889 - val_loss: 0.4775 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5135 - accuracy: 0.8889 - val_loss: 0.4771 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5117 - accuracy: 0.8889 - val_loss: 0.4767 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5100 - accuracy: 0.8889 - val_loss: 0.4764 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5082 - accuracy: 0.8889 - val_loss: 0.4760 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5064 - accuracy: 0.8889 - val_loss: 0.4756 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5047 - accuracy: 0.8889 - val_loss: 0.4752 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5029 - accuracy: 0.8889 - val_loss: 0.4748 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5011 - accuracy: 0.8889 - val_loss: 0.4744 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4993 - accuracy: 0.8889 - val_loss: 0.4740 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3173fd2e88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# # fit the model\n",
    "# model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain embedding\n",
    "\n",
    "https://keras.io/examples/pretrained_word_embeddings/\n",
    "\n",
    "* GloVe embedding data can be found at: http://nlp.stanford.edu/data/glove.6B.zip (source page: http://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "* After downloading and unzipping, you will see a few files, one of which is “glove.6B.50d.txt“, which contains a 100-dimensional version of the embedding.\n",
    "\n",
    "\n",
    "Pojedyńczy plik można pobrać z tąd:\n",
    "https://www.dropbox.com/sh/tjq47ybybgnrbel/AAAVbp0UkQTAbKWVMIi5mtHpa?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B.50d')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "# file = open(filename, encoding=\"utf8\")\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a Tokenizer class that can be fit on the training data, can convert text to sequences consistently by calling the texts_to_sequences() method on the Tokenizer class, and provides access to the dictionary mapping of words to integers in a word_index attribute.\n",
    "\n",
    "https://keras.io/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekwencje mają różne długości, a Keras wymaga aby wejścia były równej długość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a matrix of one embedding for each word in the training dataset. We can do that by enumerating all unique words in the Tokenizer.word_index and locating the embedding weight vector from the loaded GloVe embedding.\n",
    "\n",
    "The result is a matrix of weights only for words we will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13589978e-01,  1.96950004e-01, -5.19439995e-01, -8.62179995e-01,\n",
       "        1.54940002e-02,  1.09729998e-01, -8.02929997e-01, -3.33609998e-01,\n",
       "       -1.61189993e-04,  1.01889996e-02,  4.67340015e-02,  4.67510015e-01,\n",
       "       -4.74750012e-01,  1.10380001e-01,  3.93269986e-01, -4.36520010e-01,\n",
       "        3.99839997e-01,  2.71090001e-01,  4.26499993e-01, -6.06400013e-01,\n",
       "        8.11450005e-01,  4.56299990e-01, -1.27260000e-01, -2.24739999e-01,\n",
       "        6.40709996e-01, -1.27670002e+00, -7.22310007e-01, -6.95900023e-01,\n",
       "        2.80450005e-02, -2.30719998e-01,  3.79959989e+00, -1.26249999e-01,\n",
       "       -4.79669988e-01, -9.99719977e-01, -2.19760001e-01,  5.05649984e-01,\n",
       "        2.59530004e-02,  8.05140018e-01,  1.99290007e-01,  2.87959993e-01,\n",
       "       -1.59150004e-01, -3.04380000e-01,  1.60249993e-01, -1.82899997e-01,\n",
       "       -3.85629982e-02, -1.76190004e-01,  2.70409994e-02,  4.68420014e-02,\n",
       "       -6.28970027e-01,  3.57259989e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.30760002e-01, -4.38699991e-01, -3.21630001e-01, -4.93099988e-01,\n",
       "        1.02540001e-01, -2.74210004e-03, -5.17199993e-01,  2.43360009e-02,\n",
       "       -1.28160000e-01,  1.43490002e-01, -1.66909993e-01,  5.61209977e-01,\n",
       "       -5.62409997e-01, -4.09720019e-02,  7.50000000e-01,  2.30839998e-01,\n",
       "        5.32040000e-01, -4.09730002e-02,  2.68920004e-01, -6.92380011e-01,\n",
       "        2.78829992e-01,  3.79110008e-01,  5.63899994e-01, -3.81500006e-01,\n",
       "        7.21319973e-01, -1.35619998e+00, -8.17170024e-01, -5.48419990e-02,\n",
       "        5.73329985e-01, -8.54889989e-01,  3.18889999e+00,  1.99180007e-01,\n",
       "       -4.21200007e-01, -9.04269993e-01, -1.95209995e-01,  3.01109999e-01,\n",
       "        4.67559993e-01,  8.21300030e-01,  6.05520010e-02, -1.61430001e-01,\n",
       "       -2.66680002e-01, -1.76599994e-01,  1.58200003e-02,  2.55279988e-01,\n",
       "       -9.67390016e-02, -9.72819999e-02, -8.44829977e-02,  3.33119988e-01,\n",
       "       -2.22519994e-01,  7.44570017e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference is that the embedding layer can be seeded with the GloVe word embedding weights. We chose the 50-dimensional version, therefore the Embedding layer must be defined with output_dim set to 50. Finally, we do not want to update the learned word weights in this model, therefore we will set the trainable attribute for the model to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 50)             750       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 201\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "history_2 = History()\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7574 - accuracy: 0.4444 - val_loss: 0.9379 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7487 - accuracy: 0.4444 - val_loss: 0.9481 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7401 - accuracy: 0.4444 - val_loss: 0.9584 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7317 - accuracy: 0.4444 - val_loss: 0.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7235 - accuracy: 0.4444 - val_loss: 0.9791 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7156 - accuracy: 0.4444 - val_loss: 0.9894 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7078 - accuracy: 0.4444 - val_loss: 0.9999 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7003 - accuracy: 0.4444 - val_loss: 1.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6930 - accuracy: 0.4444 - val_loss: 1.0208 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6858 - accuracy: 0.4444 - val_loss: 1.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6789 - accuracy: 0.5556 - val_loss: 1.0418 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - accuracy: 0.5556 - val_loss: 1.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6656 - accuracy: 0.6667 - val_loss: 1.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6593 - accuracy: 0.6667 - val_loss: 1.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6532 - accuracy: 0.7778 - val_loss: 1.0843 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6472 - accuracy: 0.8889 - val_loss: 1.0948 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6414 - accuracy: 0.8889 - val_loss: 1.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6358 - accuracy: 0.8889 - val_loss: 1.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6303 - accuracy: 0.8889 - val_loss: 1.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6251 - accuracy: 0.8889 - val_loss: 1.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6199 - accuracy: 0.8889 - val_loss: 1.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6149 - accuracy: 0.8889 - val_loss: 1.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6101 - accuracy: 0.8889 - val_loss: 1.1651 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6053 - accuracy: 0.8889 - val_loss: 1.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6007 - accuracy: 0.8889 - val_loss: 1.1834 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5962 - accuracy: 0.8889 - val_loss: 1.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5918 - accuracy: 0.7778 - val_loss: 1.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7778 - val_loss: 1.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5833 - accuracy: 0.7778 - val_loss: 1.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5792 - accuracy: 0.7778 - val_loss: 1.2239 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5752 - accuracy: 0.7778 - val_loss: 1.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5712 - accuracy: 0.7778 - val_loss: 1.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5673 - accuracy: 0.7778 - val_loss: 1.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.7778 - val_loss: 1.2505 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5596 - accuracy: 0.7778 - val_loss: 1.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5559 - accuracy: 0.7778 - val_loss: 1.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5521 - accuracy: 0.7778 - val_loss: 1.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5485 - accuracy: 0.7778 - val_loss: 1.2716 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5448 - accuracy: 0.7778 - val_loss: 1.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5412 - accuracy: 0.7778 - val_loss: 1.2803 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5376 - accuracy: 0.7778 - val_loss: 1.2842 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.7778 - val_loss: 1.2878 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.7778 - val_loss: 1.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5271 - accuracy: 0.7778 - val_loss: 1.2942 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5236 - accuracy: 0.7778 - val_loss: 1.2971 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5202 - accuracy: 0.7778 - val_loss: 1.2997 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5168 - accuracy: 0.7778 - val_loss: 1.3021 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5134 - accuracy: 0.7778 - val_loss: 1.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5100 - accuracy: 0.8889 - val_loss: 1.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5067 - accuracy: 0.8889 - val_loss: 1.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5034 - accuracy: 0.8889 - val_loss: 1.3100 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5001 - accuracy: 0.8889 - val_loss: 1.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4969 - accuracy: 0.8889 - val_loss: 1.3131 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4936 - accuracy: 0.8889 - val_loss: 1.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4904 - accuracy: 0.8889 - val_loss: 1.3158 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4872 - accuracy: 0.8889 - val_loss: 1.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4841 - accuracy: 0.8889 - val_loss: 1.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4810 - accuracy: 0.8889 - val_loss: 1.3194 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4779 - accuracy: 0.8889 - val_loss: 1.3205 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4748 - accuracy: 0.8889 - val_loss: 1.3216 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4717 - accuracy: 0.8889 - val_loss: 1.3227 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4687 - accuracy: 0.8889 - val_loss: 1.3238 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4657 - accuracy: 0.8889 - val_loss: 1.3249 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.8889 - val_loss: 1.3260 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4598 - accuracy: 0.8889 - val_loss: 1.3271 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4569 - accuracy: 0.8889 - val_loss: 1.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.88 - 0s 16ms/step - loss: 0.4540 - accuracy: 0.8889 - val_loss: 1.3294 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4511 - accuracy: 0.8889 - val_loss: 1.3306 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4483 - accuracy: 0.8889 - val_loss: 1.3319 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.8889 - val_loss: 1.3332 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4426 - accuracy: 0.8889 - val_loss: 1.3346 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4398 - accuracy: 0.8889 - val_loss: 1.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4371 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4344 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4316 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4289 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4263 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4236 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4210 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4184 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4158 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4107 - accuracy: 1.0000 - val_loss: 1.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4031 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4007 - accuracy: 1.0000 - val_loss: 1.3634 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 1.0000 - val_loss: 1.3655 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3958 - accuracy: 1.0000 - val_loss: 1.3677 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3934 - accuracy: 1.0000 - val_loss: 1.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 1.0000 - val_loss: 1.3723 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3886 - accuracy: 1.0000 - val_loss: 1.3745 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3862 - accuracy: 1.0000 - val_loss: 1.3769 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3839 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3816 - accuracy: 1.0000 - val_loss: 1.3815 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3793 - accuracy: 1.0000 - val_loss: 1.3839 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3770 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3747 - accuracy: 1.0000 - val_loss: 1.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 1.3911 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3703 - accuracy: 1.0000 - val_loss: 1.3935 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x310070b1c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(padded_docs, labels, epochs=100, validation_split=0.1, callbacks=[history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_1.history['accuracy'], label = \"tarina Trainable\")\n",
    "plt.plot(history_1.history['val_accuracy'], label = \"test Trainable\")\n",
    "\n",
    "plt.plot(history_2.history['accuracy'], label = \"tarina Not Trainable\")\n",
    "plt.plot(history_2.history['val_accuracy'], label = \"test Not Trainable\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
