{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost\n",
    "except ImportError as ex:\n",
    "    print(\"Error: the xgboost library is not installed.\")\n",
    "    xgboost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "\n",
    "to_remove= ('headers', 'footers', 'quotes')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='all', shuffle=True, remove = to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Znajdź najlepszy model dla 20newsgroups wykonując GridSearch dla modeli:\n",
    "\n",
    "* MultinomialNB (bez redukcji wymiarowości)\n",
    "* LogisticRegression\n",
    "* LinearSVC\n",
    "* SVC\n",
    "* KNeighborsClassifier\n",
    "* DecisionTreeClassifier\n",
    "* RandomForestClassifier\n",
    "* BaggingClassifier\n",
    "* ExtraTreesClassifier\n",
    "* AdaBoostClassifier\n",
    "* GradientBoostingClassifier\n",
    "* VotingClassifier\n",
    "* xgboost.XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFMxJREFUeJzt3X2sZPV93/H3p6whtZOahb04eHcd\ncLK4JVZToytM4saiJuYpFksrU4GisrKpVm4g9UPdGBfJRI4s2XkipUqpNmZrqBAPJXZYRbh4ix2h\nSl3MhfBobPYaE7gGs9ddjOMi28H+9o/5bTy9O/dhZ+6d2eW8X9Jozvme35nzu+fOnc/9nXNmJlWF\nJKl7/t6kOyBJmgwDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOWjYAkuxMsi/Jowvqv5Xka0ke\nS/J7ffWPJplty87pq5/barNJrlzdH0OSdKiy3BvBkrwd+B5wY1W9udX+GXAV8OtV9YMkJ1TVviSn\nAjcDpwOvB/4ncEp7qCeAdwJzwH3AJVX1lTX4mSRJK7BuuQZVdU+SkxaU/w3wyar6QWuzr9W3Are0\n+jeSzNILA4DZqnoSIMktre2SAbBhw4Y66aSFm5YkLeX+++//dlVNLddu2QBYxCnAryb5BPB94MNV\ndR+wEdjT126u1QCeWVB/66AHTrId2A7whje8gZmZmSG7KEndlOSvV9Ju2JPA64D1wBnAvwduSxIg\nA9rWEvWDi1U7qmq6qqanppYNMEnSkIYdAcwBn63eCYQvJ/kxsKHVN/e12wQ826YXq0uSJmDYEcCf\nA+8ASHIKcDTwbWAXcHGSY5KcDGwBvkzvpO+WJCcnORq4uLWVJE3IsiOAJDcDZwIbkswBVwM7gZ3t\n0tAfAtvaaOCxJLfRO7n7MnB5Vf2oPc4VwF3AUcDOqnpsDX4eSdIKLXsZ6CRNT0+XJ4El6dAkub+q\nppdr5zuBJamjDABJ6igDQJI6ygCQpI4a9n0Akjromt1PTGS7H3znKcs30iEzAKQh+WKoI52HgCSp\nowwASeooA0CSOsoAkKSOMgAkqaO8CmgNTOrqEPAKkS6Y5PNLrywGgFaFl0RKRx4DQEc0/xuWhuc5\nAEnqKEcArzD+RyxppRwBSFJHGQCS1FHLBkCSnUn2te//Xbjsw0kqyYY2nyTXJplN8nCS0/rabkuy\nt922re6PIUk6VCsZAXwGOHdhMclm4J3A033l84At7bYduK61PY7el8m/FTgduDrJ+lE6LkkazbIB\nUFX3APsHLLoG+G2g/1vltwI3Vs8e4NgkJwLnALuran9VvQDsZkCoSJLGZ6hzAEkuAL5ZVQ8tWLQR\neKZvfq7VFqsPeuztSWaSzMzPzw/TPUnSChxyACR5NXAV8LFBiwfUaon6wcWqHVU1XVXTU1NTh9o9\nSdIKDTMC+HngZOChJE8Bm4AHkvwsvf/sN/e13QQ8u0RdkjQhhxwAVfVIVZ1QVSdV1Un0XtxPq6pv\nAbuAS9vVQGcAL1bVc8BdwNlJ1reTv2e3miRpQlZyGejNwP8G3pRkLsllSzS/E3gSmAX+FPhNgKra\nD/wucF+7fbzVJEkTkqqBh+IPC9PT0zUzMzPpbhwyP45BeuU4Ej9xNsn9VTW9XDvfCSxJHWUASFJH\nGQCS1FEGgCR1lAEgSR31iv5CGK/GkaTFOQKQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnq\nKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6aiXfCbwzyb4kj/bVfj/JV5M8nORzSY7tW/bRJLNJvpbk\nnL76ua02m+TK1f9RJEmHYiUjgM8A5y6o7QbeXFX/GHgC+ChAklOBi4FfbOv85yRHJTkK+BPgPOBU\n4JLWVpI0IcsGQFXdA+xfUPtCVb3cZvcAm9r0VuCWqvpBVX0DmAVOb7fZqnqyqn4I3NLaSpImZDXO\nAbwX+Hyb3gg807dsrtUWqx8kyfYkM0lm5ufnV6F7kqRBRgqAJFcBLwM3HSgNaFZL1A8uVu2oqumq\nmp6amhqle5KkJQz9jWBJtgHvAs6qqgMv5nPA5r5mm4Bn2/RidUnSBAw1AkhyLvAR4IKqeqlv0S7g\n4iTHJDkZ2AJ8GbgP2JLk5CRH0ztRvGu0rkuSRrHsCCDJzcCZwIYkc8DV9K76OQbYnQRgT1W9r6oe\nS3Ib8BV6h4Yur6oftce5ArgLOArYWVWPrcHPI0laoWUDoKouGVC+fon2nwA+MaB+J3DnIfVOkrRm\nfCewJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLU\nUQaAJHWUASBJHTX0N4JJUhdcs/uJiWz3g+88Zc234QhAkjrKAJCkjjIAJKmjlg2AJDuT7EvyaF/t\nuCS7k+xt9+tbPUmuTTKb5OEkp/Wts62135tk29r8OJKklVrJCOAzwLkLalcCd1fVFuDuNg9wHrCl\n3bYD10EvMOh9mfxbgdOBqw+EhiRpMpYNgKq6B9i/oLwVuKFN3wBc2Fe/sXr2AMcmORE4B9hdVfur\n6gVgNweHiiRpjIY9B/C6qnoOoN2f0OobgWf62s212mJ1SdKErPZJ4Ayo1RL1gx8g2Z5kJsnM/Pz8\nqnZOkvQTwwbA8+3QDu1+X6vPAZv72m0Cnl2ifpCq2lFV01U1PTU1NWT3JEnLGTYAdgEHruTZBtzR\nV7+0XQ10BvBiO0R0F3B2kvXt5O/ZrSZJmpBlPwoiyc3AmcCGJHP0rub5JHBbksuAp4GLWvM7gfOB\nWeAl4D0AVbU/ye8C97V2H6+qhSeWJUljtGwAVNUliyw6a0DbAi5f5HF2AjsPqXeSpDXjO4ElqaMM\nAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMM\nAEnqKANAkjrKAJCkjjIAJKmjDABJ6qiRAiDJB5M8luTRJDcn+akkJye5N8neJLcmObq1PabNz7bl\nJ63GDyBJGs7QAZBkI/BvgemqejNwFHAx8CngmqraArwAXNZWuQx4oap+AbimtZMkTcioh4DWAX8/\nyTrg1cBzwDuA29vyG4AL2/TWNk9bflaSjLh9SdKQhg6Aqvom8AfA0/Re+F8E7ge+U1Uvt2ZzwMY2\nvRF4pq37cmt//LDblySNZpRDQOvp/Vd/MvB64DXAeQOa1oFVlljW/7jbk8wkmZmfnx+2e5KkZYxy\nCOjXgG9U1XxV/S3wWeBXgGPbISGATcCzbXoO2AzQlr8W2L/wQatqR1VNV9X01NTUCN2TJC1llAB4\nGjgjyavbsfyzgK8AXwLe3dpsA+5o07vaPG35F6vqoBGAJGk8RjkHcC+9k7kPAI+0x9oBfAT4UJJZ\nesf4r2+rXA8c3+ofAq4cod+SpBGtW77J4qrqauDqBeUngdMHtP0+cNEo25MkrR7fCSxJHWUASFJH\nGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJH\nGQCS1FEGgCR1lAEgSR1lAEhSR40UAEmOTXJ7kq8meTzJLyc5LsnuJHvb/frWNkmuTTKb5OEkp63O\njyBJGsaoI4D/CPyPqvqHwC8Bj9P7sve7q2oLcDc/+fL384At7bYduG7EbUuSRjB0ACT5B8DbgesB\nquqHVfUdYCtwQ2t2A3Bhm94K3Fg9e4Bjk5w4dM8lSSMZZQTwRmAe+K9J/irJp5O8BnhdVT0H0O5P\naO03As/0rT/XapKkCRglANYBpwHXVdVbgP/LTw73DJIBtTqoUbI9yUySmfn5+RG6J0layigBMAfM\nVdW9bf52eoHw/IFDO+1+X1/7zX3rbwKeXfigVbWjqqaranpqamqE7kmSljJ0AFTVt4Bnkryplc4C\nvgLsAra12jbgjja9C7i0XQ10BvDigUNFkqTxWzfi+r8F3JTkaOBJ4D30QuW2JJcBTwMXtbZ3AucD\ns8BLra0kaUJGCoCqehCYHrDorAFtC7h8lO1JklaP7wSWpI4yACSpowwASeooA0CSOsoAkKSOGvUy\nUGmiznh6x8S2vecN2ye2bWk1OAKQpI5yBPAKM6n/iP1vWDryOAKQpI5yBKBVMclj8V3jeQ+tFgNg\nDfhiKOlIYABIOuw56lkbBoA0JEd6OtJ5EliSOsoAkKSOekUfAnKILq0u/6ZeWRwBSFJHGQCS1FEj\nB0CSo5L8VZK/aPMnJ7k3yd4kt7bvCybJMW1+ti0/adRtS5KGtxojgPcDj/fNfwq4pqq2AC8Al7X6\nZcALVfULwDWtnSRpQkYKgCSbgF8HPt3mA7wDuL01uQG4sE1vbfO05We19pKkCRh1BPDHwG8DP27z\nxwPfqaqX2/wcsLFNbwSeAWjLX2ztJUkTMHQAJHkXsK+q7u8vD2haK1jW/7jbk8wkmZmfnx+2e5Kk\nZYwyAngbcEGSp4Bb6B36+WPg2CQH3l+wCXi2Tc8BmwHa8tcC+xc+aFXtqKrpqpqempoaoXuSpKUM\nHQBV9dGq2lRVJwEXA1+sqt8AvgS8uzXbBtzRpne1edryL1bVQSMASdJ4rMX7AD4CfCjJLL1j/Ne3\n+vXA8a3+IeDKNdi2JGmFVuWjIKrqL4G/bNNPAqcPaPN94KLV2J4kaXS+E1iSOsoAkKSOekV/Gqgk\njWpyn4D6B2u+BUcAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1\nlAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdNXQAJNmc5EtJHk/yWJL3t/pxSXYn2dvu17d6klybZDbJ\nw0lOW60fQpJ06EYZAbwM/Luq+kfAGcDlSU6l92Xvd1fVFuBufvLl7+cBW9ptO3DdCNuWJI1o6ACo\nqueq6oE2/TfA48BGYCtwQ2t2A3Bhm94K3Fg9e4Bjk5w4dM8lSSNZlXMASU4C3gLcC7yuqp6DXkgA\nJ7RmG4Fn+labazVJ0gSMHABJfhr4M+ADVfXdpZoOqNWAx9ueZCbJzPz8/KjdkyQtYqQASPIqei/+\nN1XVZ1v5+QOHdtr9vlafAzb3rb4JeHbhY1bVjqqarqrpqampUbonSVrCKFcBBbgeeLyq/qhv0S5g\nW5veBtzRV7+0XQ10BvDigUNFkqTxWzfCum8D/hXwSJIHW+0/AJ8EbktyGfA0cFFbdidwPjALvAS8\nZ4RtS5JGNHQAVNX/YvBxfYCzBrQv4PJhtydJWl2+E1iSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCk\njjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCk\njhp7ACQ5N8nXkswmuXLc25ck9Yw1AJIcBfwJcB5wKnBJklPH2QdJUs+4RwCnA7NV9WRV/RC4Bdg6\n5j5Ikhh/AGwEnumbn2s1SdKYrRvz9jKgVv9fg2Q7sL3Nfi/J10bY3gbg2yOsv9bs32js32js32jW\ntn//+g9HWfvnVtJo3AEwB2zum98EPNvfoKp2ADtWY2NJZqpqejUeay3Yv9HYv9HYv9Ec7v1biXEf\nAroP2JLk5CRHAxcDu8bcB0kSYx4BVNXLSa4A7gKOAnZW1WPj7IMkqWfch4CoqjuBO8e0uVU5lLSG\n7N9o7N9o7N9oDvf+LStVtXwrSdIrjh8FIUkddcQHwHIfLZHkmCS3tuX3JjlpjH3bnORLSR5P8liS\n9w9oc2aSF5M82G4fG1f/+vrwVJJH2vZnBixPkmvbPnw4yWlj7Nub+vbNg0m+m+QDC9qMdR8m2Zlk\nX5JH+2rHJdmdZG+7X7/Iuttam71Jto2xf7+f5Kvt9/e5JMcusu6Sz4U17N/vJPlm3+/w/EXWXfOP\nklmkf7f29e2pJA8usu6a779VVVVH7I3eieSvA28EjgYeAk5d0OY3gf/Spi8Gbh1j/04ETmvTPwM8\nMaB/ZwJ/MeH9+BSwYYnl5wOfp/c+jjOAeyf4+/4W8HOT3IfA24HTgEf7ar8HXNmmrwQ+NWC944An\n2/36Nr1+TP07G1jXpj81qH8reS6sYf9+B/jwCn7/S/69r1X/Fiz/Q+Bjk9p/q3k70kcAK/loia3A\nDW36duCsJIPekLbqquq5qnqgTf8N8DhH5juftwI3Vs8e4NgkJ06gH2cBX6+qv57Atv9OVd0D7F9Q\n7n+e3QBcOGDVc4DdVbW/ql4AdgPnjqN/VfWFqnq5ze6h9x6ciVhk/63EWD5KZqn+tdeOfwncvNrb\nnYQjPQBW8tESf9em/QG8CBw/lt71aYee3gLcO2DxLyd5KMnnk/ziWDvWU8AXktzf3om90OHyER4X\ns/gf3qT34euq6jnoBT9wwoA2h8t+fC+9Ed0gyz0X1tIV7RDVzkUOoR0O++9Xgeerau8iyye5/w7Z\nkR4Ay360xArbrKkkPw38GfCBqvrugsUP0Duk8UvAfwL+fJx9a95WVafR+5TWy5O8fcHyw2EfHg1c\nAPz3AYsPh324EofDfrwKeBm4aZEmyz0X1sp1wM8D/wR4jt5hloUmvv+AS1j6v/9J7b+hHOkBsOxH\nS/S3SbIOeC3DDT+HkuRV9F78b6qqzy5cXlXfrarvtek7gVcl2TCu/rXtPtvu9wGfozfU7reS/bzW\nzgMeqKrnFy44HPYh8PyBw2Ltft+ANhPdj+2k87uA36h2wHqhFTwX1kRVPV9VP6qqHwN/ush2J73/\n1gH/Arh1sTaT2n/DOtIDYCUfLbELOHC1xbuBLy725F9t7Xjh9cDjVfVHi7T52QPnJJKcTu938n/G\n0b+2zdck+ZkD0/ROFj66oNku4NJ2NdAZwIsHDneM0aL/eU16Hzb9z7NtwB0D2twFnJ1kfTvEcXar\nrbkk5wIfAS6oqpcWabOS58Ja9a//nNI/X2S7k/4omV8DvlpVc4MWTnL/DW3SZ6FHvdG7QuUJelcH\nXNVqH6f3RAf4KXqHDWaBLwNvHGPf/im9IerDwIPtdj7wPuB9rc0VwGP0rmjYA/zKmPffG9u2H2r9\nOLAP+/sYel/k83XgEWB6zH18Nb0X9Nf21Sa2D+kF0XPA39L7r/QyeueV7gb2tvvjWttp4NN96763\nPRdngfeMsX+z9I6fH3geHrgy7vXAnUs9F8bUv//WnlsP03tRP3Fh/9r8QX/v4+hfq3/mwHOur+3Y\n999q3nwnsCR11JF+CEiSNCQDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaP+H3PDE739\nEhS0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups_train.data, newsgroups_train.target, test_size=0.25, random_state=33)\n",
    "\n",
    "plt.hist(y_train, alpha=0.5)\n",
    "plt.hist(y_test, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=10,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words='english', strip_accents='unicode', sublinear_tf=False,\n",
       "         token_pattern='\\\\b[a-zA-Z]{3,}\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    \n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)]\n",
    "}\n",
    "\n",
    "grid_0 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_0.fit(X_train, y_train)\n",
    "grid_0.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10,\n",
       " 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=10,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words='english', strip_accents='unicode', sublinear_tf=False,\n",
       "         token_pattern='\\\\b[a-zA-Z]{3,}\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    (\"pca\", TruncatedSVD(n_components=2)), \n",
    "    ('classifier', LinearSVC(C=1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],\n",
    "            'classifier__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "    ('classifier', SVC(C=1, probability=True))\n",
    "])\n",
    "\n",
    "param_grid_2 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],   \n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe_2, param_grid_2, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_3 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()), \n",
    "    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "    ('classifier', LogisticRegression(C=1))\n",
    "])\n",
    "\n",
    "param_grid_3 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],   \n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(pipe_3, param_grid_3, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_4 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=2, metric='euclidean'))\n",
    "])\n",
    "\n",
    "param_grid_4 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],   \n",
    "            'classifier__n_neighbors': [2, 5, 10, 11,12],\n",
    "            'classifier__metric': ['euclidean', 'cityblock', 'cosine']\n",
    "}\n",
    "\n",
    "\n",
    "grid_4 = GridSearchCV(pipe_4, param_grid_4, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_5 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid_5 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],    \n",
    "            'classifier__max_depth': [5,9,10,11,20,30],\n",
    "            'classifier__min_samples_split': [2,3,5,10,20,30,40],\n",
    "            'classifier__max_leaf_nodes': [3,4,10,14,15,16,20,30,40]\n",
    "}\n",
    "\n",
    "\n",
    "grid_5 = GridSearchCV(pipe_5, param_grid_5, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_5.(X_train, y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_6 = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                   (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', BaggingClassifier(\n",
    "                                    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "                                    max_samples=100, bootstrap=True, random_state=42))\n",
    "                  ])\n",
    "\n",
    "param_grid_6 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],    \n",
    "            'classifier__n_estimators': [10,50,100],\n",
    "            'classifier__max_samples': [10,20]\n",
    "             }\n",
    "\n",
    "grid_6 = GridSearchCV(pipe_6, param_grid_6, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_6.fit(X_train, y_train)\n",
    "grid_6.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_7 = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                   (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', RandomForestClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_7 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],    \n",
    "            'classifier__n_estimators': [10, 50, 100],\n",
    "            'classifier__max_leaf_nodes': [10, 20],\n",
    "            'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_7 = GridSearchCV(pipe_7, param_grid_7, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_7.fit(X_train, y_train)\n",
    "grid_7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pipe_8 = Pipeline([('vectorizer', CountVectorizer()), \n",
    "                   (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', ExtraTreesClassifier(n_estimators=500, max_leaf_nodes=16))\n",
    "                  ])\n",
    "\n",
    "param_grid_8 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],\n",
    "                'classifier__n_estimators': [10, 50, 100],\n",
    "                'classifier__max_leaf_nodes': [10, 20],\n",
    "                'classifier__max_depth': [10, 20]\n",
    "             }\n",
    "\n",
    "grid_8 = GridSearchCV(pipe_8, param_grid_8, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_8.fit(X_train, y_train)\n",
    "grid_8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_9 = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                   (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', AdaBoostClassifier(\n",
    "                        DecisionTreeClassifier(max_depth=1), \n",
    "                        n_estimators=1, learning_rate=0.5, \n",
    "                        algorithm=\"SAMME.R\", random_state=42)\n",
    "                   )\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_9 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_9 = GridSearchCV(pipe_9, param_grid_9, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_9.fit(X_train, y_train)\n",
    "grid_9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_10 = Pipeline([('vectorizer', CountVectorizer()), \n",
    "                    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', GradientBoostingClassifier(\n",
    "                       n_estimators=1, \n",
    "                      learning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_10 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_10 = GridSearchCV(pipe_10, param_grid_10, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_10.fit(X_train, y_train)\n",
    "grid_10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_11 = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', xgboost.XGBClassifier(n_estimators=1, \n",
    "                      learning_rate=0.5, \n",
    "                      random_state=42))\n",
    "                  ])\n",
    "\n",
    "\n",
    "param_grid_11 = {\n",
    "            'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10), \n",
    "                           CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)],\n",
    "                'classifier__n_estimators': [50, 100, 200],\n",
    "                'classifier__learning_rate': [0.1, 0.2,0.5,0.9, 1]\n",
    "             }\n",
    "\n",
    "grid_11 = GridSearchCV(pipe_11, param_grid_11, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_11.fit(X_train, y_train)\n",
    "grid_11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('grid_2', grid_2.best_estimator_), \n",
    "                ('grid_3', grid_3.best_estimator_), \n",
    "                ('grid_4', grid_4.best_estimator_), \n",
    "                ('grid_5', grid_5.best_estimator_), \n",
    "                ('grid_6', grid_6.best_estimator_), \n",
    "                ('grid_7', grid_7.best_estimator_), \n",
    "                ('grid_8', grid_8.best_estimator_), \n",
    "                ('grid_9', grid_9.best_estimator_),\n",
    "                ('grid_10', grid_10.best_estimator_), \n",
    "                ('grid_11', grid_11.best_estimator_)\n",
    "               ],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator = xgboost.XGBClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_12 = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                    (\"pca\", TruncatedSVD(n_components=10)),\n",
    "                   ('classifier', xgboost.XGBClassifier(n_jobs=-1))\n",
    "                  ])\n",
    "\n",
    "param_grid_12 = {\n",
    "    'vectorizer': [TfidfVectorizer(strip_accents = 'unicode',\n",
    "                        stop_words = 'english',\n",
    "                        lowercase = True,\n",
    "                        token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                        max_df = 0.5, \n",
    "                        min_df = 10), \n",
    "                   CountVectorizer(strip_accents = 'unicode',\n",
    "                        stop_words = 'english',\n",
    "                        lowercase = True,\n",
    "                        token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                        max_df = 0.5, \n",
    "                        min_df = 10)],\n",
    "    'classifier__max_depth': [3, 5, 8, 10],\n",
    "    'classifier__learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'classifier__n_estimators': [50, 100, 150, 200, 400],\n",
    "    'classifier__gamma': [0, 0.5, 1, 2],\n",
    "    'classifier__colsample_bytree': [1, 0.8, 0.5],\n",
    "    'classifier__subsample': [1, 0.8, 0.5],\n",
    "    'classifier__min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_12 = RandomizedSearchCV(n_iter=30,estimator=pipe_12, \n",
    "                             param_distributions=param_grid_12, \n",
    "                      cv=kfold, \n",
    "                      return_train_score=True)\n",
    "\n",
    "grid_12.fit(X_train, y_train)\n",
    "grid_12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB\n",
      "precision_score: 0.7255156638785948\n",
      "recall_score: 0.7043718166383701\n",
      "f1_score: 0.6947302256516584\n",
      "accuracy_score: 0.7043718166383701\n",
      "SVM linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.3700373476918\n",
      "recall_score: 0.39282682512733447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.34093662941938446\n",
      "accuracy_score: 0.39282682512733447\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('NB', grid_0.best_estimator_))\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "# models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "# models.append(('LR', grid_3.best_estimator_))\n",
    "# models.append(('KNN', grid_4.best_estimator_))\n",
    "# models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "# models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "# models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "# models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "# models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "# models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "# models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "# models.append(('voting_clf', voting_clf))\n",
    "# models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test), average='weighted') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test), average='weighted') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test), average='weighted') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "\n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test), average='weighted') )\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test), average='weighted') )\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test), average='weighted') )\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.725516</td>\n",
       "      <td>0.704372</td>\n",
       "      <td>0.694730</td>\n",
       "      <td>0.704372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM linear</td>\n",
       "      <td>0.370037</td>\n",
       "      <td>0.392827</td>\n",
       "      <td>0.340937</td>\n",
       "      <td>0.392827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method  precision_score  recall_score  f1_score  accuracy_score\n",
       "0          NB         0.725516      0.704372  0.694730        0.704372\n",
       "1  SVM linear         0.370037      0.392827  0.340937        0.392827"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['NB', 'SVM linear'])\n",
    "# df.insert(loc=0, column='Method', value=['NB', 'SVM linear','SVM rbf','LR','KNN','DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','voting','XGBClassifier r'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
